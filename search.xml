<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[java HTTP多线程断点续传下载]]></title>
    <url>%2F2018%2F07%2F21%2Fjava%20HTTP%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%96%AD%E7%82%B9%E7%BB%AD%E4%BC%A0%E4%B8%8B%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[HTTP协议可以说是当前最最重要的通信协议之一，HTTP协议作为应用层协议作用在TCP协议之上，是现在最广泛、最通用的通信协议。正因为如此，今天来说一说HTTP的断点续传功能。 断点续传：顾名思义就是说在数据传输时因网络原因出现下载中断，在这个时候可以在中断的地方继续下载而不需要重新下载。HTTP的断点续传原理比较简单，在HTTP1.1(RFC2616)中定义了断点续传相关的HTTP头Range和Content-Range字段。在请求某资源时，HTTP头加上Range头，如果服务器支持断点续传功能，那么你可以获取一个带有Content-Range的响应头的响应。 断点续传：顾名思义就是说在数据传输时因网络原因出现下载中断，在这个时候可以在中断的地方继续下载而不需要重新下载。HTTP的断点续传原理比较简单，在HTTP1.1(RFC2616)中定义了断点续传相关的HTTP头Range和Content-Range字段。在请求某资源时，HTTP头加上Range头，如果服务器支持断点续传功能，那么你可以获取一个带有Content-Range的响应头的响应。 一个HTTP断点续传基本步骤如下： 客户端请求某资源，HTTP头加上Range头，如： Range:bytes=1024-2048； 请求成功，服务器返回带COntent-Range响应头的响应，如：Content-Range:bytes 1024-2048/512000； 此时网络中断，客户端已经记录了当前下载的进度。 客户端继续请求资源，此时Range头将从2048开始。 资源下载成功。接下来看代码： public class MultiDownloadProcessor { private String url; private String targetPath; private int threadCount; private long contentLength; private static final String FILE_WRITE_READ = &quot;rw&quot;; private static final String FILE_WRITE_READ_MODIFY = &quot;rwd&quot;; private static final String SUFFIX_TEMP = &quot;.tmp&quot;; private static final String RANGE_HEAD = &quot;Range&quot;; private static final int SNIFF_BYTES = 1024; private static final int BUFFER = 1024 * 1024; private static final String CONTENT_RANGE = &quot;Content-Range&quot;; private static final String CONTENT_RANGE_DASH = &quot;/&quot;; private static final int TEMP_FILE_SKIP = 8; public MultiDownloadProcessor(String url, String targetPath, int threadCount) { this.url = url; this.targetPath = targetPath; this.threadCount = threadCount; } public void download() throws Exception { long startTime = System.currentTimeMillis(); boolean isRange = sniffDownload(); System.out.println(&quot;contentLength:&quot; + this.contentLength); File file = new File(targetPath, getFileName(url)); //提前初始化好要下载文件 initFile(file); if (isRange) { //分片下载 partialDownload(file); System.out.println(&quot;down!!!!!!,use time：&quot; + (System.currentTimeMillis() - startTime)); }else { //......简单单线程下载 } } private void partialDownload(File file) throws Exception { File tempFile = new File(targetPath, fetchFileName(url) + SUFFIX_TEMP); List&lt;FutureTask&lt;Boolean&gt;&gt; list = new ArrayList&lt;&gt;(); if(contentLength&lt;=0) { throw new Exception(&quot;contentLength is illegal&quot;); } //分块下载，建议设一个阈值，大于这个值才多线程下载 long blockSize = contentLength / threadCount; for (int threadId = 0; threadId &lt; threadCount; threadId++) { long startIndex = threadId * blockSize; long endIndex = (threadId + 1) * blockSize; if (threadId == (threadCount - 1)) { endIndex = contentLength - 1; } DownloadHandler downloadHandler = new DownloadHandler(threadId, startIndex, endIndex, file); FutureTask&lt;Boolean&gt; result = new FutureTask&lt;&gt;(downloadHandler); Thread thread = new Thread(result); thread.start(); list.add(result); } for (FutureTask&lt;Boolean&gt; futureTask : list) { futureTask.get(); } cleanTemp(tempFile); } private void initFile(File file) throws Exception { //做得更好可以进来就创建一个下载系统自己的下载文件名，当下载完成就把名字改为目标名，chrome就是这么做的 RandomAccessFile randomAccessFile = null; if (!file.exists()) { randomAccessFile = new RandomAccessFile(file, FILE_WRITE_READ_MODIFY); randomAccessFile.setLength(contentLength); randomAccessFile.close(); } } //嗅探下载，判断是否可分片下载 private boolean sniffDownload() throws Exception { Set&lt;Header&gt; set = new HashSet&lt;&gt;(); Header header = new BasicHeader(RANGE_HEAD, &quot;bytes=&quot; + 0 + &quot;-&quot; + SNIFF_BYTES); set.add(header); CloseableHttpResponse response = HttpUtils.doHttpGetResponse(url, set); int code = response.getStatusLine().getStatusCode(); long currentLength = response.getEntity().getContentLength(); response.close(); if (code == HttpStatus.SC_PARTIAL_CONTENT) { String contentRange = getContentRange(response.getAllHeaders()); if (!StringUtils.isEmpty(contentRange)) { this.contentLength = Long.valueOf(contentRange); return true; } return false; } else if (code &gt;= HttpStatus.SC_BAD_REQUEST) { throw new Exception(&quot;request download url failed,statusCode: &quot; + code); } else { this.contentLength = currentLength; return false; } } private String getContentRange(Header[] headers) { if (headers != null &amp;&amp; headers.length &gt; 0) { for (Header header : headers) { if (CONTENT_RANGE.equals(header.getName())) { String value = header.getValue(); return value.substring(value.lastIndexOf(CONTENT_RANGE_DASH) + 1); } } } return null; } private String getFileName(String url) { if (!url.contains(&quot;.&quot;)) { return null; } if (url.contains(&quot;?&quot;)) { return url.substring(url.lastIndexOf(&quot;/&quot;) + 1, url.lastIndexOf(&quot;?&quot;)); } return url.substring(url.lastIndexOf(&quot;/&quot;) + 1); } private String fetchFileName(String url) { return url.substring(url.lastIndexOf(&quot;/&quot;), url.lastIndexOf(&quot;.&quot;)); } private class DownloadHandler implements Callable&lt;Boolean&gt; { private int threadId; private long startIndex; private long endIndex; private File file; public DownloadHandler(int threadId, long startIndex, long endIndex, File file) { this.threadId = threadId; this.startIndex = startIndex; this.endIndex = endIndex; this.file = file; } private void readTemp(File tempFile, int threadId) throws Exception { if (tempFile.exists()) { RandomAccessFile randomAccessFile = new RandomAccessFile(tempFile, &quot;r&quot;); long skip = threadId &lt;&lt; TEMP_FILE_SKIP; randomAccessFile.seek(skip); if (randomAccessFile.length() &lt; skip) return; long l = randomAccessFile.readLong(); this.startIndex = l; randomAccessFile.close(); } } private void writeTemp(File tempFile,int threadId,int downloadTotal) throws Exception { RandomAccessFile temp = new RandomAccessFile(tempFile, FILE_WRITE_READ_MODIFY); temp.seek(threadId &lt;&lt; TEMP_FILE_SKIP); temp.writeLong(this.startIndex + downloadTotal); temp.close(); } private CloseableHttpResponse partialHttpRequest(String url, long startIndex, long endIndex) throws Exception { Set&lt;Header&gt; set = new HashSet&lt;&gt;(); Header header = new BasicHeader(RANGE_HEAD, &quot;bytes=&quot; + startIndex + &quot;-&quot; + endIndex); set.add(header); CloseableHttpResponse response = HttpUtils.doHttpGetResponse(url, set); return response; } //使用callable而不是runnable方便捕获异常 @Override public Boolean call() throws Exception { System.out.println(&quot;threadId:&quot; + threadId + &quot;start download&quot; + System.currentTimeMillis()); CloseableHttpResponse response = null; RandomAccessFile targetFile = null; InputStream content = null; try { File tempFile = new File(targetPath, fetchFileName(url) + SUFFIX_TEMP); readTemp(tempFile, threadId); System.out.println(&quot;threadId:&quot; + threadId + &quot; startIndex:&quot; + startIndex + &quot; endIndex:&quot; + endIndex); response = partialHttpRequest(url, startIndex, endIndex); content = response.getEntity().getContent(); targetFile = new RandomAccessFile(file, FILE_WRITE_READ_MODIFY); targetFile.seek(startIndex); byte[] buffer = new byte[BUFFER]; int len = 0; int total = 0;//记录本次文件下载大小 while ((len = content.read(buffer)) &gt; 0) { total += len; targetFile.write(buffer, 0, len); //记录当前线程下载进度 writeTemp(tempFile,threadId,total); } System.out.println(System.currentTimeMillis() + &quot;threadId:&quot; + threadId + &quot;download finished! this time get total :&quot; + total + &quot; byte data&quot;); } finally { if (content != null) content.close(); if (response != null) response.close(); if (targetFile != null) targetFile.close(); } return true; } } //删除线程产生的临时文件 private synchronized void cleanTemp(File file) { if (file.exists()) { file.delete(); } } }]]></content>
      <tags>
        <tag>多线程,断点续传</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次内存泄漏排查]]></title>
    <url>%2F2018%2F04%2F29%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[引言最近公司一项目写完在进行压测，在压测过程中偶然top了几次，发现项目运行的进程占用的资源RES一直在缓慢增长。于是怀疑是存在内存泄漏。 用通俗的话来讲内存泄漏是由于开发人员没有注意到内存管理，没有有效的进行内存回收导致的一部分内存无法被回收，同时在系统运行过程中会不断有新的相关内存占用，最终导致Out of Memory。这种情况在C++ programmer中是非常头疼的一件事，因为C++把内存管理的权限交给了开发人员，但是对于Java开发人员来说会轻松很多，因为JVM自带GC收集器垃圾内存回收一般不需要开发人员关心。那么有人会问了，既然如此Java程序有可能会出现内存泄漏情况吗？答案是肯定的。那么为什么在有GC收集器的情况下还会有内存泄露呢？这还需要搞清楚JVM的垃圾回收的原理–什么样的对象会被认为是垃圾 垃圾回收算法Java的JVM种类繁多，以Hotspot JVM为例，Hotspot使用的是根搜索算法，根搜索算法基本原理是定义好一个或多个GC Root对象，从这些GC Root对象开始向下遍历该对象的引用对象，遍历走过的路径叫引用链，如果一个对象没有一条引用链可达，那么这个对象和其引用链都会被标记为垃圾，会被GC收集器回收掉。在JAVA语言中，可以作为GC Root的对象有如下几种： 虚拟机栈（栈帧中d额本地变量表）中引用的对象 方法区中静态属性引用的对象 方法区中常量引用的对象 本地方法栈JNI（native方法）的引用对象了解了垃圾回收算法，我们就有理由相信JAVA程序也可能出现内存泄漏的，如果我们开发人员不注意写了一些对象被GC Root对象引用了，并且没有做内存释放操作，比如说一些集合的操作，尤其是类全局变量的集合，一有操作不慎就会造成内存泄漏。 排查过程说了这么多，现在来看看本人经历的一次内存泄露排查过程。背景上面已经介绍了，项目就是一个简单的netty程序。当发现可能有内存泄漏后，做的第一件事就是排查代码，毕竟是自己写的代码，自己最熟悉，在一通排查后并没有发现有明显集合数据添加了没有remove的操作，当时是懵逼的，因为有add就有正常remove，没办法只能祭出杀手锏使用jmap、jstat和三方内存泄漏分析工具–memory analyzer。 首先使用jstat -gcutil pid 6000 命令每6秒查看一次gc情况，观察一段时间后发现，项目运行一天后疯狂进行Full GC，这下可以断定绝对有内存泄露。然后使用jmap -histo:live pid | head -10 命令查看系统运行进程存活对象数量和占用内存前五的对象，如下图： num #instances #bytes class name ---------------------------------------------- 1: 278 16903672 [B 2: 8766 819424 [C 3: 3454 385560 java.lang.Class 4: 2777 305984 [Ljava.lang.Object; 5: 6858 219456 java.util.concurrent.ConcurrentHashMap$Node 6: 8716 209184 java.lang.String 7: 6438 103008 java.lang.Object 发现排名第一多对象数量和占用内存最多的竟然是一个Long对象，这绝对有问题，一般没有内存泄漏的系统jmap出来的前五一般都是byte、char、string这些对象，知道这个Long有问题，本人又去代码中瞧了一眼，用了Long的地方都是正常的，有remove释放操作，为了进一步弄清到底是哪个地方出问题，我祭出了终极大法–Memory Analyzer。使用jmap -dump:format=b,file=文件名 [pid] 命令dump出来内存映像文件，然后扔进Memory Analyzer，进入histoGram，选择Long这个对象，右键选择with income object。可以找到引用链，最终发现是一个别的同事写的私用协议有个全局字段add到队列中但是没有remove，所以导致内存泄漏。 对了，最后说一嘴之前我不是使用top看内存涨了么，其实使用top看是看不出什么的，因为就算没有内存泄漏，特么RES也是会涨的，因为JVM向操作系统要内存了之后，如果当前内存够，JVM是不会立马释放内存的，JVM还会占用这块内存当做缓存，防止数据高峰时又需要向操作系统要内存（因为系统调用是要时间和性能做代价的）。]]></content>
      <tags>
        <tag>JAVA,内存泄漏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解dubbo之服务引用源码分析]]></title>
    <url>%2F2018%2F01%2F14%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3dubbo%E4%B9%8B%E6%9C%8D%E5%8A%A1%E5%BC%95%E7%94%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[在之前说了一下dubbo的服务发布过程，其实严格意义上只说了一半吧，只把dubbo如何经过ProxyFactory的代理成一个Invoker，等待客户端调用的过程讲了一遍，而重要的Protocol.export方法略过去了，今天我将连带dubbo的comsumer客户端服务引用和Protocol机制来讲一讲。 dubbo服务引用和上一篇文章一样，先来个demo 123456789101112131415&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;dubbo:application name=&quot;ifenqu-web&quot; /&gt; &lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;$&#123;dubbo.address&#125;&quot; /&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;$&#123;dubbo.port&#125;&quot;/&gt; &lt;dubbo:consumer timeout=&quot;60000&quot; check=&quot;false&quot;/&gt; &lt;dubbo:service interface=&quot;com.xxx.xxx.xxxService&quot; ref=&quot;xxxService&quot; timeout=&quot;5000&quot;/&gt;&lt;/beans&gt; 在上篇文章我们已经说了，对于service暴露方也就是provider方有对应的ServiceConfig，相应的Reference引用方也就是Consumer有对应的ReferenceConfig。ReferenceConfig中定义了每一个接口参数定义，这只是部分，还有一大堆参数在父类里就不列出来了。 123456789101112131415161718// 接口类型private String interfaceName;private Class&lt;?&gt; interfaceClass;// 客户端类型private String client;// 点对点直连服务提供地址private String url;// 方法配置private List&lt;MethodConfig&gt; methods;//接口所有的方法配置// 缺省配置private ConsumerConfig consumer;//该参数对应的就是&lt;dubbo:consumer timeout=&quot;60000&quot; check=&quot;false&quot;/&gt;private String protocol;//如果为空默认dubbo 参数设值分两步，第一步是对象创建的时候，第二步是调用了get方法后执行init()方法。这个get方法就是服务引用的入口： 12345678910public synchronized T get() &#123; if (destroyed)&#123; throw new IllegalStateException(&quot;Already destroyed!&quot;); &#125; //服务实例已经存在就直接返回，没有就进行初始化 if (ref == null) &#123; init(); &#125; return ref; &#125; init()方法主要分为两个步骤，第一步：收集上下文，第二步：根据上下文创建服务实例 ref = createProxy(map);进入createProxy方法中去看看 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879private T createProxy(Map&lt;String, String&gt; map) &#123; URL tmpUrl = new URL(&quot;temp&quot;, &quot;localhost&quot;, 0, map); final boolean isJvmRefer; if (isInjvm() == null) &#123; if (url != null &amp;&amp; url.length() &gt; 0) &#123; //指定URL的情况下，不做本地引用 isJvmRefer = false; &#125; else if (InjvmProtocol.getInjvmProtocol().isInjvmRefer(tmpUrl)) &#123; //默认情况下如果本地有服务暴露，则引用本地服务. isJvmRefer = true; &#125; else &#123; isJvmRefer = false; &#125; &#125; else &#123; isJvmRefer = isInjvm().booleanValue(); &#125; if (isJvmRefer) &#123; URL url = new URL(Constants.LOCAL_PROTOCOL, NetUtils.LOCALHOST, 0, interfaceClass.getName()).addParameters(map); invoker = refprotocol.refer(interfaceClass, url); if (logger.isInfoEnabled()) &#123; logger.info(&quot;Using injvm service &quot; + interfaceClass.getName()); &#125; &#125; else &#123; if (url != null &amp;&amp; url.length() &gt; 0) &#123; // 用户指定URL，指定的URL可能是对点对直连地址，也可能是注册中心URL String[] us = Constants.SEMICOLON_SPLIT_PATTERN.split(url); if (us != null &amp;&amp; us.length &gt; 0) &#123; for (String u : us) &#123; URL url = URL.valueOf(u); if (url.getPath() == null || url.getPath().length() == 0) &#123; url = url.setPath(interfaceName); &#125; if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; urls.add(url.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map))); &#125; else &#123; urls.add(ClusterUtils.mergeUrl(url, map)); &#125; &#125; &#125; &#125; else &#123; // 通过注册中心配置拼装URL List&lt;URL&gt; us = loadRegistries(false); if (us != null &amp;&amp; us.size() &gt; 0) &#123; for (URL u : us) &#123; URL monitorUrl = loadMonitor(u); if (monitorUrl != null) &#123; map.put(Constants.MONITOR_KEY, URL.encode(monitorUrl.toFullString())); &#125; urls.add(u.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map))); &#125; &#125; if (urls == null || urls.size() == 0) &#123; throw new IllegalStateException(&quot;No such any registry to reference &quot; + interfaceName + &quot; on the consumer &quot; + NetUtils.getLocalHost() + &quot; use dubbo version &quot; + Version.getVersion() + &quot;, please config &lt;dubbo:registry address=\&quot;...\&quot; /&gt; to your spring config.&quot;); &#125; &#125; if (urls.size() == 1) &#123; invoker = refprotocol.refer(interfaceClass, urls.get(0)); &#125; else &#123; List&lt;Invoker&lt;?&gt;&gt; invokers = new ArrayList&lt;Invoker&lt;?&gt;&gt;(); URL registryURL = null; for (URL url : urls) &#123; invokers.add(refprotocol.refer(interfaceClass, url)); if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; registryURL = url; // 用了最后一个registry url &#125; &#125; if (registryURL != null) &#123; // 有 注册中心协议的URL // 对有注册中心的Cluster 只用 AvailableCluster URL u = registryURL.addParameter(Constants.CLUSTER_KEY, AvailableCluster.NAME); invoker = cluster.join(new StaticDirectory(u, invokers)); &#125; else &#123; // 不是 注册中心的URL invoker = cluster.join(new StaticDirectory(invokers)); &#125; &#125; &#125; //忽略非核心代码 // 创建服务代理 return (T) proxyFactory.getProxy(invoker); &#125; 该方法中主要逻辑就是先判断需要引用的类型，是本地服务暴露还是直连远程服务还是集群远程服务。如果暴露的服务本地就有直接url就是localhost，而对于集群还涉及到了loadbanlance。无论是什么类型的服务核心都是refprotocol.refer(interfaceClass, urls.get(0))，这个方法的返回值就是上篇说的Invoker对象，回忆一下，Invoker对象中封装了接口信息和invoke方法，只要客户端拿到了这个Invoker就可以执行invoke进而通过远程通信触发服务端的service返回执行结果。让我们的视线再回到refprotocol上： 123456789101112@SPI(&quot;dubbo&quot;)public interface Protocol &#123; int getDefaultPort(); @Adaptive &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; var1) throws RpcException; @Adaptive &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; var1, URL var2) throws RpcException; void destroy();&#125; 这个Protocol接口定义了三个方法，export、refer、destory。分别是服务暴露和服务引用和销毁方法。经过上一篇的讲述，我们已经知道了dubbo支持dubbo、http、thrift等多种协议。那么dubbo是如何做到多个版本协议可以切换自如呢？方法就在SPI上。 SPISPI（Service Provider Interface）本来是针对不同厂商或插件的一个规范，提供扩展的时候可以对同一个功能用不同的实现。Java SPI的基本思想可以用设计模式六大原则之开闭原则解释，也就是说要对接口开放，对修改关闭。基于这个原则我们就可以对不同的实现完成可拔插的效果。多种不用实现想用哪种用哪种，只要简单修改配置。 Java SPI的具体约定为:当服务的提供者，提供了服务接口的一种实现之后，在jar包的META-INF/services/目录里同时创建一个以服务接口命名的文件。该文件里就是实现该服务接口的具体实现类。而当外部程序装配这个模块的时候，就能通过该jar包META-INF/services/里的配置文件找到具体的实现类名，并装载实例化，完成模块的注入。 基于这样一个约定就能很好的找到服务接口的实现类，而不需要再代码里制定。jdk提供服务实现查找的一个工具类：java.util.ServiceLoader 知道了SPI的定义现在就更好了解Protocol的实现原理了，在ReferenceConfig中获取具体的Protocol是这一行代码private static final Protocol refprotocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();我们可以根据SPI的定义来看看它的实现过程。进入ExtensionLoader类，在这个类中我们可以看到以下几个熟悉的全局常量 1234private static final String SERVICES_DIRECTORY = &quot;META-INF/services/&quot;; private static final String DUBBO_DIRECTORY = &quot;META-INF/dubbo/&quot;; private static final String DUBBO_INTERNAL_DIRECTORY = &quot;META-INF/dubbo/internal/&quot;; private static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap(); debug断点跟进去就会看到这个EXTENSION_LOADERS里面已经装满了多个ExtensionLoaders，尽到dubbo的jar包的META-INF/dubbo/internal/路径时就全明白了，这里面就是这些ExtensionLoaders。就拿我们要说的Protocol来说，ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension()这行代码说的就是传入Protocol.class类型，就能在EXTENSION_LOADERS中找到com.alibaba.dubbo.rpc.Protocol这个类，也就是META-INF/dubbo/internal/路径下的定义的文件com.alibaba.dubbo.rpc.Protocol。进入这个文件我们能看到所有Protocol实现类定义: 1234567891011121314registry=com.alibaba.dubbo.registry.integration.RegistryProtocoldubbo=com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocolfilter=com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapperlistener=com.alibaba.dubbo.rpc.protocol.ProtocolListenerWrappermock=com.alibaba.dubbo.rpc.support.MockProtocolinjvm=com.alibaba.dubbo.rpc.protocol.injvm.InjvmProtocolrmi=com.alibaba.dubbo.rpc.protocol.rmi.RmiProtocolhessian=com.alibaba.dubbo.rpc.protocol.hessian.HessianProtocolcom.alibaba.dubbo.rpc.protocol.http.HttpProtocolcom.alibaba.dubbo.rpc.protocol.webservice.WebServiceProtocolthrift=com.alibaba.dubbo.rpc.protocol.thrift.ThriftProtocolmemcached=com.alibaba.dubbo.rpc.protocol.memcached.MemcachedProtocolredis=com.alibaba.dubbo.rpc.protocol.redis.RedisProtocol 如果你选择dubbo协议，Protocol的接口实现类就会使用com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol我这里使用的是系统默认的dubbo协议，所以我们上面ReferenceConfig方法里面调用的invoker = refprotocol.refer(interfaceClass, urls.get(0));就是DubboProtocol的Refer方法： 12345public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; serviceType, URL url) throws RpcException &#123; DubboInvoker&lt;T&gt; invoker = new DubboInvoker(serviceType, url, this.getClients(url), this.invokers); this.invokers.add(invoker); return invoker; &#125; 这个方法没什么好说的，就是Invoker的实例化而已，不过这个invoker已经有所有调用服务端的服务的必要参数。只需要通过invoker作为参数用ProxyFactory进行动态代理来拿到代理类就行了。 远程调用真正在方法调用时才会触发invoker的doInvoke方法，让我们看看这个doInvoke方法： 123456789101112131415161718192021222324252627282930313233343536protected Result doInvoke(Invocation invocation) throws Throwable &#123; RpcInvocation inv = (RpcInvocation)invocation; String methodName = RpcUtils.getMethodName(invocation); inv.setAttachment(&quot;path&quot;, this.getUrl().getPath()); inv.setAttachment(&quot;version&quot;, this.version); //通信客户端，可以与socket的客户端类比 ExchangeClient currentClient; if(this.clients.length == 1) &#123; currentClient = this.clients[0]; &#125; else &#123; currentClient = this.clients[this.index.getAndIncrement() % this.clients.length]; &#125; try &#123; boolean isAsync = RpcUtils.isAsync(this.getUrl(), invocation); boolean isOneway = RpcUtils.isOneway(this.getUrl(), invocation); int timeout = this.getUrl().getMethodParameter(methodName, &quot;timeout&quot;, 1000); if(isOneway) &#123; boolean isSent = this.getUrl().getMethodParameter(methodName, &quot;sent&quot;, false); currentClient.send(inv, isSent); RpcContext.getContext().setFuture((Future)null); return new RpcResult(); &#125; else if(isAsync) &#123; ResponseFuture future = currentClient.request(inv, timeout); RpcContext.getContext().setFuture(new FutureAdapter(future)); return new RpcResult(); &#125; else &#123; RpcContext.getContext().setFuture((Future)null); return (Result)currentClient.request(inv, timeout).get(); &#125; &#125; catch (TimeoutException var9) &#123; throw new RpcException(2, &quot;Invoke remote method timeout. method: &quot; + invocation.getMethodName() + &quot;, provider: &quot; + this.getUrl() + &quot;, cause: &quot; + var9.getMessage(), var9); &#125; catch (RemotingException var10) &#123; throw new RpcException(1, &quot;Failed to invoke remote method: &quot; + invocation.getMethodName() + &quot;, provider: &quot; + this.getUrl() + &quot;, cause: &quot; + var10.getMessage(), var10); &#125; &#125; 这个方法也很简单，首先拿到远程调用的参数，比如方法名，调用路径，暴露服务的版本号（版本号不同无法调通），拿到了ExchangeClient后就开始了请求，这个请求分同步和异步，都是看你配置来的，如果是同步的就一直阻塞直到timeout或者结果返回，如果是异步那么直接返回一个ResponseFuture，等执行成功后提供回调。到这，从consumer的方法引用到方法执行都说完了。讲得比较精炼，把很多东西都给省略了，其实dubbo真的特别复杂，但是对于我个人来说只要了解原理就已经达到我的目的了，所以到这就可以了。其实还有一部分比较重要，那就是网络通信部分，dubbo用的是netty。等有空了可以去膜拜膜拜。]]></content>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解dubbo之服务发布源码分析]]></title>
    <url>%2F2018%2F01%2F14%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3dubbo%E4%B9%8B%E6%9C%8D%E5%8A%A1%E5%8F%91%E5%B8%83%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[dubbo 是阿里开源的一个分布式服务框架，它的最大特点是按照分层的方式来架构，使各层之间充分解耦，并且它是无侵入性的，dubbo可以无缝与spring整合，更重要的是dubbo还提供了强大的容错和监控功能。 对于业务方来说，dubbo使用上手足够简单，调用过程对业务方透明，对开发人员友好。 Demo在spring项目中添加如下pom包：123456789101112&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;/dependency&gt; 如果你的是springboot项目也可以用springboot的starter包12345&lt;dependency&gt; &lt;groupId&gt;io.dubbo.springboot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-dubbo&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; 添加配置文件:spring-dubbo.xml123456789101112131415&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;dubbo:application name=&quot;ifenqu-web&quot; /&gt; &lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;$&#123;dubbo.address&#125;&quot; /&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;$&#123;dubbo.port&#125;&quot;/&gt; &lt;dubbo:consumer timeout=&quot;60000&quot; check=&quot;false&quot;/&gt; &lt;dubbo:service interface=&quot;com.xxx.xxx.xxxService&quot; ref=&quot;xxxService&quot; timeout=&quot;5000&quot;/&gt;&lt;/beans&gt; 调用的时候也很简单 12 @Autowiredprivate xxxService xxxService; demo 接介绍到这，今天的重点不是讲如何使用dubbo，今天的重点是说一说dubbo的架构设计。 源码分析dubbo框架设计总共分了10层： 服务接口层（Service）：该层是与实际业务逻辑相关，就如上面demo配置的&lt;dubbo:service interface=&quot;com.xxx.xxx.xxxService&quot; ref=&quot;xxxService&quot; timeout=&quot;5000&quot;/&gt;,这个service就是业务方自己定义的接口与其实现。 配置层（Config）：该层是将业务方的service信息，配置文件的信息收集起来，主要是以ServiceConfig和ReferenceConfig为中心，ServiceConfig是服务提供方的配置，当Spring启动的时候会相应的启动provider服务发布和注册的过程，主要是加入一个ServiceBean继承ServiceConfig在Spring注册。同理ReferenceConfig是consumer方的配置，当消费方启动时，会启动consumer的发现服务订阅服务的过程，当然也是使用一个ReferenceBean继承ReferenceConfig注册在spring上。 服务代理层（Proxy）：对服务接口进行透明代理，生成服务的客户端和服务器端，使服务的远程调用就像在本地调用一样。默认使用JavassistProxyFactory，返回一个Invoker，Invoker则是个可执行核心实体，Invoker的invoke方法通过反射执行service方法。 服务注册层（Registry）：封装服务地址的注册和发现，以服务URL为中心，基于zk。 集群层（Cluster）:提供多个节点并桥接注册中心，主要负责loadBanlance、容错。 监控层（Monitor）：RPC调用次数和调用时间监控，以Statistics为中心，扩展接口为MonitorFactory、Monitor和MonitorService。 远程调用层（Protocol）：封装RPC调用，provider通过export方法进行暴露服务/consumer通过refer方法调用服务。而Protocol依赖的是Invoker。通过上面说的Proxy获得的Invoker，包装成Exporter。 信息交换层（Exchange）：该层封装了请求响应模型，将同步转为异步，信息交换层依赖Exporter，最终将通过网络传输层接收调用请求RequestFuture和ResponseFuture。 网络传输层（Transport）：抽象mina和netty为统一接口，以Message为中心，扩展接口为Channel、Transporter、Client、Server和Codec。 数据序列化层：该层无需多言，将数据序列化反序列化。服务发布过程通过上面的框架了解我们大致知道了dubbo是怎么工作的，接下来我们来通过代码来具体看看dubbo的服务发布过程，进一步理解dubbo的工作原理。先看到demo中的spring-dubbo配置文件。这些配置文件全都会被装配成RegistryConfig，其属性如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class RegistryConfig extends AbstractConfig &#123; private static final long serialVersionUID = 5508512956753757169L; public static final String NO_AVAILABLE = &quot;N/A&quot;; // 注册中心地址 private String address; // 注册中心登录用户名 private String username; // 注册中心登录密码 private String password; // 注册中心缺省端口 private Integer port; // 注册中心协议 private String protocol; // 客户端实现 private String transporter; private String server; private String client; private String cluster; private String group; private String version; // 注册中心请求超时时间(毫秒) private Integer timeout; // 注册中心会话超时时间(毫秒) private Integer session; // 动态注册中心列表存储文件 private String file; // 停止时等候完成通知时间 private Integer wait; // 启动时检查注册中心是否存在 private Boolean check; // 在该注册中心上注册是动态的还是静态的服务 private Boolean dynamic; // 在该注册中心上服务是否暴露 private Boolean register; // 在该注册中心上服务是否引用 private Boolean subscribe; // 自定义参数 private Map&lt;String, String&gt; parameters; // 是否为缺省 private Boolean isDefault; 这些配置文件根据注册中心的个数会被装配拼接成Dubbo的URL（该url是dubbo中自定义的），该URL长这个样子：registry://sit-zk.host:2181/com.alibaba.dubbo.registry.RegistryService?application=ifenqu-web&amp;dubbo=2.5.3&amp;pid=13168&amp;registry=zookeeper&amp;timestamp=1510828420296看完配置信息，接下来让我们看下Service发布的核心方法：ServiceConfig类中的doExportUrls12345678private void doExportUrls() &#123; //该方法根据配置文件装配成一个URL的list List&lt;URL&gt; registryURLs = loadRegistries(true); //根据每一个协议配置来分别暴露服务 for (ProtocolConfig protocolConfig : protocols) &#123; doExportUrlsFor1Protocol(protocolConfig, registryURLs); &#125; &#125; 这个protocols长这个样子&lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20888&quot; id=&quot;dubbo&quot; /&gt; protocols也是根据配置装配出来的。接下来让我们进入doExportUrlsFor1Protocol方法看看dubbo具体是怎么样将服务暴露出去的。这个方法特别大，有将近300多行代码，但是其中大部分都是获取类似protocols的name、port、host和一些必要的上下文，代码太长就不全都贴出来了，只贴关键部分。1234567891011121314private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL&gt; registryURLs) &#123; //........省略获取上下文代码//通过interfaceClass获取要暴露服务的所有要暴露的方法String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames();//.......省略非核心代码//根据上下文创建URL对象 URL url = new URL(name, host, port, (contextPath == null || contextPath.length() == 0 ? &quot;&quot; : contextPath + &quot;/&quot;) + path, map);//通过proxyFactory来获取Invoker对象 Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString()));//将invoker对象在protocol中封装成Exporter方便提供给信息交换层进行网络传输 Exporter&lt;?&gt; exporter = protocol.export(invoker); //将exporter添加到list中 exporters.add(exporter); 看到这里就比较明白dubbo的工作原理了doExportUrlsFor1Protocol方法，先创建URL，URL创建出来长这样dubbo://192.168.xx.63:20888/com.xxx.xxx.VehicleInfoService?anyhost=true&amp;application=test-web&amp;default.retries=0&amp;dubbo=2.5.3&amp;interface=com.xxx.xxx.VehicleInfoService&amp;methods=get,save,update,del,list&amp;pid=13168&amp;revision=1.2.38&amp;side=provider&amp;timeout=5000&amp;timestamp=1510829644847，是不是觉得这个URL很眼熟，没错在注册中心看到的services的providers信息就是这个，再传入url通过proxyFactory获取Invoker，再将Invoker封装成Exporter的数组，只需要将这个list提供给网络传输层组件，然后consumer执行Invoker的invoke方法就行了。让我们再看看这个proxyFactory的getInvoker方法。proxyFactory下有JDKProxyFactory和JavassistProxyFactory。官方推荐也是默认使用的是JavassistProxyFactory。因为javassist动态代理性能比JDK的高。123456789101112131415161718192021public class JavassistProxyFactory extends AbstractProxyFactory &#123; @SuppressWarnings(&quot;unchecked&quot;) public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] interfaces) &#123; return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker)); &#125; public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; // TODO Wrapper类不能正确处理带$的类名 final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf(&apos;$&apos;) &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;; &#125;&#125; 可以看到使用了动态代理的方式调用了要暴露的service的方法。并且返回了Invoker对象。在dubbo的服务发布中我们可以看到，这个Invoker贯穿始终，都可以看成是一个context的作用了，让我们进Invoker里面去看看这个Invoker到底是何方神圣。1234567891011121314151617public interface Invoker&lt;T&gt; extends Node &#123; /** * get service interface. * * @return service interface. */ Class&lt;T&gt; getInterface(); /** * invoke. * * @param invocation * @return result * @throws RpcException */ Result invoke(Invocation invocation) throws RpcException; 这个Invoker就两个方法，一个getInterface，也就是要暴露的服务接口，一个就是invoke方法，这个invoke方法在AbstractProxyInvoker中是这样的：12345678910public Result invoke(Invocation invocation) throws RpcException &#123; try &#123; //调用doInvoke方法，返回一个Result return new RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments())); &#125; catch (InvocationTargetException e) &#123; return new RpcResult(e.getTargetException()); &#125; catch (Throwable e) &#123; throw new RpcException(&quot;Failed to invoke remote proxy method &quot; + invocation.getMethodName() + &quot; to &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); &#125;&#125; 其实看到JavassistProxyFactory大家就应该大概明白了这个Invoker的作用，同时这个类的名字就叫Invoker也可以猜个大概，Invoker就是调用service的方法的实体类。其中doInvoke方法已经在JavassistProxyFactory中定义了，通过反射调用要暴露的service的方法。 服务发布总结看完源码，我们已经知道了dubbo的主要发布过程，现在我们回过头来结合dubbo的总体架构和源码的分析，总结一下dubbo服务发布。服务发布过程总共五个步骤： 业务方将服务接口和实现编写定义好，添加dubbo相关配置文件。 Config层加载配置文件形成上下文，Config层包括：ServiceConfig、ProviderConfig、RegistryConfig等。 ServiceConfig根据Protocol类型，根据ProtocolConfig、ProviderConfig加载registry，根据加载的registry创建dubbo的URL。 准备工作做完后ProxyFactory上场，dubbo中有两种代理方式，JDK代理和Javassist代理，默认使用Javassist代理，Proxy代理类根据dubbo配置信息获取到接口信息、通过动态代理方式将接口的所有方法交给Proxy代理类进行代理，并封装进Invoker里面。 将所有需要暴露的service封装的Invoker组成一个list传给信息交换层提供给消费方进行调用。]]></content>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch5.3.0 索引创建及查询]]></title>
    <url>%2F2018%2F01%2F14%2Felasticsearch5-3-0-%E7%B4%A2%E5%BC%95%E5%88%9B%E5%BB%BA%E5%8F%8A%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[引言上篇文章介绍了elasticsearch5.3.0服务器搭建，接下来说说elasticsearch的java客户端对数据的索引创建和对数据的查询。虽说现在es的api使用文档不少，但是5.3.0版本的太新了，许多都不兼容老版本，所以有了这篇博文。elasticsearch允许HTTP Restful的方式进行数据访问和操作，也同样允许通过JAVA API来访问服务器，HTTP Restful方式官方网站有很详细的说明在这就不罗嗦了，先看如何使用JAVA API来访问服务器。 准备本人使用springboot建的项目，本文重点是如何使用es的java api，其他有的没的就先略去。首先引入elasticsearch客户端maven包,因为是5.3.0的版本，所以客户端包也保持一致。12345678910&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;transport&lt;/artifactId&gt; &lt;version&gt;5.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;5.3.0&lt;/version&gt; &lt;/dependency&gt; 索引创建及查询Client1234567891011@Beanpublic Client esClient()throws UnknownHostException &#123; Settings settings=Settings.builder() .put(&quot;cluster.name&quot;,clusterName)//集群名称 .put(&quot;client.transport.sniff&quot;,true)//是否开启嗅探功能 .build(); InetAddress inetAddress=InetAddress.getByName(ip); TransportAddress transportAddress =new InetSocketTransportAddress(inetAddress,port); return new PreBuiltTransportClient(settings) .addTransportAddress(transportAddress);&#125; 创建索引对于es的文档而言，一个文档会包括一个或者多个字段，任何字段都要有自己的数据类型，比如string、date等。es中是通过映射来进行字段和数据类型对应的，在默认的情况下es会自动识别字段的数据类型，但是最好还是提供一个mappings参数类显式的进行映射。 接下来我们先给要索引的数据创建一个mapping 1234567891011121314151617181920212223242526272829303132public boolean getMapping(String index, String type) &#123; try &#123; CreateIndexRequest createIndexRequest = new CreateIndexRequest(index); CreateIndexResponse createIndexResponse = esClient.admin().indices().create(createIndexRequest).get(); logger.info(&quot;Index:&#123;&#125; created,response:&#123;&#125;&quot;, index, JSON.toJSON(createIndexResponse)); XContentBuilder builder = XContentFactory.jsonBuilder(); builder.startObject() .startObject(type) .startObject(&quot;properties&quot;) .startObject(&quot;firstName&quot;).field(&quot;type&quot;, &quot;string&quot;) .endObject() .startObject(&quot;lastName&quot;).field(&quot;type&quot;, &quot;string&quot;) .endObject() .startObject(&quot;about&quot;).field(&quot;type&quot;, &quot;string&quot;) .endObject() .startObject(&quot;interests&quot;).field(&quot;type&quot;, &quot;string&quot;) .endObject() .endObject() .endObject(); PutMappingRequest putMappingRequest = new PutMappingRequest(index); putMappingRequest.type(type); putMappingRequest.source(builder); PutMappingResponse putMappingResponse = esClient.admin().indices().putMapping(putMappingRequest).get(); logger.info(&quot;Mapping for `&#123;&#125;.&#123;&#125;` putted, response:&#123;&#125;&quot;, index, type, JSON.toJSON(putMappingResponse)); return true; &#125; catch (Exception e) &#123; logger.error(&quot;doCreateIndex&quot;, e); return false; &#125;&#125; 测试数据是官网上的一个例子，就是一个公司部门中员工的信息，而mapping的作用就是在es中被索引的数据规定每一个field数据类型。 接下来添加索引数据：12345678910111213141516public boolean createIndex(String json) &#123; try &#123; if(!esIndexTypes.get(index)) &#123; if(getMapping(index, indexType)) esIndexTypes.put(index,true); &#125; IndexRequestBuilder requestBuilder = esClient.prepareIndex(index, indexType); IndexResponse indexResponse = requestBuilder.setSource(json).execute().actionGet(); logger.info(&quot;Index:&#123;&#125; created,response:&#123;&#125;&quot;, index, JSON.toJSON(indexResponse)); return true; &#125; catch (Exception e) &#123; logger.error(&quot;createIndex failed,exception:&#123;&#125;&quot;, e.getMessage()); return false; &#125;&#125; 组合查询并高亮显示123456789101112131415161718192021222324252627282930313233343536373839public List&lt;String&gt; search(String... queryStr) &#123; BoolQueryBuilder queryBuilder = QueryBuilders.boolQuery(); for (String s : queryStr) &#123;//使用queryStringQuery无法使用高亮 queryBuilder.should(QueryBuilders.matchQuery(&quot;about&quot;, s)); &#125; HighlightBuilder highlightBuilder = new HighlightBuilder(); highlightBuilder.preTags(&quot;&lt;span style=\&quot;color:red\&quot;&gt;&quot;); highlightBuilder.postTags(&quot;&lt;/span&gt;&quot;); highlightBuilder.field(&quot;about&quot;).field(&quot;interests&quot;).forceSource(true); SearchResponse searchResponse = esClient.prepareSearch(index) .setTypes(indexType) .setQuery(queryBuilder) .highlighter(highlightBuilder) .execute() .actionGet(); SearchHits hits = searchResponse.getHits(); List&lt;String&gt; list = new ArrayList&lt;String&gt;(); if (hits != null &amp;&amp; hits.getHits().length &gt; 0) &#123; for (SearchHit hit : hits) &#123; JSONObject data = new JSONObject(); for(Map.Entry&lt;String, Object&gt; entry : hit.getSource().entrySet()) &#123; data.put(entry.getKey(), entry.getValue()); &#125; hit.getHighlightFields().forEach((title, frag) -&gt; &#123; String str = &quot;&quot;; for (Text text : frag.getFragments()) &#123; str = str + text.string(); &#125; data.put(title, str); &#125;); list.add(JSON.toJSONString(data)); &#125; &#125; return list; &#125; 测试1234567@org.junit.Test public void testquery()&#123; List&lt;String&gt; haha = esProxy.search(&quot;认真&quot;,&quot;眼泪&quot;,&quot;杀猪&quot;); System.out.println(haha.toString()); &#125; //结果 [&#123;&quot;firstName&quot;:&quot;王麻子&quot;,&quot;lastName&quot;:&quot;君君&quot;,&quot;about&quot;:&quot;爱的那么&lt;span style=\&quot;color:red\&quot;&gt;认&lt;/span&gt;&lt;span style=\&quot;color:red\&quot;&gt;真&lt;/span&gt;，不让我的&lt;span style=\&quot;color:red\&quot;&gt;眼&lt;/span&gt;&lt;span style=\&quot;color:red\&quot;&gt;泪&lt;/span&gt;陪我过夜&quot;,&quot;interests&quot;:[&quot;怼人，我是在等待发呆，笨小孩&quot;,&quot;杀猪&quot;,&quot;打豆豆&quot;],&quot;age&quot;:18&#125;, &#123;&quot;firstName&quot;:&quot;王把&quot;,&quot;lastName&quot;:&quot;君君&quot;,&quot;about&quot;:&quot;中华人民共和国体育总局，不让我的&lt;span style=\&quot;color:red\&quot;&gt;眼&lt;/span&gt;&lt;span style=\&quot;color:red\&quot;&gt;泪&lt;/span&gt;陪我过夜&quot;,&quot;interests&quot;:[&quot;怼人，我是在等待发呆，笨小孩&quot;,&quot;杀猪&quot;,&quot;打豆豆&quot;],&quot;age&quot;:18&#125;]]]></content>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch实现中文分词和拼音分词混合查询+CompletionSuggestion]]></title>
    <url>%2F2018%2F01%2F14%2Felasticsearch%E5%AE%9E%E7%8E%B0%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%92%8C%E6%8B%BC%E9%9F%B3%E5%88%86%E8%AF%8D%E6%B7%B7%E5%90%88%E6%9F%A5%E8%AF%A2-CompletionSuggestion%2F</url>
    <content type="text"><![CDATA[引言之前已经介绍了如何搭建elasticsearch服务端和简单的索引创建，和中文分词的支持。今天我们来说一说如何实现elasticsearch同时实现中文分词和pinyin分词。并且实现类似百度搜索栏的搜索建议的功能。 混合查询实现混合查询有很多方式，这里介绍我认为是一个偷懒的方法，就是为你要拼音搜索的字段提供两个额外的字段，一个是全拼字段，一个是首字母缩写字段。我这里用的是官网的Employee的例子：1234567891011public class Employee implements Serializable &#123; private String firstName; private String lastName; private String pinyin;//firstName全拼 private String header;//firstName首字母缩写 private int age; private String about; private List&lt;String&gt; interests; ....省略getter setter 接下来为index添加setting和mapping123456789101112131415161718192021222324252627282930313233343536373839404142434445XContentBuilder settings = XContentFactory.jsonBuilder(); settings.startObject() .startObject(&quot;analysis&quot;) .startObject(&quot;analyzer&quot;) .startObject(&quot;ik_analyzer&quot;).field(&quot;tokenizer&quot;,&quot;ik_smart&quot;) .endObject() .endObject() .endObject().endObject(); CreateIndexRequest createIndexRequest = new CreateIndexRequest(index).settings(settings); CreateIndexResponse createIndexResponse = esClient.admin().indices().create(createIndexRequest).get(); logger.info(&quot;Index:&#123;&#125; created,response:&#123;&#125;&quot;, index, JSON.toJSON(createIndexResponse)); XContentBuilder builder = XContentFactory.jsonBuilder(); builder.startObject() .startObject(type) .startObject(&quot;properties&quot;) .startObject(&quot;firstName&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) /* .field(&quot;search_analyzer&quot;,&quot;ik_smart&quot;).field(&quot;preserve_separators&quot;,false) .field(&quot;preserve_position_increments&quot;,false)*/ .endObject() .startObject(&quot;lastName&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) .endObject() .startObject(&quot;pinyin&quot;).field(&quot;type&quot;,&quot;string&quot;).field(&quot;analyzer&quot;,&quot;pinyin&quot;) .startObject() .startObject(&quot;header&quot;).field(&quot;type&quot;,&quot;string&quot;).field(&quot;analyzer&quot;,&quot;pinyin&quot;) .startObject(&quot;about&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) .endObject() .startObject(&quot;interests&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) .endObject() .endObject() .endObject() .endObject(); PutMappingRequest putMappingRequest = new PutMappingRequest(index); putMappingRequest.type(type); putMappingRequest.source(builder); PutMappingResponse putMappingResponse = esClient.admin().indices().putMapping(putMappingRequest).get(); logger.info(&quot;Mapping for `&#123;&#125;.&#123;&#125;` putted, response:&#123;&#125;&quot;, index, type, JSON.toJSON(putMappingResponse)); return true; &#125; catch (Exception e) &#123; logger.error(&quot;doCreateIndex&quot;, e); return false; &#125; 添加几个测试用例，我这里直接用了批量插入索引的方法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public Boolean bulkIndex(List&lt;String&gt; jsonList)&#123; if(esIndexTypes.get(index)==null) &#123; if(getMapping(index, indexType)) esIndexTypes.put(index,true); &#125; BulkRequestBuilder bulkBuilder= esClient.prepareBulk(); for (String s : jsonList) &#123; IndexRequestBuilder requestBuilder = esClient.prepareIndex(index, indexType) .setSource(s); bulkBuilder.add(requestBuilder); &#125; BulkResponse bulkResponse = bulkBuilder.execute().actionGet(); logger.info(&quot;index:&#123;&#125; bulk request,:response:&#123;&#125;&quot;,index,JSON.toJSON(bulkResponse)); return true;&#125;@org.junit.Testpublic void test()&#123; List&lt;String&gt; list1 = new ArrayList&lt;&gt;(10000); for (int i=0;i&lt;10000;i++) &#123; Employee employee = new Employee(); employee.setFirstName(&quot;告白气球&quot;+i); employee.setPinyin(&quot;gaobaiqiqiu&quot;+i); employee.setHeader(&quot;gbqq&quot;); employee.setLastName(&quot;周杰伦,日记&quot;); employee.setAbout(&quot;呜啦啦啦火车笛\n&quot; + &quot;\n&quot; + &quot;随着奔腾的马蹄\n&quot; + &quot;\n&quot; + &quot;小妹妹吹着口琴\n&quot; + &quot;\n&quot; + &quot;夕阳下美了剪影\n&quot; + &quot;\n&quot; + &quot;我用子弹写日记,我泡妞看电影&quot;); employee.setAge(18); List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;喜欢打篮球&quot;); list.add(&quot;在大晴天晒太阳&quot;); list.add(&quot;泡妞看电影&quot;); employee.setInterests(list); list1.add(JSON.toJSONString(employee)); &#125; boolean index = esProxy.bulkIndex(list1);&#125; 最后直接搜gaobaiqiqiu或gbqq搜出来的数据像这样：1[&#123;&quot;firstName&quot;:&quot;告白气球&quot;,&quot;lastName&quot;:&quot;周杰伦,日记&quot;,&quot;pinyin&quot;:&quot;gaobaiqiqiu&quot;,&quot;about&quot;:&quot;呜啦啦啦火车笛\n\n随着奔腾的马蹄\n\n小妹妹吹着口琴\n\n夕阳下美了剪影\n\n我用子弹写日记,我泡妞看电影&quot;,&quot;header&quot;:&quot;gbqq&quot;,&quot;interests&quot;:[&quot;喜欢打篮球&quot;,&quot;在大晴天晒太阳&quot;,&quot;泡妞看电影&quot;],&quot;age&quot;:18&#125;] 如果直接搜告白搜出来的数据像这样:1[&#123;&quot;firstName&quot;:&quot;&lt;span style=\&quot;color:red\&quot;&gt;告白&lt;/span&gt;气球&quot;,&quot;lastName&quot;:&quot;周杰伦,日记&quot;,&quot;pinyin&quot;:&quot;gaobaiqiqiu&quot;,&quot;about&quot;:&quot;呜啦啦啦火车笛\n\n随着奔腾的马蹄\n\n小妹妹吹着口琴\n\n夕阳下美了剪影\n\n我用子弹写日记,我泡妞看电影&quot;,&quot;header&quot;:&quot;gbqq&quot;,&quot;interests&quot;:[&quot;喜欢打篮球&quot;,&quot;在大晴天晒太阳&quot;,&quot;泡妞看电影&quot;],&quot;age&quot;:18&#125;] CompletionSuggestion查询建议使用CompletionSuggestion时mapping需要改一下，实时推荐的字段type需要使用completion。1234567891011121314151617181920XContentBuilder builder = XContentFactory.jsonBuilder(); builder.startObject() .startObject(type) .startObject(&quot;properties&quot;) .startObject(&quot;firstName&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) .field(&quot;search_analyzer&quot;,&quot;ik_smart&quot;).field(&quot;preserve_separators&quot;,false) .field(&quot;preserve_position_increments&quot;,false) .endObject() .startObject(&quot;lastName&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) .endObject() .startObject(&quot;pinyin&quot;).field(&quot;type&quot;,&quot;string&quot;).field(&quot;analyzer&quot;,&quot;pinyin&quot;) .startObject() .startObject(&quot;header&quot;).field(&quot;type&quot;,&quot;string&quot;).field(&quot;analyzer&quot;,&quot;pinyin&quot;) .startObject(&quot;about&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) .endObject() .startObject(&quot;interests&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) .endObject() .endObject() .endObject() .endObject(); 查询的时候需要使用CompletionSuggestionBuilder.123456789101112131415161718192021public void searchSuggest(String str)&#123; CompletionSuggestionBuilder suggestionBuilder = new CompletionSuggestionBuilder(&quot;firstName&quot;); suggestionBuilder.analyzer(&quot;ik_smart&quot;); suggestionBuilder.text(str); SearchResponse response = esClient.prepareSearch(index).setTypes(indexType).setQuery(QueryBuilders.matchAllQuery()) .suggest(new SuggestBuilder().addSuggestion(&quot;my-suggest-1&quot;,suggestionBuilder)).get(); Suggest suggest= response.getSuggest(); CompletionSuggestion suggestion = suggest.getSuggestion(&quot;my-suggest-1&quot;); List&lt;CompletionSuggestion.Entry&gt; list = suggestion.getEntries(); for (int i = 0; i &lt; list.size(); i++) &#123; List&lt;CompletionSuggestion.Entry.Option&gt; options = list.get(i).getOptions(); for (int j = 0; j &lt; options.size(); j++) &#123; if (options.get(j) instanceof CompletionSuggestion.Entry.Option) &#123; CompletionSuggestion.Entry.Option op = options.get(j); System.out.println(op.getScore()+&quot;--&quot;+op.getText()); &#125; &#125; &#125; &#125; 你也可以使用restAPI：http://192.168.10.xxx:9200/megacorp/_search?pretty这里megacorp是indexName,12345678910&#123; &quot;size&quot;: 0, &quot;suggest&quot;: &#123; &quot;my-suggest-1&quot;: &#123; &quot;prefix&quot;: &quot;someone li&quot;, &quot;completion&quot;: &#123; &quot;field&quot;: &quot;firstName&quot; &#125; &#125; &#125;&#125; 查询出来的结果:12345678910111213141516171819202122232425262728293031323334353637383940414243&#123; &quot;took&quot;: 12, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 0, &quot;max_score&quot;: 0, &quot;hits&quot;: [] &#125;, &quot;suggest&quot;: &#123; &quot;blog-suggest&quot;: [ &#123; &quot;text&quot;: &quot;someone li&quot;, &quot;offset&quot;: 0, &quot;length&quot;: 10, &quot;options&quot;: [ &#123; &quot;text&quot;: &quot;someone like you&quot;, &quot;_index&quot;: &quot;megacorp&quot;, &quot;_type&quot;: &quot;employee&quot;, &quot;_id&quot;: &quot;AV_doqcXKY206Vs3lcCO&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;about&quot;: &quot;呜啦啦啦火车笛\n\n随着奔腾的马蹄\n\n小妹妹吹着口琴\n\n夕阳下美了剪影\n\n我用子弹写日记,我泡妞看电影&quot;, &quot;age&quot;: 18, &quot;firstName&quot;: &quot;someone like you&quot;, &quot;interests&quot;: [ &quot;喜欢打篮球&quot;, &quot;在大晴天晒太阳&quot;, &quot;泡妞看电影&quot; ], &quot;lastName&quot;: &quot;周杰伦,日记&quot; &#125; &#125; ] &#125; ] &#125;&#125;]]></content>
      <tags>
        <tag>elasticsearch,CompletionSuggestion</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot启动流程]]></title>
    <url>%2F2017%2F09%2F21%2Fspring-boot%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[引言早在15年的时候就开始用spring boot进行开发了，然而一直就只是用用，并没有深入去了解spring boot是以什么原理怎样工作的，说来也惭愧。今天让我们从spring boot启动开始，深入了解一下spring boot的工作原理。 为什么用spring boot在使用一个东西或者一个工具之前，我们总是会问自己，我为什么要用？用他能给我带来什么好处？ 最大的好处就是spring boot遵从了java约定大于配置不用面对一大堆的配置文件，spring boot是根据你用的包来决定提供什么配置。 服务器以jar包的形式内嵌于项目中，对于微服务满天飞的情况，spring boot天生适合微服务架构，方便部署。 提供devtools从此改代码就需重启成为历史。 ​ 有优点就一定有缺点，缺点来源于优点优点来源于缺点（感觉在说哲学问题了哈哈哈） 正因为配置对开发者不透明，不看源码会不清楚spring boot如何进行诸如JDBC加载、事务管理等，出现错误也很难调错。 自动配置之后要自定义配置需编码javaConfig，需要了解这些配置类api。 版本迭代太快，新版本对老版本改动太多导致不兼容，比如1.3.5之前的springBootTest和1.4.0之后的springBootTest。 只有合适的架构才是最好的架构如果能接受spring boot这些缺点，spring boot确实是一个可以提高开发效率的不错的选择。 启动流程扯了这么多，该上正题了，让我们来看看spring boot是怎样启动和启动做了哪些事情。 以下代码是spring boot项目标准的启动方式，使用注解@SpringBootApplication并且在main方法中调用SpringApplication的run方法，就可以完成。我们就从这个run方法开始看看spring boot的启动过程。12345678@SpringBootApplicationpublic class Application &#123; public static void main(String[] args)&#123; SpringApplication.run(Application.class,args); &#125;&#125; 我们进入run方法，可以看到最终是调用了 new SpringApplication(sources).run(args);new SpringApplication(sources).run(args); 这个方法，可以看到，springBoot的启动可以分为两个部分，第一部分：SpringApplication的实例化；第二部分：调用该实例运行run方法。我们先来看看这个SpringApplication的实例化过程。1234567891011121314private void initialize(Object[] sources) &#123; if (sources != null &amp;&amp; sources.length &gt; 0) &#123; this.sources.addAll(Arrays.asList(sources)); &#125; //判定是否为webEnvironment this.webEnvironment = deduceWebEnvironment(); //实例化并加载所有可以加载的ApplicationContextInitializer setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); //实例化并加载所有可以加载的ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); &#125; 关键点在两个set方法上setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)) 和 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)) 这两个方法一毛一样，挑实例化ApplicationContextInitializer讲一讲。123456789101112131415private &lt;T&gt; Collection&lt;? extends T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; //拿到类加载器 ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); // Use names and ensure unique to protect against duplicates //使用loadFactoryNames方法载入所有的ApplicationContextInitializer的类全限定名 Set&lt;String&gt; names = new LinkedHashSet&lt;String&gt;( SpringFactoriesLoader.loadFactoryNames(type, classLoader)); //使用反射将所有的ApplicationContextInitializer实例化 List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); //排序 AnnotationAwareOrderComparator.sort(instances); return instances; &#125; 自动配置的关键就是这个 getSpringFactoriesInstances方法,确切的说是这个方法里的loadFactoryNames方法，浪我们看看这个loadFactoryNames方法干了啥，咋就能实现自动配置。12345678910111213141516171819public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, ClassLoader classLoader) &#123; String factoryClassName = factoryClass.getName(); try &#123; Enumeration&lt;URL&gt; urls = classLoader != null?classLoader.getResources(&quot;META-INF/spring.factories&quot;):ClassLoader.getSystemResources(&quot;META-INF/spring.factories&quot;); ArrayList result = new ArrayList(); while(urls.hasMoreElements()) &#123; URL url = (URL)urls.nextElement(); Properties properties = PropertiesLoaderUtils.loadProperties(new UrlResource(url)); String factoryClassNames = properties.getProperty(factoryClassName); result.addAll(Arrays.asList(StringUtils.commaDelimitedListToStringArray(factoryClassNames))); &#125; return result; &#125; catch (IOException var8) &#123; throw new IllegalArgumentException(&quot;Unable to load [&quot; + factoryClass.getName() + &quot;] factories from location [&quot; + &quot;META-INF/spring.factories&quot; + &quot;]&quot;, var8); &#125;&#125; 可以看到这个方法就做了一件事，就是从META-INF/spring.factories这个路径取出所有”url”来，我们可以去到这个路径下看看到底是些啥？1234567# Initializersorg.springframework.context.ApplicationContextInitializer=\org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer# Application Listenersorg.springframework.context.ApplicationListener=\org.springframework.boot.autoconfigure.BackgroundPreinitializer 这下大家都应该明白了，spring是通过将所有你加载的jar包中找到它需要的ApplicationContextInitializer来进行动态的配置的，只要你有用到特定的maven包，初始化的时候会找这个包下的META-INF/spring.factories的需要的类比如ApplicationContextInitializer进行实例化bean，你就可以用了，不需要任何配置。说到这已经将所有SpringApplication实例化说完了，只是在加载完ApplicationContextInitializer和ApplicationListener这之后还有一步，就是找到启动类所在的位置并且设入属性mainApplicationClass中。 接下来让我们回到new SpringApplication(sources).run(args)方法来看看run方法是怎么run的。1234567891011121314151617181920212223242526272829303132333435363738public ConfigurableApplicationContext run(String... args) &#123; //开启启动计时器，项目启动完会打印执行时间出来 StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); //获取SpringApplicationRunListener并启动监听器 SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); //环境变量的加载 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); //启动后console的打印出来的一堆配置信息 Banner printedBanner = printBanner(environment); //终极大boss-&gt;ApplicationContext实例化 context = createApplicationContext(); analyzers = new FailureAnalyzers(context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125; &#125; 从这个方法里面做的最关键的三件事情就是： 获取监听器并启动 加载环境变量，该环境变量包括system environment、classpath environment和用户自己加的application.properties 创建ApplicationContext 12345678910111213141516171819202122232425private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); postProcessApplicationContext(context); applyInitializers(context); listeners.contextPrepared(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // Add boot specific singleton beans context.getBeanFactory().registerSingleton(&quot;springApplicationArguments&quot;, applicationArguments); if (printedBanner != null) &#123; context.getBeanFactory().registerSingleton(&quot;springBootBanner&quot;, printedBanner); &#125; // Load the sources Set&lt;Object&gt; sources = getSources(); Assert.notEmpty(sources, &quot;Sources must not be empty&quot;); load(context, sources.toArray(new Object[sources.size()])); listeners.contextLoaded(context); &#125; 前两点没什么好说的，重点说说第三个，创建ApplicationContext。创建applicationContext又分为几部：实例化applicationContext、prepareContext、refreshContext。实例化applicationContext会根据在之前我们说的webEnvironment这个属性判断是使用webContext类AnnotationConfigEmbeddedWebApplicationContext还是普通context类AnnotationConfigApplicationContext（在这里我们使用的是webContext为例）然后通过反射进行实例化。applicationContext实例化完了会进入prepareContext流程，这个prepareContext方法会加载之前准备好的environment进入context中，然后如果有beanNameGenerator和resourceLoader那么提前创建bean加载进applicationContext，但是一般这两个都是空的，所以直接进入applyInitializers方法，将之前实例化的所有initializers进行初始化，所有的bean就是在这里进行bean的扫描和加载的因这次讲的是启动过程，所以不再细讲。最后把创建好的applicationContext设置进入listener，prepareContext过程就结束了。最后是refreshContext，这个就和spring的bean加载过程一致了，bean的注入、beanFactory、postProcessBeanFactory等等，详情可以去看看spring bean的生命周期。 总结spring boot 初始化内容还是很多的，但是总结起来就四点： 创建SpringApplication实例，判定环境，是web环境还是普通环境。加载所有需要用到的Initializers和Listeners，这里使用约定大于配置的理念揭开了自动配置的面纱。 加载环境变量，环境变量包括system environment、classpath environment、application environment（也就是我们自定义的application.properties配置文件） 创建SpringApplicationRunListeners 创建ApplicationContext，设置装配context，在这里将所有的bean进行扫描最后在refreshContext的时候进行加载、注入。最终将装配好的context作为属性设置进SpringApplicationRunListeners，这就完成了一个spring boot项目的启动。]]></content>
      <tags>
        <tag>spring boot,源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch5.x服务器搭建]]></title>
    <url>%2F2017%2F06%2F21%2Felasticsearch5-x%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[引言之前与搜索有关的需求都是使用solrCloud实现的，最近公司在做日志监控的时候使用并没有用solr而是使用了好评更甚的elasticsearch。之前本来就一直想了解es，现在刚好有机会学习，特此记录下学习的过程。 what is elasticsearchelasticsearch（以下使用缩写es代替）是一个基于lucene的分布式、近实时的全文搜索引擎。它还是一个分布式非关系型数据库，被es存储的json数据每个字段都会被索引且可被搜索，并且es可以轻松的存储和处理达pb级别的数据。 服务环境搭建首先准备好elasticsearch按照包我用的是当时最新版5.3.0。1elasticsearch-5.3.0.tar.gz 解压，因本人机器性能有限，并没有用上集群，使用默认设置直接启动。需要注意的是elasticsearch不允许root权限进行启动，所以需要创建一个单独用户来运行。123456adduser elastic -g elastic -p elasticgroupadd elastictar -zvxf elasticsearch-5.3.0.tar.gz chown -R elastic:elastic elasticsearch-5.3.0 使用默认配置启动elasticsearch 1./elasticsearch-5.3.0/bin/elasticsearch 当看到以下日志时就说明启动成功123456789101112131415161718[2017-06-21T04:42:29,857][INFO ][o.e.n.Node ] initialized[2017-06-21T04:42:29,857][INFO ][o.e.n.Node ] [vQCqom0] starting ...[2017-06-21T04:42:30,305][INFO ][o.e.t.TransportService ] [vQCqom0] publish_address &#123;192.168.10.133:9300&#125;, bound_addresses &#123;[::]:9300&#125;[2017-06-21T04:42:30,333][INFO ][o.e.b.BootstrapChecks ] [vQCqom0] bound or publishing to a non-loopback or non-link-local address, enforcing bootstrap checks[2017-06-21T04:42:33,430][INFO ][o.e.c.s.ClusterService ] [vQCqom0] new_master &#123;vQCqom0&#125;&#123;vQCqom0yQMypwf2VdeS4cw&#125;&#123;8_zAvAFORVK2GCS-3N0CNQ&#125;&#123;192.168.10.133&#125;&#123;192.168.10.133:9300&#125;, reason: zen-disco-elected-as-master ([0] nodes joined)[2017-06-21T04:42:33,508][INFO ][o.e.h.n.Netty4HttpServerTransport] [vQCqom0] publish_address &#123;192.168.10.133:9200&#125;, bound_addresses &#123;[::]:9200&#125;[2017-06-21T04:42:33,521][INFO ][o.e.n.Node ] [vQCqom0] started[2017-06-21T04:42:33,651][INFO ][o.w.a.d.Monitor ] try load config from /elastic/elasticsearch-5.3.0/config/analysis-ik/IKAnalyzer.cfg.xml[2017-06-21T04:42:33,653][INFO ][o.w.a.d.Monitor ] try load config from /elastic/elasticsearch-5.3.0/plugins/ik/config/IKAnalyzer.cfg.xml[2017-06-21T04:42:35,023][INFO ][o.e.m.j.JvmGcMonitorService] [vQCqom0] [gc][young][5][9] duration [985ms], collections [1]/[1.1s], total [985ms]/[4.2s], memory [76.5mb]-&gt;[65.7mb]/[1.9gb], all_pools &#123;[young] [49mb]-&gt;[221.7kb]/[66.5mb]&#125;&#123;[survivor] [8.3mb]-&gt;[8.3mb]/[8.3mb]&#125;&#123;[old] [19.1mb]-&gt;[57.4mb]/[1.9gb]&#125;[2017-06-21T04:42:35,023][WARN ][o.e.m.j.JvmGcMonitorService] [vQCqom0] [gc][5] overhead, spent [985ms] collecting in the last [1.1s][2017-06-21T04:42:35,209][INFO ][o.w.a.d.Monitor ] [Dict Loading] custom/mydict.dic[2017-06-21T04:42:35,236][INFO ][o.w.a.d.Monitor ] [Dict Loading] custom/single_word_low_freq.dic[2017-06-21T04:42:35,261][INFO ][o.w.a.d.Monitor ] [Dict Loading] custom/ext_stopword.dic[2017-06-21T04:42:35,538][INFO ][o.e.g.GatewayService ] [vQCqom0] recovered [2] indices into cluster_state[2017-06-21T04:42:36,324][INFO ][o.e.c.r.a.AllocationService] [vQCqom0] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[megacorp][2]] ...]).[2017-06-21T04:43:04,255][INFO ][o.e.m.j.JvmGcMonitorService] [vQCqom0] [gc][young][34][10] duration [728ms], collections [1]/[1.1s], total [728ms]/[4.9s], memory [131.6mb]-&gt;[90.2mb]/[1.9gb], all_pools &#123;[young] [65.9mb]-&gt;[145kb]/[66.5mb]&#125;&#123;[survivor] [8.3mb]-&gt;[8.3mb]/[8.3mb]&#125;&#123;[old] [57.4mb]-&gt;[81.8mb]/[1.9gb]&#125;[2017-06-21T04:43:04,255][WARN ][o.e.m.j.JvmGcMonitorService] [vQCqom0] [gc][34] overhead, spent [728ms] collecting in the last [1.1s] 错误集锦与处理ERROR: bootstrap checks failed 具体报错信息为：max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]max number of threads [1024] for user [lishang] likely too low, increase to at least [2048] 意思就是文件描述符至少需要65536个，线程数至少需要2048个。 解决方法：切换到root用户，进入到security目录下的limits.conf1vim /etc/security/limits.conf 文件末尾追加一下数据1234567* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096 重启生效 max number of threads [1024] for user [lish] likely too low, increase to at least [2048] 解决方法：切换到root用户，进入limits.d目录下修改配置文件。12345vim /etc/security/limits.d/90-nproc.conf将这一行* soft nproc 1024改为* soft nproc 2048 max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144] 解决方法：切换到root用户修改配置sysctl.conf1vim /etc/sysctl.conf 文件后面追加一下配置：1vm.max_map_count=655360 执行命令1sysctl -p]]></content>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中如何正确使用volatile]]></title>
    <url>%2F2017%2F04%2F16%2Fjava%E4%B8%AD%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E4%BD%BF%E7%94%A8volatile%2F</url>
    <content type="text"><![CDATA[引言对于java开发同学来说，说到多线程首先想到的就是队列、synchronized、lock等等，就这几个东西就够说好几个文章的篇幅了，今天我们主角并不是它们，而是并不太受欢迎的volatile。很多开发同学可能一碰到多线程变量共享问题直接上锁，当然这样做也是无可以厚非，毕竟木有用错，只能说这样编码不是那么的优雅，如果说能使用锁和volatile配合使用无论对性能也好还是对java语言的理解也都是很有帮助的。volatile关键字在java多线程中有着比较重要作用，volatile主要作用是可以保持变量在多线程中是实时可见的,是java中提供的最轻量的同步机制。 可见性在Java的内存模型中所有的的变量（这里的变量是类全局变量，并不是局部变量，局部变量在方法内并没有线程安全的问题，因为变量随方法调用完成而销毁）都是存放在主内存中的，而每个线程有自己的工作内存，每次线程执行时，会从主内存获取变量的拷贝，对变量的操作都在线程的工作内存中进行，不同线程之间也不能共享工作内存，只能从主内存读取变量的拷贝。具体可以通过下图来表示： 然而对于volatile（使用synchronized/final修饰都具有可见性）来说打破了上述的规则，即当线程修改了变量的值，其他线程可以立即知道该变量的改变。然而对于普通变量来说，当一个线程修改了变量，需要先将变量写回主内存，其他线程从主内存读取变量后才对该线程可见。似乎从以上的描述可以推导出只要使用volatile修饰的变量就可以保证该变量在多线程环境下操作是安全的，因为它对于所有线程的工作内存都是可见的也就是说一致的。这么理解确实没错，但是在java中很多运算都不是原子的，所以在java的一些运算中使用volatile并不能保证线程安全问题。让我们来看一个例子：12345678910111213141516171819202122232425public class test&#123;private static volatile t=0; private static int add()&#123; return t++; &#125; public static void testVolatile()&#123; for (int i=0;i&lt;20;i++)&#123; Thread thread=new Thread(()-&gt; &#123; for (int j=0;j&lt;1000;j++) &#123; add(); &#125; &#125;); thread.start(); &#125; while (Thread.activeCount()&gt;1)&#123; Thread.yield(); &#125; System.out.println(t); &#125; public static void main(String[] args)&#123; testVolatile(); &#125;&#125; 预期这个t值应该是20000，但是会出现t值小于20000的情况，原因大家应该猜到了，问题出在t++上，t++并不是一个原子操作，t++的操作在java中代表先获取t值，再加1，再赋值还t。在获取t值时因为是volatile修饰的，所以可以获取线程最新值，然而在加1的时候就不能保证了，有可能其他线程已经加1了。 使用场景那么什么场景使用volatile是最合适的呢？ 在变量运算不依赖当前值 变量不需要与其他状态变量共同参与不变约束翻译成中文就是对于那些在多线程中既有读又有写的变量，完全可以使用volatile修饰，这样就对于读操作就不要使用lock/synchronized比较重的操作了，直接读就是，因为变量是可见的。]]></content>
      <tags>
        <tag>volatile,多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring boot学习之调用dubbo]]></title>
    <url>%2F2016%2F12%2F07%2FSpring-boot%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B0%83%E7%94%A8dubbo%2F</url>
    <content type="text"><![CDATA[Spring boot好早之前就有在用，但是都是用Spring boot建简单的web站点，很多Spring boot其他特性的使用都处于未知状态，最近又开始使用Spring boot开发，特此记录。 使用@Import注解引入配置文件Spring boot最好用的一点就是自动配置，约定大于配置的特性让我们减少了很多配置工作，但是有很多情况下是不能自动配置的，比如dubbo就没有，所以dubbo的引入依旧需要配置文件，Spring boot要使配置文件生效需要引入配置文件，引入方式如下：12345678@SpringBootApplication@Import(&quot;classpath:*.xml&quot;)public class App&#123; public static void main(String[] args)&#123; SpringApplication.run(App.class,args); &#125;&#125; 使用CommandLineRunner接口在开发时经常会有在项目启动后就初始化模块、或者执行一次的需求，这时CommandLineRunner就是一个很好的选择，该接口有run()方法当实现了CommandLineRunner接口,项目启动之后会首先执行run方法。例如：123456789@Componentpublic class StartupRunner implements CommandLineRunner &#123; protected final Logger logger = LoggerFactory.getLogger(StartupRunner.class); @Override public void run(String... strings) throws Exception &#123; logger.info(&quot;you are invoke this method!&quot;); &#125;&#125;]]></content>
      <tags>
        <tag>Spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用spring方式引入外部文件]]></title>
    <url>%2F2016%2F11%2F18%2F%E4%BD%BF%E7%94%A8spring%E6%96%B9%E5%BC%8F%E5%BC%95%E5%A6%82%E5%A4%96%E9%83%A8%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[在很多业务场景下我们都需要引入外部文件，比如大量的静态json、业务模板、xml文件等，大量的外部文件引入如果方式不正确很有可能会导致系统性能问题，今天我们就说说如何使用优雅的方式引入外部文件。 传统引入方式一般我们引入外部文件都是通过IO流的方式引入，每次使用都要从硬盘读到内存中。代码如下：12345678910111213public String readFile()&#123; File file=new File(&quot;test.txt&quot;); BufferedReader reader=new BufferedReader(new InputStreamReader(new FileInputStream(file))); StringBuffer sb=new StringBuffer(); String temp=null; while((temp=reader.readLine())!=null)&#123; sb.append(temp); &#125; reader.close(); &#125; 该代码缺陷在于，每用一次就要从硬盘读取到内存，性能着急，这样的代码是不行的。 使用spring方式如果系统中使用来spring框架，那么你可以优雅的使用spring来引入外部文件，spring自带有resource解析器Resource可以在项目启动时加载静态资源。我们可以定义一个专门的BeanResourceResolver来加载外部文件，代码如下：123456789101112131415161718192021222324252627282930313233public class ResourceResolver &#123; private Resource resource; private String transforStr; @PostConstruct public void readFile()throws IOException&#123; File file=resource.getFile(); BufferedReader reader=new BufferedReader(new InputStreamReader(new FileInputStream(file))); StringBuffer sb=new StringBuffer(); String temp=null; while((temp=reader.readLine())!=null)&#123; sb.append(temp); &#125; reader.close(); this.transforStr=sb.toString(); &#125; public String getTransforStr() &#123; return transforStr; &#125; public void setTransforStr(String transforStr) &#123; this.transforStr = transforStr; &#125; public Resource getResource() &#123; return resource; &#125; public void setResource(Resource resource) &#123; this.resource = resource; &#125;&#125; 在spring配置文件中配置：123&lt;bean id=&quot;resourceResolver&quot; class=&quot;com.ifenqu.bean.ResourceResolver&quot;&gt; &lt;property name=&quot;resource&quot; value=&quot;classpath:test.txt&quot;&gt;&lt;/property&gt; &lt;/bean&gt; 相对于第一种实现方式，使用spring的方式只需要在项目加载的时候执行一次从磁盘加载到内存操作就行，该方式更佳优雅。]]></content>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC源码分析之Handler请求映射与调用]]></title>
    <url>%2F2016%2F10%2F30%2FpageSpringMVC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BHandler%E8%AF%B7%E6%B1%82%E6%98%A0%E5%B0%84%E4%B8%8E%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[在前两篇说了springMVC的初始化和HandlerMapping，接下来我们用最后一篇说说handler被映射和调用的过程。在说过初始化和HandlerMapping的注册过程后，springMVC的映射和调用就很简单了。 请求映射Handler当一个请求发出后，比如我们发出一个”http://localhost:8080/pay/payment&quot;的请求，springMVC会先将路径封装到HttpServletRequest中，而spring容器会通过getHandler方法来通过路径找到上一篇说的已经注册好的HandlerMapping。请看如下代码：123456789101112131415161718192021222324252627protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // 找到当前请求的handler. mappedHandler = getHandler(processedRequest); if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; //未找到handler抛出异常 noHandlerFound(processedRequest, response); return; &#125; // 找到handler之后，为该handler匹配正确的适配器 HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());................截取部分代码 通过request来匹配当前已经注册了的handlerMapping，再通过handlerMapping来获取handler。123456789101112protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; for (HandlerMapping hm : this.handlerMappings) &#123; if (logger.isTraceEnabled()) &#123; logger.trace( &quot;Testing handler map [&quot; + hm + &quot;] in DispatcherServlet with name &apos;&quot; + getServletName() + &quot;&apos;&quot;); &#125; HandlerExecutionChain handler = hm.getHandler(request); if (handler != null) &#123; return handler; &#125; &#125; return null; 从下面的代码来看，spring容器是通过request封装的请求路径lookupPath来找到handler的，并且也是通过lookupPath来找到handler的handlerMethod的，代码就不重复贴了。12345678910111213141516171819202122protected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception &#123; String lookupPath = getUrlPathHelper().getLookupPathForRequest(request); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Looking up handler method for path &quot; + lookupPath); &#125; this.mappingRegistry.acquireReadLock(); try &#123; HandlerMethod handlerMethod = lookupHandlerMethod(lookupPath, request); if (logger.isDebugEnabled()) &#123; if (handlerMethod != null) &#123; logger.debug(&quot;Returning handler method [&quot; + handlerMethod + &quot;]&quot;); &#125; else &#123; logger.debug(&quot;Did not find handler method for [&quot; + lookupPath + &quot;]&quot;); &#125; &#125; return (handlerMethod != null ? handlerMethod.createWithResolvedBean() : null); &#125; finally &#123; this.mappingRegistry.releaseReadLock(); &#125; &#125; 在找到handler之后返回的并不是仅仅是handler，而是HandlerExecutionChain，这一招应该是借鉴了struts的优良责任链模式，在handler的处理前后还有可能有多个处理逻辑，这其中包括各种拦截器或者其他的handler处理。 handler调用handler获取之后接下来就是获取对应的adapter，在这使用的是适配器模式，在springMVC中有各种类型的controller bean，你比如使用注解的不使用注解的。为了方便扩展，spring容器使用适配器模式来对应不同controller调用，也就是通过实现adapter接口同时组合该handler来实现不同handler使用统一的调用方式。获取adapter的方式和获取handler的方式差不多，这里就不展开讲。接下来也就是最后的一步–调用handler。调用handler主要三步，第一获取解析器，第二步获取具体方法，第三部反射调用方法并返回结果封装到ModelAndView中最终返回，详情看下面代码：123456789101112131415161718protected ModelAndView invokeHandlerMethod(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //获取方法解析器 ServletHandlerMethodResolver methodResolver = getMethodResolver(handler); //通过方法解析器通过request的url来调用具体方法 Method handlerMethod = methodResolver.resolveHandlerMethod(request); ServletHandlerMethodInvoker methodInvoker = new ServletHandlerMethodInvoker(methodResolver); ServletWebRequest webRequest = new ServletWebRequest(request, response); ExtendedModelMap implicitModel = new BindingAwareModelMap(); //调用具体方法返回结果 Object result = methodInvoker.invokeHandlerMethod(handlerMethod, handler, webRequest, implicitModel); //将结果封装到modelAndView中结果返回 ModelAndView mav = methodInvoker.getModelAndView(handlerMethod, handler.getClass(), result, implicitModel, webRequest); methodInvoker.updateModelAttributes(handler, (mav != null ? mav.getModel() : null), implicitModel, webRequest); return mav;&#125; 总的来说，springMVC方法调用还是比较简单的，通过请求的mapping路径匹配具体的handler，也就是我们说的controller，找到handler还要将找到对应的适配器，最后才是调用具体方法返回已经被封装成ModelAndView的结果。]]></content>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springMVC源码分析之HandlerMapping请求映射]]></title>
    <url>%2F2016%2F09%2F16%2FspringMVC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BHandlerMapping%E8%AF%B7%E6%B1%82%E6%98%A0%E5%B0%84%2F</url>
    <content type="text"><![CDATA[在上一篇我们说了springMVC的初始化，作为springMVC启动的第一步完成的任务是初始化spring的IoC容器、初始化DispatchServlet的IoC容器，同时将webApplicationContext进行初始化，接下来就是strategy的初始化。这一系列初始化后接下来就是要完成根据url来映射到对应的具体方法并调用到最后返回页面。在接下的的两篇博文中我会分两篇来说说springMVC具体的映射分析。 Handler注册在springMVC中最后一步是初始化strategy，就是初始化各个解析器如HandlerMapping和handlerAdapter。这是springMVC各配件初始化的入口。而initStrategies方法中initHandlerMapping是handlerMapping初始化的入口，该方法逻辑比较简单，首先从ApplicationContext中找到所有的HandlerMapping，如果没有则使用默认的HandlerMapping –DefaultAnnonationHandlerMapping、BeanNameUrlHandlerMapping。具体请看下面源码12345678910111213141516171819202122232425262728293031private void initHandlerMappings(ApplicationContext context) &#123; this.handlerMappings = null; if (this.detectAllHandlerMappings) &#123; //从ApplicationContext中获取所有HandlerMapping包括父Context Map&lt;String, HandlerMapping&gt; matchingBeans = BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerMapping.class, true, false); if (!matchingBeans.isEmpty()) &#123; this.handlerMappings = new ArrayList&lt;HandlerMapping&gt;(matchingBeans.values()); // We keep HandlerMappings in sorted order. AnnotationAwareOrderComparator.sort(this.handlerMappings); &#125; &#125; else &#123; try &#123; HandlerMapping hm = context.getBean(HANDLER_MAPPING_BEAN_NAME, HandlerMapping.class); this.handlerMappings = Collections.singletonList(hm); &#125; catch (NoSuchBeanDefinitionException ex) &#123; // Ignore, we&apos;ll add a default HandlerMapping later. &#125; &#125; //如果handlerMapping为空那么给其初始化默认的handlerMapping if (this.handlerMappings == null) &#123; this.handlerMappings = getDefaultStrategies(context, HandlerMapping.class); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;No HandlerMappings found in servlet &apos;&quot; + getServletName() + &quot;&apos;: using default&quot;); &#125; &#125; &#125; 在该方法中一般如果没有特别配置基本上ApplicationContext中handlerMapping是null，所以都需要调用getDefaultStrategies方法，该方法会将默认的handlerMapping实例化并注册进ApplicationContext中。具体请看以下代码：12345678910111213141516171819202122232425262728293031protected &lt;T&gt; List&lt;T&gt; getDefaultStrategies(ApplicationContext context, Class&lt;T&gt; strategyInterface) &#123; String key = strategyInterface.getName(); //defaultStrategies是一个map，获取的是DispatchServlet.properties的属性，在这里获取的是系统默认的String类型的handlerMapping String value = defaultStrategies.getProperty(key); if (value != null) &#123; String[] classNames = StringUtils.commaDelimitedListToStringArray(value); List&lt;T&gt; strategies = new ArrayList&lt;T&gt;(classNames.length); for (String className : classNames) &#123; try &#123; //通过反射实例化类 Class&lt;?&gt; clazz = ClassUtils.forName(className, DispatcherServlet.class.getClassLoader()); Object strategy = createDefaultStrategy(context, clazz); strategies.add((T) strategy); &#125; catch (ClassNotFoundException ex) &#123; throw new BeanInitializationException( &quot;Could not find DispatcherServlet&apos;s default strategy class [&quot; + className + &quot;] for interface [&quot; + key + &quot;]&quot;, ex); &#125; catch (LinkageError err) &#123; throw new BeanInitializationException( &quot;Error loading DispatcherServlet&apos;s default strategy class [&quot; + className + &quot;] for interface [&quot; + key + &quot;]: problem with class file or dependent class&quot;, err); &#125; &#125; return strategies; &#125; else &#123; return new LinkedList&lt;T&gt;(); &#125; &#125; 该方法就是通过反射将默认的handlerMapping进行实例化并且通过createDefaultStrategy将controller也就是这里handlerMapping中的handler注册到handlerMapping中。而handler的注册是在BeanUrlHandlerMapping的父类AbstractDetectingUrlHandlerMapping中detectHandler实现的，该方法主要逻辑是将所有spring IoC容器初始化的bean进行匹配，查找到该bean的urls不为空我们就认为他是一个handler并通过registerHandler方法进行注册。具体逻辑代码如下：1234567891011121314151617181920212223protected void detectHandlers() throws BeansException &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Looking for URL mappings in application context: &quot; + getApplicationContext()); &#125; String[] beanNames = (this.detectHandlersInAncestorContexts ? BeanFactoryUtils.beanNamesForTypeIncludingAncestors(getApplicationContext(), Object.class) : getApplicationContext().getBeanNamesForType(Object.class)); // Take any bean name that we can determine URLs for. for (String beanName : beanNames) &#123; //获取handler的所有url定义 String[] urls = determineUrlsForHandler(beanName); if (!ObjectUtils.isEmpty(urls)) &#123; // URL paths found: Let&apos;s consider it a handler. registerHandler(urls, beanName); &#125; else &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Rejected bean name &apos;&quot; + beanName + &quot;&apos;: no URL paths identified&quot;); &#125; &#125; &#125; &#125; 最终在registerHandler方法中将url注册进一个HandlerMapping的私有属性handlerMap中，该handlerMap是一个以url为key、handler为value的linkedHashMap。经过以上几个步骤handler注册已经完成了，其中handlerMap是这里面的核心，在handlerMap中配置好了url请求和对应的handler映射，这为springMVC响应http请求做好了基本映射数据的准备。]]></content>
      <tags>
        <tag>springMVC,HandlerMapping</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springMVC源码分析之初始化]]></title>
    <url>%2F2016%2F09%2F04%2FSpringMVC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[springMVC属于SpringFrameWork家族中的一员，目前已经是最流行的和效率最好的MVC框架了，特别是配合spring的bean管理容器使用能让你很优雅的开发WEB应用。从这篇开始本人会从springMVC的初始化、springMVC的Controller调用过程、springMVC的视图解析过程、springMVC拦截器原理来分析源码，而今天就让我们先来领教一下springMVC的初始化吧。 springMVC配置在开始源码分析前，我们先来看看springMVC的配置文件和web.xml的配置方便接下来de分析。首先是spring-servlet.xml（配置文件什么名字都可以）1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd&quot;&gt; &lt;context:annotation-config/&gt; &lt;context:component-scan base-package=&quot;com.ifenqu.controller&quot;/&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot; p:suffix=&quot;.jsp&quot;&gt; &lt;/bean&gt; &lt;/beans&gt; 以上是一个非常简单的demo配置，包括第一个&lt;context:annotation-config&gt;用来声明允许使用注解，第二个&lt;context:component-scan base-package=&quot;com.ifenqu.controller&quot;/&gt;来自动扫描需要注入的bean，第三个&lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot; p:suffix=&quot;.jsp&quot;&gt;&lt;/bean&gt;为返回的view自动加上后缀。接下来是web.xml文件 123456789101112131415161718192021222324&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd&quot; id=&quot;WebApp_ID&quot; version=&quot;3.0&quot;&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;servlet&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-*.xml&lt;/param-value&gt; &lt;/context-param&gt;&lt;/web-app&gt; web.xml没什么好说的，就是将springMVC在web.xml中注册加入各配置文件。接下来看看controller 1234567891011121314151617package com.ifenqu.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;/** * Created by LAIYAO on 2016/9/4. */@Controllerpublic class HelloController &#123; @ResponseBody @RequestMapping(value=&quot;/hello&quot;) public String hello()&#123; return &quot;hello&quot;; &#125;&#125; 初始化springMVC中最核心的就是DispatcherServlet这个类，该类充当前端控制器控制着request的Mapping、handle、viewResolver等。我们看看这个DispatcherServlet类继承体系。如图所示，DispatcherServlet继承于FrameworkServlet，而FrameworkServlet继承于HttpServletBean，最终继承于HttpServlet。 当系统启动时，在web.xml配置的各配置文件被读取最终组成RootWebApplicationContext并初始化IoC容器，紧接着会执行DispatcherServlet持有的IoC容器的初始化，DispatcherServlet初始化包括两个部分，第一，DispatcherServlet持有的子上下文初始化（该上下文对应的是Servlet的上下文，与Web应用的servletContext上下文呈父子关系）和DispatcherServlet其他部分如strategy初始化等，接下来我们看看springMVC的init方法，如下图所示：其中这个PropertyValues是DispatcherServlet的内部静态类,在这一步主要是用来读入从web.xml配置的文件如下图所示：接下来将DispatcherServlet封装了一层并且初始化好资源加载器resourceLoader，这个resourceLoader初始化之后主要是有类似于getResourceAsStream、getRealPath等资源加载的方法的一个Map和classLoader。 接下来就是初始化这个BeanWrapper，然后执行initServletBean方法，这个方法中主要是初始化webApplicationContext。webApplicationContext的初始化是要以RootWebApplicationContext作为参数，通过反射来创建webApplicationContext对象，实例化结束后需要给上下文设置一下基本配置如bean定义的配置文件位置等，双亲上下文（实例化后子上下文会被setAttribute到根上下文，当要获取bean时先进根上下文获取，再去子上下文找），最后通过调用DispatcherServlet的IoC容器的refresh方法完成strategy的初始化，也就是各种解析器、HandlerMapping、适配器等的初始化，为什么是strategy呢，因为在这里使用了策略模式，springMVC中有很多解析器、映射器和适配器以适应不同场合的调用，所以这里使用使用策略模式。如下图所示：我们挑这其中的initHandlerMappings和initHandlerAdapters方法来看看。首先initHandlerMappings，方法如下图所示：初始化HandlerMapping首先会从ApplicationContext中找到所有的HandlerMappings，为保证至少有一个HandlerMapping注册，如果在ApplicationContext中没有找到HandlerMapping，系统会提供默认的HandlerMapping，即BeanNameUrlHandlerMapping和DefaultAnnotionHandlerMapping而initHandlerAdapters方法和initHandlerMappings差不多，或者说是简直一模一样（moji笑哭脸），不过话说回来，HandlerMapping和HandlerAdapter本来就是相同的用途的类用在不同作用域上，HandlerMapping是找到需要请求的bean，而HandlerAdapter则是找到该bean的具体方法并调用，在最初的初始化时期当然是差不多的逻辑。在这一系列的各模块的初始化之后，WebApplicationContext算是初始化结束，同时FrameworkServlet初始化结束。 总结起来，springMVC的初始化过程就三步，第一步：加载配置文件读取配置文件属性，第二步：将配置文件属性和读取servletContext的组成自己的上下文，第三步，调用refresh方法初始化各strategy组件（各种解析器、适配器）,完成WebApplicationContext的初始化，最终完成DispacherServlet持有的IoC容器的初始化。]]></content>
      <tags>
        <tag>springMVC,源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于redis的发布订阅模式]]></title>
    <url>%2F2016%2F08%2F20%2F%E5%9F%BA%E4%BA%8Eredis%E7%9A%84%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[发布订阅模式pub/sub（publish/subscribe）发布订阅模式是基于事件中广泛使用的通信模型，其中subscriber将注册到自己所监听的事件中，只要publisher有消息或者消息改变，所有注册的subscriber就会接收到消息通知。 发布订阅模式应用广泛，各种消息中间件（如rabbitmq，activemq）都是基于该模式开发，同时在zookeeper中的文件配置集中管理功能中就是用了发布订阅模式，而即时聊天也可以使用这种模式。 redis作为高性能的内存数据库也支持pub/sub模式，今天就说说基于redis的发布订阅模式。 准备首先要安装redis，因本人使用win7开发，所以就直接下载了window版redis，地址 redis on windows ,直接解压运行redis.exe就按默认的配置启动。 编码本实例是基于spring的所以获取redis的bean实例都是由spring注入，首先需先配置spring配置文件spring-redis-config.xml12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;context:property-placeholder location=&quot;classpath:application.properties&quot;/&gt;&lt;bean id=&quot;jedisPoolConfig&quot; class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt; &lt;property name=&quot;maxTotal&quot;&gt; &lt;value&gt;$&#123;redis.pool.maxActive&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;maxIdle&quot;&gt; &lt;value&gt;$&#123;redis.pool.maxIdle&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;testOnReturn&quot; value=&quot;true&quot;/&gt;&lt;/bean&gt;&lt;bean id = &quot;jedisPool&quot; class=&quot;redis.clients.jedis.JedisPool&quot;&gt; &lt;constructor-arg index=&quot;0&quot; ref=&quot;jedisPoolConfig&quot;/&gt; &lt;constructor-arg index=&quot;1&quot; value=&quot;$&#123;redis.host&#125;&quot;/&gt; &lt;constructor-arg index=&quot;2&quot; value=&quot;$&#123;redis.port&#125;&quot; type=&quot;int&quot;/&gt; &lt;constructor-arg index=&quot;3&quot; value=&quot;$&#123;redis.timeout&#125;&quot; type=&quot;int&quot;/&gt; &lt;!-- &lt;constructor-arg index=&quot;4&quot; value=&quot;$&#123;redis.password&#125;&quot;/&gt;--&gt;&lt;/bean&gt;&lt;bean id=&quot;jedisConnectionFactory&quot; class=&quot;org.springframework.data.redis.connection.jedis.JedisConnectionFactory&quot; destroy-method=&quot;destroy&quot;&gt; &lt;property name=&quot;poolConfig&quot; ref=&quot;jedisPoolConfig&quot;&gt;&lt;/property&gt; &lt;property name=&quot;hostName&quot; value=&quot;$&#123;redis.host&#125;&quot;&gt;&lt;/property&gt; &lt;property name=&quot;port&quot; value=&quot;$&#123;redis.port&#125;&quot;&gt;&lt;/property&gt; &lt;!--&lt;property name=&quot;password&quot; value=&quot;$&#123;redis.password&#125;&quot;&gt;&lt;/property&gt;--&gt; &lt;property name=&quot;timeout&quot; value=&quot;$&#123;redis.timeout&#125;&quot;&gt;&lt;/property&gt; &lt;property name=&quot;usePool&quot; value=&quot;true&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;jedisTemplate&quot; class=&quot;org.springframework.data.redis.core.RedisTemplate&quot;&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;jedisConnectionFactory&quot;&gt;&lt;/property&gt; &lt;property name=&quot;keySerializer&quot;&gt; &lt;bean class=&quot;org.springframework.data.redis.serializer.StringRedisSerializer&quot; /&gt; &lt;/property&gt; &lt;property name=&quot;valueSerializer&quot;&gt; &lt;bean class=&quot;org.springframework.data.redis.serializer.StringRedisSerializer&quot; /&gt; &lt;/property&gt;&lt;/bean&gt; 接着封装publisher-MQPublisher主要封装的是该方法，其中我们可以制定自己的消息格式，方便业务操作，在这里本人封装了一个MQMessage的一个消息实体类。123456789101112131415161718public void pub(String channel,String message) &#123; Jedis jedis = null; try &#123; jedis = jedisPool.getResource(); MQMessage mqMessage = new MQMessage(); mqMessage.setChannelName(channel); mqMessage.setData(message); mqMessage.setMsgId(channel + UUID.randomUUID()); String mqMsg = JSON.toJSONString(mqMessage); jedis.publish(channel, mqMsg); &#125; catch (Exception e) &#123; log.error(&quot;got exception :&quot; + e); &#125; finally &#123; if(jedis!=null) &#123; jedis.close(); &#125; &#125; &#125; 要实现redis的pub/sub需要定义一个监听器，该监听器继承redis的JedisPubSub。并重写onMessage等方法来消费接收消息，因为只是个demo，所以直接用log输出表示。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class MQPubListener extends JedisPubSub&#123; private static Logger log= LoggerFactory.getLogger(MQPubListener.class); /** * 订阅消息后的处理 * @param channel * @param message */ @Override public void onMessage(String channel, String message) &#123; log.info(channel+&quot;......&quot;+message); &#125; /** * 取得按表达式获取的消息后的处理 * @param pattern * @param channel * @param message */ public void onPMessage(String pattern, String channel, String message) &#123; log.info(pattern+&quot;....&quot;+channel+&quot;....&quot;+message); &#125; /** * 初始化订阅时处理 * @param channel * @param subscribedChannels */ public void onSubscribe(String channel, int subscribedChannels) &#123; log.info(channel+&quot;......&quot;+&quot;subscirbed count:&quot;+subscribedChannels); &#125; /** * 取消订阅时处理 * @param channel * @param subscribedChannels */ public void onUnsubscribe(String channel, int subscribedChannels) &#123; log.info(channel+&quot;have unsubscribed&quot;+&quot;current subscirbed channel count is:&quot;+subscribedChannels); &#125; public void onPUnsubscribe(String pattern, int subscribedChannels) &#123; &#125; public void onPSubscribe(String pattern, int subscribedChannels) &#123; &#125;&#125; 接下来是定义subscribe方的消费者-MQComsumer由于redis的subscribe方法时阻塞的，并且消费者的注册需要在生产者的publish前进行，所以我们消费者利用多线程来实现。123456789101112131415161718192021222324252627282930public class MQComsumer &#123; private static Logger log= LoggerFactory.getLogger(MQComsumer.class); private JedisPubSub listener; private Jedis jedis; public MQComsumer(JedisPubSub listener,Jedis jedis)&#123; this.jedis=jedis; this.listener=listener; &#125; public SubTask subscribe(String channel)&#123; return new SubTask(channel); &#125; public void unSubscribe(String channel)&#123; jedis.del(channel); &#125; public class SubTask implements Runnable&#123; private String routeKey; public SubTask(String routeKey)&#123; this.routeKey=routeKey; &#125; public void run() &#123; log.info(&quot;sub starting ,the key is:&quot; +routeKey); jedis.subscribe(listener,routeKey); log.info(&quot;sub end&quot;); &#125; &#125;&#125; 最后使用MQEngine来触发启动comsumer线程123456789101112131415public class MQEngine &#123; private static Logger log= LoggerFactory.getLogger(MQEngine.class); private MQComsumer comsumer; private ExecutorService service; public MQEngine(MQComsumer comsumer)&#123; this.comsumer=comsumer; &#125; public void sub(String channel)&#123; log.info(&quot;subscribe channel:&quot;+channel); service= Executors.newFixedThreadPool(1); service.execute(comsumer.subscribe(channel)); &#125; 测试123456789101112131415161718@RunWith(SpringJUnit4ClassRunner.class)@WebAppConfiguration@ContextConfiguration(&#123;&quot;/spring-beans.xml&quot;,&quot;/spring-redis-config.xml&quot;&#125;)public class appTest &#123; @Autowired private JedisPool jedisPool; private static final String Channel=&quot;test&quot;; @Test public void test()&#123; MQPubListener listener=new MQPubListener(); MQComsumer comsumer=new MQComsumer(listener,jedisPool.getResource()); MQEngine engine=new MQEngine(comsumer); engine.sub(Channel); MQPublisher publisher=new MQPublisher(jedisPool); publisher.pub(Channel,&quot;hello message&quot;); &#125;&#125; 测试结果 test…….{“channelName”:”test”,”data”:”hello message”,”msgId”:”testbe6de83c-ffbf-4bbb-8553-381e41dc133f”}消费方成功获取消息]]></content>
      <tags>
        <tag>redis,sub/pub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用httpClient+PoolingHttpClientConnectionManager提交请求]]></title>
    <url>%2F2016%2F08%2F06%2F%E4%BD%BF%E7%94%A8httpClient%2BPoolingHttpClientConnectionManager%E6%8F%90%E4%BA%A4%E8%AF%B7%E6%B1%82%2F</url>
    <content type="text"><![CDATA[使用连接池的好处大家都知道http连接是基于tcp的，而tcp创建连接需要三次握手，断开连接四次挥手，如果我们不使用连接池，那么每发出一个请求，就需要三次握手和四次挥手，而三次握手和四次挥手都是耗资源的操作。试想如果频繁的发出请求，性能是不是会是个瓶颈。所以HttpClient在4之后就出现了连接池的概念，当请求结束并不是直接断开连接，而是返回给连接池方便下次调用。 连接池配置使用连接池主要是用到PoolingHttpClientConnectionManager这个类，基本上的配置像Cookie配置策略、连接数的控制都是在ConnectionManager中配置的,所以在调用httpClient时必须先初始化ConnectionManager。12345678910111213141516private static PoolingHttpClientConnectionManager clientConnectionManager=null; private static CloseableHttpClient httpClient=null; private static RequestConfig config = RequestConfig.custom().setCookieSpec(CookieSpecs.STANDARD_STRICT).build(); private final static Object syncLock = new Object(); @PostConstruct private void init()&#123; Registry&lt;ConnectionSocketFactory&gt; socketFactoryRegistry = RegistryBuilder.&lt;ConnectionSocketFactory&gt;create() .register(&quot;https&quot;, SSLConnectionSocketFactory.getSocketFactory()) .register(&quot;http&quot;, PlainConnectionSocketFactory.getSocketFactory()) .build(); clientConnectionManager =new PoolingHttpClientConnectionManager(socketFactoryRegistry); clientConnectionManager.setMaxTotal(50); clientConnectionManager.setDefaultMaxPerRoute(25); &#125; 创建httpClient实例一般在这个实例中我们将CookieStore传入并让其一直持有Cookie 12345678910111213141516public static CloseableHttpClient getHttpClient()&#123; if(httpClient == null)&#123; synchronized (syncLock)&#123; if(httpClient == null)&#123; CookieStore cookieStore = new BasicCookieStore(); BasicClientCookie cookie = new BasicClientCookie(&quot;sessionID&quot;, &quot;######&quot;); cookie.setDomain(&quot;#####&quot;); cookie.setPath(&quot;/&quot;); cookieStore.addCookie(cookie); httpClient =HttpClients.custom().setConnectionManager(clientConnectionManager).setDefaultCookieStore(cookieStore).setDefaultRequestConfig(config).build(); &#125; &#125; &#125; &#125; return httpClient; &#125; 创建POST/GET请求方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public static HttpEntity httpGet(String url, Map&lt;String,Object&gt; headers)&#123; CloseableHttpClient httpClient = getHttpClient(); HttpRequest httpGet = new HttpGet(url); if(headers!=null&amp;&amp;!headers.isEmpty())&#123; httpGet = setHeaders(headers, httpGet); &#125; CloseableHttpResponse response = null; try&#123; response =httpClient.execute((HttpGet)httpGet); HttpEntity entity = response.getEntity(); return entity; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; return null; &#125; /** * post请求,使用json格式传参 * @param url * @param headers * @param data * @return */ public static HttpEntity httpPost(String url,Map&lt;String,Object&gt; headers,String data)&#123; CloseableHttpClient httpClient = getHttpClient(); HttpRequest request = new HttpPost(url); if(headers!=null&amp;&amp;!headers.isEmpty())&#123; request = setHeaders(headers,request); &#125; CloseableHttpResponse response = null; try &#123; HttpPost httpPost = (HttpPost) request; httpPost.setEntity(new StringEntity(data, ContentType.create(&quot;application/json&quot;, &quot;UTF-8&quot;))); response=httpClient.execute(httpPost); HttpEntity entity = response.getEntity(); return entity; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; /** 使用表单键值对传参 */ public static HttpEntity PostForm(String url,Map&lt;String,Object&gt; headers,List&lt;NameValuePair&gt; data)&#123; CloseableHttpClient httpClient = getHttpClient(); HttpRequest request = new HttpPost(url); if(headers!=null&amp;&amp;!headers.isEmpty())&#123; request = setHeaders(headers,request); &#125; CloseableHttpResponse response = null; UrlEncodedFormEntity uefEntity; try &#123; HttpPost httpPost = (HttpPost) request; uefEntity = new UrlEncodedFormEntity(data,&quot;UTF-8&quot;); httpPost.setEntity(uefEntity); // httpPost.setEntity(new StringEntity(data, ContentType.create(&quot;application/json&quot;, &quot;UTF-8&quot;))); response=httpClient.execute(httpPost); HttpEntity entity = response.getEntity(); return entity; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; /** * 设置请求头信息 * @param headers * @param request * @return */ private static HttpRequest setHeaders(Map&lt;String,Object&gt; headers, HttpRequest request) &#123; for (Map.Entry entry : headers.entrySet()) &#123; if (!entry.getKey().equals(&quot;Cookie&quot;)) &#123; request.addHeader((String) entry.getKey(), (String) entry.getValue()); &#125; else &#123; Map&lt;String, Object&gt; Cookies = (Map&lt;String, Object&gt;) entry.getValue(); for (Map.Entry entry1 : Cookies.entrySet()) &#123; request.addHeader(new BasicHeader(&quot;Cookie&quot;, (String) entry1.getValue())); &#125; &#125; &#125; return request; &#125;]]></content>
      <tags>
        <tag>httpClient,连接池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos6.6搭建solrcloud5.3.1]]></title>
    <url>%2F2016%2F07%2F31%2Fcentos6-6%E6%90%AD%E5%BB%BAsolrcloud5-3-1%2F</url>
    <content type="text"><![CDATA[1.搭建前准备去官网分别下载以下压缩包：12345jdk-8u45-linux-x64.tar.gzzookeeper-3.4.6.tar.gzsolrcloud-5.3.1.tar.gz 1.1安装配置jdk1tar xvzf /home/workspaces/jdk-8u45-linux-x64.tar.gz 配置环境变量，进入profile文件1vim /etc/profile 追加以下内容12345JAVA_HOME=/usr/java/jdk1.8.45JRE_HOME=/usr/java/jdk1.8.45/jrePATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libexport JAVA_HOME JRE_HOME PATH CLASSPATH 2安装配置开启zookeeper集群1tar xf /home/workspace/soft/zookeeper-3.4.6.tar.gz 复制zookeeper默认配置文件12cd zookeeper-3.4.6/conf cp zoo_sample.cfg zoo.cfg 将需要搭建成集群的服务器添加进去12345678910vim zoo.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=/path/to/zookeeper/data clientPort=2181 server.1=192.168.156.121:2888:3888 server.2=192.168.156.122:2888:3888 server.3=192.168.156.123:2888:3888 将服务器编号写入每一台服务器12345678910# 注意每台机器上的不一样echo&quot;1&quot;&gt;myid#在solr1上echo&quot;2&quot;&gt;myid#在solr2上echo&quot;3&quot;&gt;myid#在solr3上 其中solr1、solr2、solr3分别是我三台不同服务器名在上面配置了三台服务器集群，要在三台服务器分别如上配置并且开启zookeeper服务器1zookeeper-3.4.6/bin ./zkServer.sh start 3.将solr安装为服务1tar xf /home/workspace/soft/solrcloud-5.3.1.tar.gz 创建两个文件夹solr、data1mkdir -p /solrcloud/&#123;data,solr&#125; 设置服务名称、端口等12cd solr-5.3.1/bin ./install_solr_service.sh /home/wokspace/soft/solr-5.3.1.tgz -d /solrcloud/data/ -i /solrcloud/solr/ -s solrcloud -u root -p 8080 这里面-d是放solr的data数据，-i是放solr文件，-s是服务名 -u是用户 -p是实用端口，默认是8983 修改solrcloud的data文件123456789cd /home/workspace/solrcloud/data ls data log4j.properties logs solr-8983.pid solr.in.sh vim solr.in.sh # Set the ZooKeeper connection string if using an external ZooKeeper ensemble # e.g. host1:2181,host2:2181/chroot # Leave empty if not using SolrCloud ZK_HOST=&quot;192.168.156.121:2181,192.168.156.122:2181,192.168.156.123:2181&quot; 启动solrcloud1service solrcloud restart 4.更新配置文件创建collection123456cd solr-5.3.1 ./server/scripts/cloud-scripts/zkcli.sh -zkhost localhost:2181 -cmd upconfig -confname demo-conf -confdir server/solr/configsets/basic_configs/conf/ ./server/scripts/cloud-scripts/zkcli.sh -zkhost localhost:2181 -cmd linkconfig -collection demo -confname demo-conf curl &apos;http://192.168.156.121:8080/solr/admin/collections?action=CREATE&amp;name=demo&amp;numShards=1&amp;replicationFactor=1&apos; 其中-upconfig 是更新配置文件，-linkconfig是创建链接最后curl 提交请求创建collection，collection名称为demo，一个collection创建一个shard，一个shard创建一个replica 5.添加文件数据索引123bin/post -c demo -p 8080 /home/workspace/solrcloud/example/exampledocs/books.json 以上 -c是指定要上传数据给哪个collection，-p是端口号 如果想自定义field字段，进入schema.xml添加或修改field，修改之后需要再次更新配置文件和第四步的更新配置文件一样 7.查询1curl &apos;http://192.168.219.128:8080/solr/demo/select?wt=json&amp;indent=true&amp;q=cat:book&amp;fl=name&apos; 响应12345678910111213141516171819&#123; &quot;responseHeader&quot;:&#123; &quot;status&quot;:0, &quot;QTime&quot;:6, &quot;params&quot;:&#123; &quot;q&quot;:&quot;cat:book&quot;, &quot;indent&quot;:&quot;true&quot;, &quot;fl&quot;:&quot;name&quot;, &quot;wt&quot;:&quot;json&quot;&#125;&#125;, &quot;response&quot;:&#123;&quot;numFound&quot;:4,&quot;start&quot;:0,&quot;docs&quot;:[ &#123; &quot;name&quot;:[&quot;The Lightning Thief&quot;]&#125;, &#123; &quot;name&quot;:[&quot;The Sea of Monsters&quot;]&#125;, &#123; &quot;name&quot;:[&quot;Sophie&apos;s World : The Greek Philosophers&quot;]&#125;, &#123; &quot;name&quot;:[&quot;Lucene in Action, Second Edition&quot;]&#125;] &#125;&#125;]]></content>
      <tags>
        <tag>centos,solrcloud</tag>
      </tags>
  </entry>
</search>
