<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Netty4.x源码分析之EventLoop（二）]]></title>
    <url>%2F2019%2F09%2F10%2FNetty4.x%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BEventLoop%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[引言在上篇文章我们分析了EventLoop的两大核心NioEventLoopGroup和NioEventLoop，NioEventLoopGroup在其父类MultithreadEventExecutor中维护了NioEventLoop数组，而NioEventLoop首先内部持有线程对象，所以NioEventLoopGroup是个线程池，并且上篇文章我们也分析了NioEventLoop除了是个单线程，并且也是它执行了I/O的事件循环，没错就是它自己的run方法里面的逻辑，今天我们专门深入到这块事件循环里面，看看Netty是怎么做的。 NioEventLoop事件循环回顾一下上篇文章NioEventLoop启动是通过Channel注册到selector上时执行execute方法触发startThread()方法启动的。 123456789101112131415161718192021@Override public void execute(Runnable task) &#123; if (task == null) &#123; throw new NullPointerException(&quot;task&quot;); &#125; boolean inEventLoop = inEventLoop(); if (inEventLoop) &#123; addTask(task); &#125; else &#123; startThread(); addTask(task); if (isShutdown() &amp;&amp; removeTask(task)) &#123; reject(); &#125; &#125; if (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &#123; wakeup(inEventLoop); &#125; &#125; 而这个startThread方法先是调用threadFactory创建一个线程，然后往线程提交一任务，而任务里面直接调用了NioEventLoop的run方法。 1234567891011121314151617181920212223242526private void startThread() &#123; if (state == ST_NOT_STARTED) &#123; if (STATE_UPDATER.compareAndSet(this, ST_NOT_STARTED, ST_STARTED)) &#123; doStartThread(); &#125; &#125; &#125; private void doStartThread() &#123; assert thread == null; executor.execute(new Runnable() &#123; @Override public void run() &#123; thread = Thread.currentThread(); if (interrupted) &#123; thread.interrupt(); &#125; try &#123; SingleThreadEventExecutor.this.run(); success = true; &#125; catch (Throwable t) &#123; logger.warn(&quot;Unexpected exception from an event executor: &quot;, t); &#125; &#125;); &#125;//删除无关代码 而这个run方法就是时间循环的核心，我们着重看看这个run方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152protected void run() &#123; for (;;) &#123; try &#123; switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123; case SelectStrategy.CONTINUE: continue; case SelectStrategy.SELECT: select(wakenUp.getAndSet(false)); if (wakenUp.get()) &#123; selector.wakeup(); &#125; default: // fallthrough &#125; cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; if (ioRatio == 100) &#123; try &#123; processSelectedKeys(); &#125; finally &#123; // Ensure we always run tasks. runAllTasks(); &#125; &#125; else &#123; final long ioStartTime = System.nanoTime(); try &#123; processSelectedKeys(); &#125; finally &#123; // Ensure we always run tasks. final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125; &#125; &#125; catch (Throwable t) &#123; handleLoopException(t); &#125; // Always handle shutdown even if the loop processing threw an exception. try &#123; if (isShuttingDown()) &#123; closeAll(); if (confirmShutdown()) &#123; return; &#125; &#125; &#125; catch (Throwable t) &#123; handleLoopException(t); &#125; &#125; &#125; 可以看到run方法里面直接for (;;)一个忙循环开始一直保持这个Thread进行事件循环保证当前线程可以一直处理注册在当前线程的selector出来的I/O事件。接下来是个switch判断，我们来看看selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())这个方法，selectStrategy这个对象是个接口，实现类是子类创建默认的实例传上来的DefaultSelectStrategy，我们看下这个方法 1234567891011 private final IntSupplier selectNowSupplier = new IntSupplier() &#123; @Override public int get() throws Exception &#123; return selectNow(); &#125; &#125;; @Override public int calculateStrategy(IntSupplier selectSupplier, boolean hasTasks) throws Exception &#123; return hasTasks ? selectSupplier.get() : SelectStrategy.SELECT; &#125; 这个方法传入一个IntSupplier对象和boolean值德 hasTasks，方法也很简单如果队列里面有任务那么直接调用selectSupplier.get()方法返回，否则返回SelectStrategy.SELECT。这个IntSupplier我也在在上面代码列出来了，调用selectSupplier.get()方法其实是直接调用了selectNow()方法，这个selectNow()方法并不是阻塞的，而是里吗select一把之后立即返回，为什么在队列里面有任务时进行selectNow()而不是调用Select阻塞线程呢？这是因为Netty的EventLoop不仅是个I/O线程处理I/O事件，它还是个任务线程，处理用户提交或者netty自己提交的任务。如果任务队列里面有任务，执行select把线程阻塞了，用户提交的业务任务永远都得不到执行，所以在这里会做一个判断如果有任务在队列里直接select一把后再执行队列里面的任务。如果队列里面没有任务那么返回SelectStrategy.SELECT，switch代码块执行到select(wakenUp.getAndSet(false));调用这个方法首先会把线程的wakenUp状态设为false，表示我要阻塞当前线程了，然后调用select方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081private void select(boolean oldWakenUp) throws IOException &#123; Selector selector = this.selector; try &#123; int selectCnt = 0; long currentTimeNanos = System.nanoTime(); long selectDeadLineNanos = currentTimeNanos + delayNanos(currentTimeNanos); for (;;) &#123; long timeoutMillis = (selectDeadLineNanos - currentTimeNanos + 500000L) / 1000000L; if (timeoutMillis &lt;= 0) &#123; if (selectCnt == 0) &#123; selector.selectNow(); selectCnt = 1; &#125; break; &#125; if (hasTasks() &amp;&amp; wakenUp.compareAndSet(false, true)) &#123; selector.selectNow(); selectCnt = 1; break; &#125; int selectedKeys = selector.select(timeoutMillis); selectCnt ++; if (selectedKeys != 0 || oldWakenUp || wakenUp.get() || hasTasks() || hasScheduledTasks()) &#123; // - Selected something, // - waken up by user, or // - the task queue has a pending task. // - a scheduled task is ready for processing break; &#125; if (Thread.interrupted()) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Selector.select() returned prematurely because &quot; + &quot;Thread.currentThread().interrupt() was called. Use &quot; + &quot;NioEventLoop.shutdownGracefully() to shutdown the NioEventLoop.&quot;); &#125; selectCnt = 1; break; &#125; long time = System.nanoTime(); if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) &gt;= currentTimeNanos) &#123; // timeoutMillis elapsed without anything selected. selectCnt = 1; &#125; else if (SELECTOR_AUTO_REBUILD_THRESHOLD &gt; 0 &amp;&amp; selectCnt &gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) &#123; // The selector returned prematurely many times in a row. // Rebuild the selector to work around the problem. logger.warn( &quot;Selector.select() returned prematurely &#123;&#125; times in a row; rebuilding Selector &#123;&#125;.&quot;, selectCnt, selector); rebuildSelector(); selector = this.selector; // Select again to populate selectedKeys. selector.selectNow(); selectCnt = 1; break; &#125; currentTimeNanos = time; &#125; if (selectCnt &gt; MIN_PREMATURE_SELECTOR_RETURNS) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Selector.select() returned prematurely &#123;&#125; times in a row for Selector &#123;&#125;.&quot;, selectCnt - 1, selector); &#125; &#125; &#125; catch (CancelledKeyException e) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(CancelledKeyException.class.getSimpleName() + &quot; raised by a Selector &#123;&#125; - JDK bug?&quot;, selector, e); &#125; // Harmless exception - log anyway &#125; &#125; select方法首先是计算什么时候结束阻塞，就是selectDeadLineNanos这个变量，那是怎么计算的呢，先拿到当前时间，然后再计算ScheduleTask下次到期时间，就算出了select需要阻塞多久再醒过来，这里设计的很巧妙，还是那句话，老子不仅是I/O线程，我还是个任务线程，谁都要照顾到。 1234567891011 long currentTimeNanos = System.nanoTime(); long selectDeadLineNanos = currentTimeNanos + delayNanos(currentTimeNanos); protected long delayNanos(long currentTimeNanos) &#123; ScheduledFutureTask&lt;?&gt; scheduledTask = peekScheduledTask(); if (scheduledTask == null) &#123; return SCHEDULE_PURGE_INTERVAL; &#125; return scheduledTask.delayNanos(currentTimeNanos); &#125; 然后在这个selectDeadLineNanos时间内通过一个死循环阻塞开始尽情select。我们继续看下面的代码。for循环内每次设置500毫秒的select超时时间，接着判断selectDeadLineNanos的阻塞时间到了没，到了但是selectCnt计数还是0那么直接selectNow一把再退出，接着在调用select方法阻塞之前再次判断这时候有没有任务进队列有的话乖乖退出让出线程时间给任务执行。最后才是调用selector.select(timeoutMillis)方法，直到有事件触发或者超时线程才恢复，并且只要有事件触发或者wakeUp被设为true或者任务队列有任务了，直接退出死循环。在select方法里还有一个逻辑值得一提，也就是Netty解决JDK臭名昭著的epoll空轮询导致cpu 100%的bug。 epoll BUGjava NIO在linux环境下通过selector.select在一般情况下如果没有事件准备好当前线程是被阻塞的，但是在某些情况下select之后就算没有事件触发也会返回，然后select获取到的selectorkey数量为0，然后在忙循环里面一直空轮询导致cpu 100%系统崩溃。在Netty中把这个bug修复了，修复逻辑很简单，使用一个计数器默认阈值为512次，如果出现512次空轮询，那么进行重建selector，新建一个selector，把老的selector上面注册的channel迁移到新的selector上，最后把老的selector覆盖，然后关闭老的selector的方式来修复空轮询bug，具体看下面代码，实现逻辑在rebuildSelector()方法里。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576else if (SELECTOR_AUTO_REBUILD_THRESHOLD &gt; 0 &amp;&amp; selectCnt &gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) &#123; // The selector returned prematurely many times in a row. // Rebuild the selector to work around the problem. logger.warn( &quot;Selector.select() returned prematurely &#123;&#125; times in a row; rebuilding Selector &#123;&#125;.&quot;, selectCnt, selector); rebuildSelector(); selector = this.selector; // Select again to populate selectedKeys. selector.selectNow(); selectCnt = 1; break; &#125; private void rebuildSelector0() &#123; final Selector oldSelector = selector; final SelectorTuple newSelectorTuple; if (oldSelector == null) &#123; return; &#125; try &#123; newSelectorTuple = openSelector(); &#125; catch (Exception e) &#123; logger.warn(&quot;Failed to create a new Selector.&quot;, e); return; &#125; // Register all channels to the new Selector. int nChannels = 0; for (SelectionKey key: oldSelector.keys()) &#123; Object a = key.attachment(); try &#123; if (!key.isValid() || key.channel().keyFor(newSelectorTuple.unwrappedSelector) != null) &#123; continue; &#125; int interestOps = key.interestOps(); key.cancel(); SelectionKey newKey = key.channel().register(newSelectorTuple.unwrappedSelector, interestOps, a); if (a instanceof AbstractNioChannel) &#123; // Update SelectionKey ((AbstractNioChannel) a).selectionKey = newKey; &#125; nChannels ++; &#125; catch (Exception e) &#123; logger.warn(&quot;Failed to re-register a Channel to the new Selector.&quot;, e); if (a instanceof AbstractNioChannel) &#123; AbstractNioChannel ch = (AbstractNioChannel) a; ch.unsafe().close(ch.unsafe().voidPromise()); &#125; else &#123; @SuppressWarnings(&quot;unchecked&quot;) NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a; invokeChannelUnregistered(task, key, e); &#125; &#125; &#125; selector = newSelectorTuple.selector; unwrappedSelector = newSelectorTuple.unwrappedSelector; try &#123; // time to close the old selector as everything else is registered to the new one oldSelector.close(); &#125; catch (Throwable t) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(&quot;Failed to close the old Selector.&quot;, t); &#125; &#125; logger.info(&quot;Migrated &quot; + nChannels + &quot; channel(s) to the new Selector.&quot;); &#125; 看完select方法，我们回过头来看run方法里面剩余的部分。select结束之后按照我们JAVA NIO的经验是要对这些SelectedKeys进行处理的，比如读、写数据，对数据进行业务处理等等。我们看看Netty是怎么处理的 123456789101112131415161718final int ioRatio = this.ioRatio; if (ioRatio == 100) &#123; try &#123; processSelectedKeys(); &#125; finally &#123; // Ensure we always run tasks. runAllTasks(); &#125; &#125; else &#123; final long ioStartTime = System.nanoTime(); try &#123; processSelectedKeys(); &#125; finally &#123; // Ensure we always run tasks. final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125; &#125; 特地把run方法剩余部分截出来，上面贴的代码太长怕忘了。可以看到在NioEventLoop里定义了个ioRatio的变量，默认是50，这个ioRatio就是之前我们说到的“EventLoop既是I/O线程处理I/O事件，又是任务线程处理任务队列里的任务”。这里首先判断ioRatio是否100，如果io执行百分比是100%，那么直接就处理processSelectedKeys()方法，只有等到有I/O事件处理完成再处理任务队列里的任务，如果不是100%那么也是先处理I/O事件，接着再计算处理任务队列里的任务可以占用线程的时间。计算公式如下,很好推导 123ioTime / ioRatio = taskTime / taskRatiotaskRatio=100-ioRatiotaskTime=ioTime * (100 - ioRatio) / ioRatio 也就是说如果是50的ioRatio，那么处理I/O事件所占用线程时间和处理队列任务各占一半。处理任务队列的任务在这就不展开了，代码不难有兴趣的可以自行阅读源码，我们重点看看processSelectedKeys()方法 123456789101112131415161718192021222324252627private void processSelectedKeysOptimized() &#123; for (int i = 0; i &lt; selectedKeys.size; ++i) &#123; final SelectionKey k = selectedKeys.keys[i]; // null out entry in the array to allow to have it GC&apos;ed once the Channel close // See https://github.com/netty/netty/issues/2363 selectedKeys.keys[i] = null; final Object a = k.attachment(); if (a instanceof AbstractNioChannel) &#123; processSelectedKey(k, (AbstractNioChannel) a); &#125; else &#123; @SuppressWarnings(&quot;unchecked&quot;) NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a; processSelectedKey(k, task); &#125; if (needsToSelectAgain) &#123; // null out entries in the array to allow to have it GC&apos;ed once the Channel close // See https://github.com/netty/netty/issues/2363 selectedKeys.reset(i + 1); selectAgain(); i = -1; &#125; &#125; &#125; processSelectedKeysOptimized()方法拿到select出来的selectedKeys，首先把SelectedKey取出来然后remove掉，在Netty这变成了置空，取出来的key通过Key.attachment方法拿到当初设置进去的AbstractNioChannel。还记得么，我们在注册Channel到Selector上的时候在unsafe里把this设到attachment里去了。 123456789101112@Override protected void doRegister() throws Exception &#123; boolean selected = false; for (;;) &#123; try &#123; selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; &#125; catch (CancelledKeyException e) &#123; //删除无关代码 &#125; &#125; &#125; 所以这个attachment拿到的object当然是AbstractNioChannel，然后就来到了processSelectedKey(k, (AbstractNioChannel) a)方法 1234567891011121314151617181920212223242526272829private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &#123; final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); if (!k.isValid()) &#123; //省略无关代码 try &#123; int readyOps = k.readyOps(); // We first need to call finishConnect() before try to trigger a read(...) or write(...) as otherwise // the NIO JDK channel implementation may throw a NotYetConnectedException. if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) &#123; int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); &#125; // Process OP_WRITE first as we may be able to write some queued buffers and so free memory. if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) &#123; // Call forceFlush which will also take care of clear the OP_WRITE once there is nothing left to write ch.unsafe().forceFlush(); &#125; if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; unsafe.read(); &#125; &#125; catch (CancelledKeyException ignored) &#123; unsafe.close(unsafe.voidPromise()); &#125; &#125; 可以看到这块代码就是在真正处理I/O事件了，如果readyOps是OP_CONNECT那么先把OP_CONNECT操作位从SelectedKeys的interestOps()给移除，否则每次select都能拿到这个老的事件，然后通过unsafe.finishConnect()方法把事件传播下去channel是Active的了。如果readyOps是OP_WRITE那么直接forceFlush()，把Netty的OutboundBuffer转换成ByteBuffer调用JDK原生方法把数据写如内核缓存区最终传输出去。如果readyOps是OP_READ或者OP_ACCEPT那么调用unsafe.read()方法，unsafe.read()方法如下 12345678910111213141516171819202122232425262728293031323334353637383940public void read() &#123; assert eventLoop().inEventLoop(); final ChannelConfig config = config(); final ChannelPipeline pipeline = pipeline(); final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle(); allocHandle.reset(config); boolean closed = false; Throwable exception = null; try &#123; try &#123; do &#123; int localRead = doReadMessages(readBuf); if (localRead == 0) &#123; break; &#125; if (localRead &lt; 0) &#123; closed = true; break; &#125; allocHandle.incMessagesRead(localRead); &#125; while (allocHandle.continueReading()); &#125; catch (Throwable t) &#123; exception = t; &#125; int size = readBuf.size(); for (int i = 0; i &lt; size; i ++) &#123; readPending = false; pipeline.fireChannelRead(readBuf.get(i)); &#125; readBuf.clear(); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); &#125; &#125; &#125; &#125; 该方法主要做了三件事：1.分配空间；2.accept 操作拿到channel；3.调用pipeline.fireChannelRead方法把channelRead事件传递下去以便进行业务处理。 总结我们分析完了EventLoop的逻辑，总的来说EventLoopGroup在Netty中是线程池的角色，EventLoopGroup中的每个线程持有类NioEventLoop是I/O线程可以处理I/O事件，在NioEventLoop内部通过死循环+select操作完成事件循环，同时也是任务线程可以处理任务队列里的任务，并且任务队列里的任务也可以是定时任务。]]></content>
      <tags>
        <tag>JAVA,Netty,NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty4.x源码分析之EventLoop（一）]]></title>
    <url>%2F2019%2F08%2F15%2FNetty4.x%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BEventLoop%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[引言上篇文章我们分析了ServerBootstrap的启动这部分源码，从整体的角度初步接触了netty的编码设计的魅力，今天我们来分析一下Netty里面另一个核心角色–EventLoop。用过netty的同学应该都或多或少知道Netty的高性能很大一部分功劳都在EventLoop的设计，尤其是EventLoop对Reactor线程模型的实现，大大提升了Netty的并发能力，接下来我们就来揭开EventLoop的神秘面纱 UNIX网络I/O模型Netty一直以其优异的性能表现收获粉丝无数，有研究称netty可以撑过单机10w的TPS。如此高的性能自然离不开精良的线程模型设计和UNIX网络I/O编程模型的选用，我们在看源码前先了解下UNIX网了I/O编程模型和Reactor线程模型。 UNIX网络I/O模型本来有五种，这里只列出三种与我们理解Netty源码有关的，即阻塞I/O模型、非阻塞I/O模型、I/O多路复用模型。 阻塞I/O模型 在JDK1.4之前默认使用的就是阻塞I/O模型，阻塞I/O模型所有的文件操作都是阻塞的。我们以套接字接口为例：在进程空间中调用recvfrom，系统调用知道数据包到达并且被复制到应用进程（用户态）的缓冲区或者发生错误时才返回，在返回之前一直等待，进程从调用recvfrom到返回一直被阻塞。了解这一点，我们就知道为什么JDK1.4之前java的网络通信为什么如此为人所诟病了，只要并发量上来，假设因为某些客观原因网络拥堵，很有可能会有大量accept进来的客户端连接会被阻塞，导致大量连接超时。 非阻塞I/O模型 非阻塞I/O模型与阻塞I/O模型的唯一区别就是recvfrom系统调用发出后，如果应用进程的缓存区没有数据，就直接返回一个EWOULDBLOCK的错误，一般都是使用一个线程进行轮询这个状态，看内核是否有数据到来。这个非阻塞I/O模型对于阻塞I/O模型是个进步，但是为每个连接都是用一个线程进行轮询，这会对cpu时间大量的耗费，性能也不高。 I/O多路复用模型 进程通过将一个或多个文件描述符(fd)传递给select/poll系统调用，阻塞在select操作上，虽然都会阻塞，但是可以实现多个fd阻塞在这个select上，这样我们通过一个线程就可以使用select/poll监听多个文件描述符是否处于就绪状态，这个进步是巨大的，一个线程可以监听大量的连接情况，Java的NIO就是使用的I/O多路复用模型，而Netty就是使用了Java的NIO。 Reactor线程模型Reactor是一个形象的名称，具体下来可以理解为这么一段伪代码 while(true) {selector.select();后续处理….} ,就是不断的select一把，然后对select出来的连接进行对应的业务操作。Reactor模型实质上是一个观察者模式，所有的事件处理器注册在Dispatcher上，只要select出多个连接，并监听感兴趣的事件，Dispatcher就调用这些对应的事件处理器，并且这些操作是异步的。Reactor线程模型有三种：Reactor单线程模型、Reactor多线程模型、主从多线程模型。 Reactor单线程模型Reactor单线程模型比较简单，就是一个线程把select操作、监听读写事件，处理业务操作全在一个线程内，虽然简单但也强大，因为使用的I/O多路复用模型，除非你的业务逻辑比较耗时，一般体量的业务Reactor单线程模型就足够了。但是一旦并发连接数上来恐怕是hold不住，单线程无法满足大量的消息编解码、消息读取和发送，可能会导致大量的连接超时。基于这些问题演进了Reactor多线程模型。 Reactor多线程模型Reactor多线程模型为了解决单线程无法满足大量消息编解码，I/O事件的处理，将Accept事件和读写I/O事件区分开，Accept事件单独使用单线程处理，因Accept操作简单，资源占用少，所以单线程足以支撑海量连接的Accept的操作。而I/O读写事件通过一个线程池处理.Reactor多线程模型充分利用了现代计算机多核cpu的特性，大大提升了TCPServer的并发性能。而Netty正是使用了Reactor多线程模型，只不过在Netty中对多线程模型的线程池做了适应性改造，一个连接绑定一个线程，而不是像JDK原生线程池一样通过一个队列接收所有的task，多个线程竞争获取task执行。这样减少了因为同步导致的资源消耗，一定程度上提高了性能。除了Reactor多线程模型，还有一种Reactor主从多线程模型。 Reactor主从多线程模型其实一般项目使用Reactor多线程模型足够的，目前本人并不太理解这个主从多线程模型的需求，因为Accept操作并不太消耗资源，加上使用的是I/O多路复用模型，一个线程处理足以大量的Accept请求。尽管如此我们还是简单了解一下主从多线程模型吧，有对主从多线程模型理解更深的欢迎交流。 主从多线程模型除了对Accept操作把单线程换成一个线程池之外，其他的和Reactor多线程模型一模一样。应该是觉得可能在Accept阶段如果使用单线程处理会成为一个瓶颈，所以Accept阶段也使用一个线程池处理，查看李林峰老师的Netty权威指南也指明了很多项目有安全需求，比如服务端需要对客户端握手进行安全认证，安全认证的过程是比较消耗性能的，这种场景下单线程处理Accept过程可能存在性能问题。 NioEventLoopGroup初始化了解了UNIX网络I/O模型和Reactor线程模型之后我们正式开始了解Netty的EventLoop。我们可以回忆一下我们是怎么在启动ServerBootstrap时设置EventLoop的. 12345this.bossGroup = new NioEventLoopGroup(bossThreadNumber, new DefaultThreadFactory(bossThreadName, true)); this.workerGroup = new NioEventLoopGroup(workerThreadNumber, new DefaultThreadFactory(workerThreadName, true)); ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(this.bossGroup, this.workerGroup).channel(NioServerSocketChannel.class).childHandler(channelInitializer); 我们创建两个NioEventLoopGroup实例，从名称可以大概猜到这两个是线程池，一个处理三次握手的Accept过程，一般我们称为Boss线程池，一个是处理读写I/O的网络事件，一般我们称为worker线程池。我们先看看这个NioEventLoopGroup的类层次结构 可以看到NioEventLoopGroup类的继承体系还是比较复杂的，首先继承了MultithreadEventLoopGroup，然后继承MultithreadEventExecutorGroup，AbstractEventExecutorGroup，并且还实现了ScheduledExecutorService接口，我们可以初步判断这个NioEventLoopGroup不仅仅是个线程池可以提交任务执行，还能提交定时任务执行。接下来我们看看NioEventLoopGroup的初始化。 可以看到NioEventLoop经过自己的构造函数多层调用后拿到了线程数、threadFactory、selectorProvider，selectStrategyFactory和rejectHandler调用了父类MultithreadEventLoopGroup的构造函数。其中线程数和threadFactory我们不用多说大家都清楚，而selectorProvider就是提供selector对象的，而selectStrategyFactory这里用不到先不说。接下来MultithreadEventLoopGroup又经过层层调用拿到了ThreadPreTaskExecutor实例和DefaultEventExecutorChooserFactory实例，这里ThreadPreTaskExecutor实现了Executor接口，所以ThreadPreTaskExecutor基本实现了线程池的功能–创建线程和启动线程。而这个DefaultEventExecutorChooserFactory则是多线程中选择的负载均衡器，说白了就是线程选择器。最终调用到了MultithreadEventLoopGroup关键的构造函数，我们看看代码 1234567891011121314151617protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) &#123; //去除无关代码 children = new EventExecutor[nThreads]; for (int i = 0; i &lt; nThreads; i ++) &#123; boolean success = false; try &#123; children[i] = newChild(executor, args); success = true; &#125; catch (Exception e) &#123; // TODO: Think about if this is a good exception type throw new IllegalStateException(&quot;failed to create a child event loop&quot;, e); &#125; chooser = chooserFactory.newChooser(children);&#125; 在这个关键的构造函数里面初始化了nthreads个EventExecutor数组，for循环创建子线程，这个newChild方法是个抽象方法，实现在NioEventLoopGroup中。 12345@Override protected EventLoop newChild(Executor executor, Object... args) throws Exception &#123; return new NioEventLoop(this, executor, (SelectorProvider) args[0], ((SelectStrategyFactory) args[1]).newSelectStrategy(), (RejectedExecutionHandler) args[2]); &#125; 进入NioEventLoop类中我们可以看到该类也很复杂，查看类层次结构，可以看到它的父类维护了thread的属性，所以我们可以认为NioEventLoop其实是线程包装类，所以我们可以认为这个EventExecutor数组其实是NioEventLoop–线程包装类数组。所以我们已经可以断定这个MultithreadEventLoopGroup其实就是线程池。 NioEventLoopNioEventLoop类层次结构也很复杂，首先它继承SingleThreadEventLoop，看到类名大概也知道了这个NioEventLoop首先是个单线程包装类，然后SingleThreadEventLoop继承SingleThreadEventExecuto、AbstractScheduledEventExecutor，最上层还实现了ScheduledExecutorService，所以NioEventLoop还实现了scheduled的逻辑可以执行定时调度任务。我们看看类图 首先我们看看NioEventLoop的构造函数123456789101112131415NioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider, SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) &#123; super(parent, executor, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler); if (selectorProvider == null) &#123; throw new NullPointerException(&quot;selectorProvider&quot;); &#125; if (strategy == null) &#123; throw new NullPointerException(&quot;selectStrategy&quot;); &#125; provider = selectorProvider; final SelectorTuple selectorTuple = openSelector(); selector = selectorTuple.selector; unwrappedSelector = selectorTuple.unwrappedSelector; selectStrategy = strategy; &#125; NioEventLoop的构造函数拿到了selectorProvider和selectStrategy，并赋值给全局变量，最后通过openSelector()方法拿到一个selector对象，并通过selectorTuple包装好。到这我们大概可以知道每个线程持有一个selector对象，联系到上篇文章分析的channel的注册过程，我们应该知道每个线程应该会通过一个忙循环来select一把来监听所有感兴趣的I/O事件，最终通过pipeline把事件传到业务handler中对这些I/O事件进行处理。最后我们看看刚刚说的父类SingleThreadEventExecutor类构造函数。 1234567891011121314151617181920212223242526272829private final Queue&lt;Runnable&gt; taskQueue; private volatile Thread thread; @SuppressWarnings(&quot;unused&quot;) private volatile ThreadProperties threadProperties; private final Executor executor; private volatile boolean interrupted; private final Semaphore threadLock = new Semaphore(0); private final Set&lt;Runnable&gt; shutdownHooks = new LinkedHashSet&lt;Runnable&gt;(); private final boolean addTaskWakesUp; private final int maxPendingTasks; private final RejectedExecutionHandler rejectedExecutionHandler; private long lastExecutionTime; @SuppressWarnings(&#123; &quot;FieldMayBeFinal&quot;, &quot;unused&quot; &#125;) private volatile int state = ST_NOT_STARTED; protected SingleThreadEventExecutor(EventExecutorGroup parent, Executor executor, boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedHandler) &#123; super(parent); this.addTaskWakesUp = addTaskWakesUp; this.maxPendingTasks = Math.max(16, maxPendingTasks); this.executor = ObjectUtil.checkNotNull(executor, &quot;executor&quot;); taskQueue = newTaskQueue(this.maxPendingTasks); rejectedExecutionHandler = ObjectUtil.checkNotNull(rejectedHandler, &quot;rejectedHandler&quot;); &#125; 可以看到它持有了一个thread，并且还在构造函数中new了一个TaskQueue可以接收任务执行，这个TaskQueue也证实了Netty的EventLoop不仅可以执行I/O任务，也可以把业务任务提交到TaskQueue里执行用户非I/O任务的业务任务。 NioEventLoop启动经过NioEventLoopGroup的初始化分析，我们知道了NioEventLoopGroup是个线程池，具体子线程维护在NioEventLoop中，并且在上篇文章服务端启动分析中我们也知道了eventLoop是在channel注册的时候和channel绑定了，接下来我们来看看NioEventLoop的线程到底是什么时候启动的。看SingleThreadEventEexecutor代码时，很容易就能注意到startThread()这个方法，从方法名就知道，该方法就是启动线程的方法。 1234567891011121314151617181920212223242526private void startThread() &#123; if (state == ST_NOT_STARTED) &#123; if (STATE_UPDATER.compareAndSet(this, ST_NOT_STARTED, ST_STARTED)) &#123; doStartThread(); &#125; &#125; &#125; private void doStartThread() &#123; assert thread == null; executor.execute(new Runnable() &#123; @Override public void run() &#123; thread = Thread.currentThread(); if (interrupted) &#123; thread.interrupt(); &#125; try &#123; SingleThreadEventExecutor.this.run(); success = true; &#125; catch (Throwable t) &#123; logger.warn(&quot;Unexpected exception from an event executor: &quot;, t); &#125; &#125;); &#125;//删除无关代码 可以看到SingleThreadEventExecutor内部维护了线程状态state，如果线程还没启动，那么先CAS把状态修改为启动状态，接着调用doStartThread方法，在doStartThread方法中通过子类传上来的executor对象调用execute方法，而这个executor对象其实是ThreadPreTaskExecutor类，execute方法则是通过threadFactory创建线程并启动线程。 123456789101112131415public final class ThreadPerTaskExecutor implements Executor &#123; private final ThreadFactory threadFactory; public ThreadPerTaskExecutor(ThreadFactory threadFactory) &#123; if (threadFactory == null) &#123; throw new NullPointerException(&quot;threadFactory&quot;); &#125; this.threadFactory = threadFactory; &#125; @Override public void execute(Runnable command) &#123; threadFactory.newThread(command).start(); &#125;&#125; 接着回到上面SingleThreadEventExecutor的doStartThread方法，线程启动后把当前的线程赋值给thread这个全局变量，接着调用SingleThreadEventExecutor的run方法，而这个方法不出意外是个抽象方法，其具体实现在子类NioEventLoop中 12345678910111213141516171819202122232425262728293031323334353637383940@Override protected void run() &#123; for (;;) &#123; try &#123; switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123; case SelectStrategy.CONTINUE: continue; case SelectStrategy.SELECT: select(wakenUp.getAndSet(false)); if (wakenUp.get()) &#123; selector.wakeup(); &#125; default: // fallthrough &#125; cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; if (ioRatio == 100) &#123; try &#123; processSelectedKeys(); &#125; finally &#123; // Ensure we always run tasks. runAllTasks(); &#125; &#125; else &#123; final long ioStartTime = System.nanoTime(); try &#123; processSelectedKeys(); &#125; finally &#123; // Ensure we always run tasks. final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125; &#125; &#125; catch (Throwable t) &#123; handleLoopException(t); &#125; &#125; 看到这个run方法，更加证实了之前我们说的eventLoop与selector绑定，通过一个忙循环监听I/O事件并处理的逻辑。那么到现在我们就只剩一个问题了，什么时候调用了这个startThread方法？要解答这个问题，我们还是回顾下Channel注册到Selector上的过程吧。 12345AbstractBootstrap.initAndRegister() -&gt;MultithreadEventLoopGroup.register(Channel channel) -&gt;SingleThreadEventLoop.register(Channel channel) -&gt;SingleThreadEventLoop.register(ChannelPromise promise) -&gt;AbstractChannel.AbstractUnsafe.register(EventLoop eventLoop,ChannelPromise promise) 在ServerBootstrap.bind的时候，会先初始化Channel和把Channel注册到Selector上，整个调用链如上所示，最终调用的是Unsafe的注册方法，unsafe的注册方法如下 12345678910111213141516171819202122232425@Override public final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; //忽略无关代码 AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) &#123; register0(promise); &#125; else &#123; try &#123; eventLoop.execute(new Runnable() &#123; @Override public void run() &#123; register0(promise); &#125; &#125;); &#125; catch (Throwable t) &#123; logger.warn( &quot;Force-closing a channel whose registration task was not accepted by an event loop: &#123;&#125;&quot;, AbstractChannel.this, t); closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125; &#125; &#125; 在这里会先把eventLoop绑定到channel上，然后调用eventLoop.inEventLoop()方法判断当前的线程是否就是该eventLoop持有的线程，因为是在初始化阶段，eventLoop的线程都还没启动，这里eventLoop.inEventLoop()返回当然是false，所以执行else阶段的代码，eventLoop.execute(new Runnable(){})这个execute是个接口方法，真正实现在SingleThreadEventExecutor类里面。 123456789101112131415161718192021@Override public void execute(Runnable task) &#123; if (task == null) &#123; throw new NullPointerException(&quot;task&quot;); &#125; boolean inEventLoop = inEventLoop(); if (inEventLoop) &#123; addTask(task); &#125; else &#123; startThread(); addTask(task); if (isShutdown() &amp;&amp; removeTask(task)) &#123; reject(); &#125; &#125; if (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &#123; wakeup(inEventLoop); &#125; &#125; 同样，这个execute方法先判断是否为eventLoop自己持有的线程在执行，在这当然是false，然后就来到了else部分，在这会执行两个方法startThread()和addTask(task)，还记得上面分析的startThread()么，这就串起来了，通过提交注册channel到selecot上的任务，触发线程的启动。启动之后把刚刚提交的注册任务添加到TaskQueue中，这个注册任务非I/O处理任务，所以提交到TaskQueue中。]]></content>
      <tags>
        <tag>JAVA,Netty,NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty4.x源码笔记之服务端启动]]></title>
    <url>%2F2019%2F06%2F23%2FNetty4.x%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0%E4%B9%8B%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[引言Netty是由JBOSS提供的一个java开源框架。Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。因其基于异步的、事件驱动的特性，Netty具有很优异的性能，接下来我会展开一系列的Netty源码的学习，源码分析基于Netty版本V4.1.0。希望自己能有所收获。 服务端启动示例在分析学习之前我们先按照国际惯例，我们先看看Netty服务端是怎么启动的:123456ServerBootstrap bootStrap = new ServerBootstrap(); bootStrap.group(bossGroup, workerGroup).channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024) .childHandler(MockChannelInitializer); bootStrap.bind(port).sync(); 首先需要先创建ServerBootstrap，设置双线程组（boss线程组和worker线程组，Netty的Reactor线程模型），配置好网络处理的属性如SO_BACKLOG（正在与客户端进行三次握手的队列，分两个队列，客户端调用connect给服务端发送syn包，进行第一次握手，服务端收到syn包返回一个shn包和ack标志进行第二次握手时，放进一个握手初始队列，当服务端接收到客户端返回的ack包时，tcp内核会将连接从握手初始队列转到新的队列中，最后在应用程序accept完成后从新队列中取出，如果SO_BACKLOG太小，accept线程处理不过来，服务端会拒绝新的连接）。最后绑定端口就ok了。值得一提的是Netty使用调用链的方式进行设值(主要是因为参数较多，类结构较为复杂，采用建造器模式)，比较符合本人的胃口，手动滑稽。 channel创建与初始化看完服务端启动示例，我们进入正题，开始分析源码。我们先直接看bootStrap.bind(port)方法。bind方法调用链如下1ServerBootstrap.bind -&gt; AbstractBootstrap.bind -&gt; AbstractBootstrap.doBind 经过层层嵌套调用，参数校验后最终调用了关键的AbstractBootstrap.doBind方法，该方法做了两件事情，第一，初始化NioServerSocketChannel实例和异步把channel注册到selector上；第二在注册成功后进行绑定端口。1234567891011121314151617181920212223242526272829303132333435private ChannelFuture doBind(final SocketAddress localAddress) &#123; final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) &#123; return regFuture; &#125; if (regFuture.isDone()) &#123; // At this point we know that the registration was complete and successful. ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; &#125; else &#123; // Registration future is almost always fulfilled already, but just in case it&apos;s not. final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; Throwable cause = future.cause(); if (cause != null) &#123; // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an // IllegalStateException once we try to access the EventLoop of the Channel. promise.setFailure(cause); &#125; else &#123; // Registration was successful, so set the correct executor to use. // See https://github.com/netty/netty/issues/2586 promise.registered(); doBind0(regFuture, channel, localAddress, promise); &#125; &#125; &#125;); return promise; &#125; &#125; 我们进入这个initAndRegister方法看看具体实现。123456789101112131415161718192021final ChannelFuture initAndRegister() &#123; //这个channelFactory实际是ReflectiveChannelFactory实例，该实例封装了NioServerChannel，调用newChannel()方法是通过反射拿到NioServerChannel实例 final Channel channel = channelFactory.newChannel(); try &#123; init(channel); &#125; catch (Throwable t) &#123; channel.unsafe().closeForcibly(); // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); &#125; ChannelFuture regFuture = group().register(channel); if (regFuture.cause() != null) &#123; if (channel.isRegistered()) &#123; channel.close(); &#125; else &#123; channel.unsafe().closeForcibly(); &#125; &#125; return regFuture; 上面的initAndRegister()方法调用了ReflectiveChannelFactory的newChannel方法，使用反射创建了NioServerSocketChannel实例（还记得在创建ServerBootstrap的时候channel(NioServerSocketChannel.class)么，是他是他就是他），NioServerChannel的构造函数比较关键，我们先来看看NioServerChannel创建实例的过程。12345678910111213public NioServerSocketChannel() &#123; this(newSocket(DEFAULT_SELECTOR_PROVIDER)); &#125; public NioServerSocketChannel(ServerSocketChannel channel) &#123; super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket()); &#125; private static ServerSocketChannel newSocket(SelectorProvider provider) &#123; //忽略无关代码 return provider.openServerSocketChannel(); &#125; 通过channelFactory反射创建channel实例使用的是无参构造方法，而这个构造函数先通过newSocket方法创建java原生的ServerSocketChannel实例，然后调用父类AbstractNioMessageChannel构造函数，值得注意的是这里把OP_ACCEPT的操作位传给了父类，而最终在祖父类AbstractNioChannel中设置了readInterestOp参数，同时把channel设置成非阻塞的。12345678910111213141516171819protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; super(parent); this.ch = ch; this.readInterestOp = readInterestOp; try &#123; ch.configureBlocking(false); &#125; catch (IOException e) &#123; try &#123; ch.close(); &#125; catch (IOException e2) &#123; if (logger.isWarnEnabled()) &#123; logger.warn( &quot;Failed to close a partially initialized socket.&quot;, e2); &#125; &#125; throw new ChannelException(&quot;Failed to enter non-blocking mode.&quot;, e); &#125; &#125; 在调用完父类的构造函数后NioServerSocketChannel还做了一件事，创建ChannelConfig实例，该实例是每个channel一些参数配置，比如高低水位设置，连接超时参数设置等，这个参数配置在下面channel初始化的时候会再见面的。到这NioServerSocketChannel的实例化已完成。 最后我们回到AbstractBootstrap的initAndRegister()方法，再看看实例化过后的channel初始化过程。1234567891011121314151617181920212223242526272829303132333435363738394041424344@Override void init(Channel channel) throws Exception &#123; //第一步，加载用户自定义的tcp服务端的options参数，比如上面提到的SO_BACKLOG，该参数关注的是有连接建立的时候情况，只在server端有 final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = options0(); synchronized (options) &#123; channel.config().setOptions(options); &#125; //第二步，加载用户自定义的attrs属性，初始化channel就设定的，一般是全局属性 final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = attrs0(); synchronized (attrs) &#123; for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: attrs.entrySet()) &#123; @SuppressWarnings(&quot;unchecked&quot;) AttributeKey&lt;Object&gt; key = (AttributeKey&lt;Object&gt;) e.getKey(); channel.attr(key).set(e.getValue()); &#125; &#125; //拿到ChannelPipeline ChannelPipeline p = channel.pipeline(); //第四步，拿到childOptions和childAttrs，这里的childOptions是设置接收客户端连接的参数的，比如连接超时，与发送客户端数据buffer的高低水位等，而childAttrs则一般为与客户端相关的参数，比如通过channel识别用户的一些数据可以维护到这里，childAttrs是线程安全的。childOptions关注的是channel accept之后的事情。 final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] currentChildOptions; final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] currentChildAttrs; synchronized (childOptions) &#123; currentChildOptions = childOptions.entrySet().toArray(newOptionArray(childOptions.size())); &#125; synchronized (childAttrs) &#123; currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(childAttrs.size())); &#125; p.addLast(new ChannelInitializer&lt;Channel&gt;() &#123; @Override public void initChannel(Channel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) &#123; pipeline.addLast(handler); &#125; pipeline.addLast(new ServerBootstrapAcceptor( currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;); &#125; channel的初始化就是把服务端配置和接入客户端的配置的上下文属性设置到channel中，也就是把上下文参数设置到上面我们说到过的ChannelConfig实例上。细节在这就不说了，有兴趣的可以查看源码，具体链路如下1AbstractBootstrap.init -&gt; ServerBootstrap.init -&gt; AbstractBootstrap.setChannelOption -&gt; NioServerSocketChannel.NioServerSocketChannelConfig.setOption 到这channel的实例化和初始化就讲完了，总结下来就是以下几点： ServerBootstrap.channel()绑定NioServerSocketChannel类型 调用AbstractBootstrap.doBind方法 使用反射把绑定的NioServerSocketChannel实例化 实例化创建java原生ServerSocketChannel实例 调用NioServerSocketChannel父类构造函数，设置readInterestOp为OP_ACCEPT(16)操作位，并把channel设置为非阻塞模式。 实例化ChannelConfig。 初始化channelConfig的各tcp连接option参数和channel的Attribute参数，添加Netty内部的channelHandler。 Channel注册在初始化完成之后，就开始了真正的注册，让我们回到initAndRegister()方法中看看注册过程,initAndRegister()方法拿到NioEventLoopGroup，也就是前面初始化ServerBootstrap的boss线程（accept线程），从group中拿出一个线程执行注册任务，去掉层层嵌套，真正注册的是register0方法。12345678910111213141516171819202122232425262728293031323334private void register0(ChannelPromise promise) &#123; try &#123; // check if the channel is still open as it could be closed in the mean time when the register // call was outside of the eventLoop if (!promise.setUncancellable() || !ensureOpen(promise)) &#123; return; &#125; boolean firstRegistration = neverRegistered; doRegister(); neverRegistered = false; registered = true; safeSetSuccess(promise); pipeline.fireChannelRegistered(); // Only fire a channelActive if the channel has never been registered. This prevents firing // multiple channel actives if the channel is deregistered and re-registered. if (isActive()) &#123; if (firstRegistration) &#123; pipeline.fireChannelActive(); &#125; else if (config().isAutoRead()) &#123; // This channel was registered before and autoRead() is set. This means we need to begin read // again so that we process inbound data. // // See https://github.com/netty/netty/issues/4805 beginRead(); &#125; &#125; &#125; catch (Throwable t) &#123; // Close the channel directly to avoid FD leak. closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125; &#125; register0方法首先判断调用register0的promise任务是否还在注册进行中就被取消了，接下来调用doRegister()方法，该方法实现就是调用了java原生的注册方法，将channel往selector上面注册。123456789101112131415161718192021@Override protected void doRegister() throws Exception &#123; boolean selected = false; for (;;) &#123; try &#123; selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; &#125; catch (CancelledKeyException e) &#123; if (!selected) &#123; // Force the Selector to select now as the &quot;canceled&quot; SelectionKey may still be // cached and not removed because no Select.select(..) operation was called yet. eventLoop().selectNow(); selected = true; &#125; else &#123; // We forced a select operation on the selector before but the SelectionKey is still cached // for whatever reason. JDK bug ? throw e; &#125; &#125; &#125; &#125; 上面javaChannel()方法就是拿到了java原生的SelectableChannel。通过调用该channel的register方法，来把该channel注册到与eventLoop绑定的selector上面。值得注意的是这里面的设置监听的操作位应该是OP_ACCEPT(16)的，监听accept事件的，而这里却是个0。只是注册一下，什么都不做。其实这里设置0只注册而不监听事件的原因是该类AbstractNioChannel是个公用的类，服务端NioServerSocketChannel和客户端NioSocketChannel都是用这个抽象的channel，而真正的感兴趣的事件在初始化NioServerSocketChannel和NioSocketChannel设定了，因为selectKey可以使用interestOps方法方便设置。还记得我们刚刚看NioSocketChannel实例化设置了readInterestOp为OP_ACCEPT了么？ 注册完成后往pipeline触发channelRegistered的事件，该事件只在inboundHandler中传播。最后再判断channel是否active了，如果active了再触发channelActive事件。最后再看看AbstractNioChannel这个门面类，该类代理的各种java原生API,比如初始化selector等。 地址绑定在把channel注册到NioEventLoop上的selector之后，最后我们再倒回来看看bind0()方法，这个方法除了绑定本地地址和端口，最重要的方法就把上面的只注册了0的操作位给修正为真正OP_ACCEPT(16)到selectionKey上。请看下面的代码。1234567891011121314151617private static void doBind0( final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) &#123; // This method is invoked before channelRegistered() is triggered. Give user handlers a chance to set up // the pipeline in its channelRegistered() implementation. channel.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; if (regFuture.isSuccess()) &#123; channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); &#125; else &#123; promise.setFailure(regFuture.cause()); &#125; &#125; &#125;); &#125; 可以看到doBind0方法是将bind的功能封装成一个任务提交到了accept线程池中，经过层层嵌套最终是ChannelPipeline的头结点head调用了unsafe.bind()方法，调用链路如下1AbstractChannel#bind(xxx)-&gt;DefaultChannelPipeline#bind(xx)-&gt;tail.bind(xxx)-&gt;tail.invokeBind(xxx)-&gt;head.bind(xxx)-&gt;unsafe.bind(xxx)) 关于Pipeline我们可以看成调用链，和servlet的filterChain一样使用责任链模式在事件触发后事件在pipeline中流转，pipeline我们在源码分析其他文章中再细聊，这里不是我们关注的重点，这里我们的重点是这个unsafe对象。我们看看这个unsafe对象。123456789101112131415161718192021222324252627282930313233interface Unsafe &#123; RecvByteBufAllocator.Handle recvBufAllocHandle(); SocketAddress localAddress(); SocketAddress remoteAddress(); void register(EventLoop eventLoop, ChannelPromise promise); void bind(SocketAddress localAddress, ChannelPromise promise); void connect(SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise); void disconnect(ChannelPromise promise); void close(ChannelPromise promise); void closeForcibly(); void deregister(ChannelPromise promise); void beginRead(); void write(Object msg, ChannelPromise promise); void flush(); ChannelPromise voidPromise(); ChannelOutboundBuffer outboundBuffer(); &#125;&#125; unsafe对象是个接口，具体实现有两个：AbstractNioMessageChannel.NioMessageUnsafe和AbstractNioByteChannel.NioByteUnsafe，分别对应NioServerSocketChannel和NioSocketChannel。看接口定义我们大概就知道unsafe类是用来封装java底层的通信方法，使用unsafe实现类作为代理类代理底层java通信实现。现在我们来看下这个unsafe.bind方法。12345678910111213141516171819202122232425262728293031323334353637383940public final void bind(final SocketAddress localAddress, final ChannelPromise promise) &#123; assertEventLoop(); if (!promise.setUncancellable() || !ensureOpen(promise)) &#123; return; &#125; // See: https://github.com/netty/netty/issues/576 if (Boolean.TRUE.equals(config().getOption(ChannelOption.SO_BROADCAST)) &amp;&amp; localAddress instanceof InetSocketAddress &amp;&amp; !((InetSocketAddress) localAddress).getAddress().isAnyLocalAddress() &amp;&amp; !PlatformDependent.isWindows() &amp;&amp; !PlatformDependent.maybeSuperUser()) &#123; // Warn a user about the fact that a non-root user can&apos;t receive a // broadcast packet on *nix if the socket is bound on non-wildcard address. logger.warn( &quot;A non-root user can&apos;t receive a broadcast packet if the socket &quot; + &quot;is not bound to a wildcard address; binding to a non-wildcard &quot; + &quot;address (&quot; + localAddress + &quot;) anyway as requested.&quot;); &#125; boolean wasActive = isActive(); try &#123; doBind(localAddress); &#125; catch (Throwable t) &#123; safeSetFailure(promise, t); closeIfClosed(); return; &#125; if (!wasActive &amp;&amp; isActive()) &#123; invokeLater(new Runnable() &#123; @Override public void run() &#123; pipeline.fireChannelActive(); &#125; &#125;); &#125; safeSetSuccess(promise); &#125; 可以看到第一件事就是调用java原生的bind方法绑定地址和接口然后channel被激活，激活之后立马调用pipleline.fireChannelActive()方法，事件在pipleline中流转。12345@Override public final ChannelPipeline fireChannelActive() &#123; AbstractChannelHandlerContext.invokeChannelActive(head); return this; &#125; 事件最先在头结点获取，而头结点获取到channelActive事件后做了两件事，先把事件传递下去，然后调用readIfIsAutoRead()方法，而该方法先会判断channel.config().isAutoRead()，如果true那么调用AbstractChannel的read方法。123456789101112@Overridepublic void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ctx.fireChannelActive(); readIfIsAutoRead();&#125;private void readIfIsAutoRead() &#123; if (channel.config().isAutoRead()) &#123; channel.read(); &#125;&#125; 这个config()其实就是在初始化NioServerSocketChannel的时候初始化的。1234public NioServerSocketChannel(ServerSocketChannel channel) &#123; super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket()); &#125; 就是这个NioServerSocketChannelConfig。回到isAutoRead()方法public boolean isAutoRead() { return autoRead == 1; }就这个方法判断的，而autoRead是全局变量初始化就是1所以一定是true。所以AbstractChannel的read方法一定会调用。12345@Override public Channel read() &#123; pipeline.read(); return this; &#125; 看上面的代码，调用pipeline.read()方法，所以read()方法又经过层层调用（tail.invokeRead()-&gt;head.read()-&gt;unsafe.beginRead()），来到unsafe.beginRead()方法，而这个beginRead()是会修改selectionKey的interestOps的也就是在初始化NioServerSocketChannel的时候设置的SO_ACCEPT(16)。到这就完成了服务端的accept过程，只要有客户端连接进来，selector就能够select进来。这部分我们在讲EventLoopGroup的时候细讲。123456789101112131415@Overrideprotected void doBeginRead() throws Exception &#123; // Channel.read() or ChannelHandlerContext.read() was called final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) &#123; return; &#125; readPending = true; final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) &#123; selectionKey.interestOps(interestOps | readInterestOp); &#125;&#125; 到这里netty的服务端启动源码分析就结束了。总结一下就是以下几点: 实例化ServerBootstrap对象，设置具体的NioServerSocketChannel.class类。 调用initAndRegister方法初始化NioServerSocketChannel实例，在初始化Channel实例时拿到了java原生的ServerSocketChannel实例，并且实例化ChannelConfig，最后将channel设置为非阻塞模式，把readInterestOp属性设为OP_ACCEPT操作位。 实例化NioServerSocketChannel时调用父类构造函数，生成channel唯一id，实例化unsafe对象这个java底层通信的代理类，实例化Pipeline。 实例化过后根据用户设置的options和childOptions参数设置到ChannelConfig中。 把channel注册到NioEventLoop上 把channel注册到与NioEventLoop绑定的Selector上 绑定本地ip和端口触发channelActive事件，调用unsafe.doBeginRead方法把selectionKey监听的操作位修改为OP_ACCEPT操作位。开始accept客户端的连接。]]></content>
      <tags>
        <tag>JAVA,Netty,NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java基础之ReentrantLock]]></title>
    <url>%2F2019%2F04%2F29%2Fjava%E5%9F%BA%E7%A1%80%E4%B9%8BReentrantLock%2F</url>
    <content type="text"><![CDATA[引言之前我们说了java的synchronized同步关键字，解析了jdk1.6之后对其进行一系列优化原理分析，今天我们聊一聊java中另一个锁ReentrantLock。 synchronized同步关键字实现同步或者说独占是通过JVM底层进行系统调用操作Mutex Lock（互斥锁）实现的，而ReentrantLock则是通过上层代码实现，某种意义上可以说是锁的软实现（当然还是需要通过调用大量的Unsafe类进行CAS操作，最终还是要调用JVM的native方法）。所以不涉及操作系统层面的系统调用不存在线程切换和内核区和用户区的切换的开销，在jdk1.6之前性能是比synchronized好的。按照惯例，我们先看ReentrantLock怎么用。123456789public void test() &#123; ReentrantLock lock = new ReentrantLock(); try&#123; lock.lock(); &#125;finally &#123; lock.unlock(); &#125;&#125; AQS看ReentrantLock的源码我们会看到它是基于AbstractQueuedSynchronizer实现的，而AbstractQueuedSynchronizer是一个抽象的工具类，提供了独占或者共享某一个状态的工具，而独占正是Lock的核心需求，所以我们可以在ReentrantLock、Semaphore、CountDownLatch中看到它的身影。我们先看看AQS的全局变量声明。12345678910111213141516//定义了一个Node内部类 static final class Node&#123;&#125;private transient volatile Node head;/** * Tail of the wait queue, lazily initialized. Modified only via * method enq to add new wait node. */private transient volatile Node tail;/** * The synchronization state. */ //同步状态，大于0：线程已获得锁、0：无锁状态private volatile int state; AbstractQueuedSynchronizer提供一个FIFO的双向队列存放等待的线程并且使用一个volatile的state变量来保证同一时刻只有一个线程在临界区内。换句话说就是通过一个变量来记录锁的状态。接着看看这个存放等待锁的线程队列。1234567891011121314151617181920212223242526//共享模式static final Node SHARED = new Node();//独占模式static final Node EXCLUSIVE = null;//如果当前node的waitStatus是CANCELLED状态那么该node代表将放弃锁竞争，将会直接被删除static final int CANCELLED = 1;//如果当前node的waitStatus是SIGNAL状态代表该node的线程将会被挂起（parking）static final int SIGNAL = -1;//如果为CONDITION状态代表该线程在等待调度static final int CONDITION = -2;/** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */static final int PROPAGATE = -3;volatile int waitStatus;volatile Node prev;volatile Node next;volatile Thread thread;Node nextWaiter; 单独看AQS其实很难理解，我们进到ReentrantLock里面面具体锁的实现中看看ReentrantLock到底是怎么配合AQS来实现独占锁的。 ReentrantLock实现原理ReentrantLock并非是直接继承AbstractQueuedSynchronizer而是让Sync继承AQS，ReentrantLock持有Sync对象，ReentrantLock内部的类结构如下12345678910111213 +-------------------------------+ | AbstractQueuedSynchronizer | +--------------^----------------+ | | +------------------------------+ | Sync | +--------^----------^----------+ | | | |+-----------------------+ +-----------------------+| NonfairSync | | FairSync |+-----------------------+ +-----------------------+ 在ReentrantLock中分公平锁和非公平锁，默认使用非公平锁，你可以通过构造函数传入一个boolean类型的参数来决定使用公平锁还是非公平锁。 public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } 按照上的用法，我们先进入到FairSync中看lock方法final void lock() { acquire(1); }，代码很简单，就一行，看方法名大概就知道是获取锁的意思，再进入这个acquire方法里面。123456789101112131415161718192021222324252627282930public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); //获取当前锁的状态 int c = getState(); //如果当前是无锁状态，那么直接判断是否有前驱结点，如果没有前驱结点说 //明没有等待获取锁的线程，可以直接尝试获取锁 if (c == 0) &#123; //判断是否有前驱结点 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; //将当前线程设置为exclusiveOwnerThread，锁被当前线程持有 setExclusiveOwnerThread(current); return true; &#125; &#125; //如果锁就是被当前线程持有，就是线程重入了，那么直接更新state值 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; 这段代码很简单，先尝试获取锁，尝试获取锁的具体实现是先拿到state的值，如果是state==0，说明当前没有线程获取锁，再看看现在队列里面有没有等待的线程，如果没有那么直接尝试CAS将state设置为1，如果且将线程设为自己。如果state不等于0但是当前exclusiveOwnerThread是自己那么直接更新当前state值，实现重入。这里面使用了java中短路的特性，如果tryAcquire成功后面的acquireQueued就不会被执行了。如果失败了意味着当前锁已经被别的线程持有，那么就需要添加一个waiter结点来存放当前尝试获取锁的线程，接下来我们先看看addWaiter方法。123456789101112131415161718192021222324252627282930313233343536373839404142//在ReentrantLock中mode都是独占的，所以mode是nullprivate Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; //判断尾部结点是否为空 if (pred != null) &#123; //先把新加的结点的前驱赋值给原来的tail结点，因prev结点和next结点是volatile修饰的，所以直接设值是线程安全的，所以只有在设置tail结点需要CAS操作 node.prev = pred; //CAS把新结点设置tail结点 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //运行到这里说明线程等待队列还是空的 enq(node); return node;&#125; /** *1、这里通过一个死循环方式调用CAS，即使有高并发的场景，无限循环将会最终成功把当前线程追加到队尾 * 2、第一次循环tail肯定为null，则会初始化一个默认的node，并将head=tail指向该node * 3、第二次循环的时候，会将当前node追加到1中创建的node尾部 */ private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 在添加waiter时先新建一个node元素，如果尾部结点为不为空，那先将node的前驱指向tail，再尝试使用CAS方式将当前要添加的node设为tail结点，这里值得注意的是只有将新加入的node设为tail结点时用了CAS操作，原因是Node的成员变量prev和next被volatile修饰了，直接进行设值是线程安全的，想了解volatile的原理可以看我之前写得《如何正确使用volatile》。如果tail结点为空那么说明现在队列还是空的，需要初始化，这里使用延迟加载的方式，等到在添加结点的时候再初始化。接下来再进acquireQueued方法。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; //中断标志 boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); //又一次判断此时node的前驱结点是否为头结点，如果是头结点说明之前获得锁的线程已经执行完了，此时尝试拿锁 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don&apos;t park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 这个方法分几步： 判断当前结点的前驱是否为头结点，如果是头结点那么说明它有资格去竞争锁，那么再执行一次tryAcquire尝试获取锁，如果获取锁成功那么直接将当前node设为头结点。 如果当前结点的前驱不是头结点那么再看结点线程取锁失败后要不要挂起，因为在ReentrantLock中Node结点初始化时并没有初始化waitStatus， 如果前驱结点不是头结点，会进入shouldParkAfterFailedAcquire方法，而该方法将当前结点的前驱结点的waitStatus设为SIGNAL,等到第二次循环时将线程挂起。 从上面的代码来看，ReentrantLock开发人员是多么不希望尽可能让新进来的线程直接通过CAS操作就拿到锁，在对线程挂起前进行了三次的tryAcquire操作，这也从侧面体现了挂起线程和对线程的唤起操作涉及到线程切换是多么的消耗性能。 看完公平锁，让我们看看非公平锁，到底公平锁公平在哪里。同样，我们先从加锁圆头看是看lock.lock()方法。123456final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; 和公平锁不一样，只要有线程请求锁，立马CAS一把尝试拿锁，如果成功就拿到了锁，并不会讲究先来后到，竞争到锁就是非公平锁的唯一目的。如果CAS设值state失败说明竞争锁失败，才走acquire分支，而acquire方法在非公平锁中的实现也有点不同。1234567891011121314151617181920212223protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; //就这里和公平锁不同 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; 可以看到，非公平锁里面的nonfairTryAcquire方法和公平锁tryAcquire唯一的区别就是非公平锁不会判断当前是否有线程在队列中等待锁，直接CAS一把锁，简直是只要发现当前无锁状态直接就去抢，这也体现了非公平性。 锁释放按我们上面说的当多个线程尝试获取锁时，只有一个线程可以拿到锁，而其他的线程会放到双向队列挂起等待拿到锁的线程运行结束后释放锁。接下来看看锁释放最后一步。123456789101112131415161718192021222324252627public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; //找到头结点，唤醒头结点的后继结点去竞争锁了 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; protected final boolean tryRelease(int releases) &#123; //释放锁将state-1 int c = getState() - releases; //若当前线程与独占锁线程不一致，抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; //只有state=0时才算真正释放锁，独占锁线程字段清空 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; //更新state值 setState(c); return free; &#125; 锁释放在公平锁和非公平锁上都是统一实现，调用父类AQS的实现，毕竟公平和不公平的点是在获取锁上，现在锁拿到了，执行完都是要释放的。锁释放很简单： 更新state值，每次release都是state-1，直到state等于0才算真正释放锁，毕竟我们是可重入的锁。 state等于0后把exclusiveOwnerThread字段置空，腾出位置。 找到头结点的后继结点，进行unpark操作唤醒头结点的后继结点，通知它可以起来竞争锁了。 总结经过ReentrantLock的源码分析，我们直到可重入锁是基于AbstractQueuedSynchronizer实现的，通过使用CAS操作一个状态值state完成线程的独占，实现同一时刻只有一个线程可以获得锁，而其他竞争失败的线程封装成一个个Node，将Node存放到维护的双向队列里面，通过忙循环的方式将竞争失败的线程进行parking操作，将这些线程挂起，直到获得锁的线程执行完成，退出临界区，队列的头结点才会被唤醒，继续竞争锁。对于ReentrantLock来说具有公平锁和非公平锁的概念，公平锁顾名思义获取锁是公平的，按照FIFO（先进先出），每次只有头结点有机会竞争锁，而非公平锁则是直接竞争不管是不是头结点。ReentrantLock默认是使用非公平锁的，毕竟非公平锁若有新线程进入有可能不需要挂起就可以拿到锁，性能上比公平锁要好，毕竟要更细粒度的控制肯定要更多资源支持的。 和synchronized相比，ReentrantLock优势很明显，ReentrantLock支持可中断加锁，判断线程中断标志位，如果中断状态下可以抛出中断异常，并且ReentrantLock支持获取锁超时，并且支持condition，对生产者消费者模式的实现可以更为优雅，ReentrantLock对synchronized是一个很好的扩展。]]></content>
      <tags>
        <tag>JAVA,锁,多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java基础之equals方法和hashcode方法]]></title>
    <url>%2F2019%2F02%2F23%2Fjava%E5%9F%BA%E7%A1%80%E4%B9%8Bequals%E6%96%B9%E6%B3%95%E5%92%8Chashcode%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[引言java基础系列之前已经剖析过好几个java里面比较关键的关键字了，今天我们来讲讲容易被人忽视的equals方法和hashcode方法。为什么说容易被人忽视，因为这两货就算你理他，也不会出什么问题，java的上帝类Object自带equals方法和hashcode方法，所以不用你操心，然鹅只要你根据业务需求来重写equals方法，就很有可能出错，今天我们就来看看这两个方法。 equals方法每个对象默认都是用上帝类Object的equals方法：123public boolean equals(Object obj) &#123; return (this == obj); &#125; 非常简单粗暴的直接判断是否为当前对象，如果不是直接返回false。如果你自定义的对象要判断两个对象是否相等直接用父类的equals方法是不行的，做个试验：123456789101112131415public class TestEquals &#123; private String testName; private Integer age; //省略 getter setter方法&#125; TestEquals test1 = new TestEquals(); test1.setTestName(&quot;test&quot;); test1.setAge(10); TestEquals test2 = new TestEquals(); test2.setTestName(&quot;test&quot;); test1.setAge(10); System.out.println(test1.equals(test2)); 上面100%返回false，因为是两个对象，但是在业务上很可能是需要返回true的，因为数据都一样需要它是equal的。所以在实际开发场景下重写equals方法的概率还是很大的。 在重写equals方法时我们需要注意遵守以下条件： 自反性：x.equals(x)必须返回true。 对称性：x.equals(y)与y.equals(x)的返回值必须相等。 传递性：x.equals(y)为true，y.equals(z)也为true，那么x.equals(z)必须为true。 一致性：如果对象x和y在equals()中使用的信息都没有改变，那么x.equals(y)值始终不变。 对于任何非空引用值x，x.equal(null)应返回false。 重写equals方法最佳实践可以按照以下步骤来做: 使用==操作符判断是否当前对象（判断参数是否为该对象的引用），如果是直接返回true。 使用instanceof判断是否为目标类的实例如果不是直接返回false。 根据你的业务逻辑使用Objects.equals方法判断各个字段是否相同。 重写equals方法后必须重写hashcode方法。 hashcode方法hashcode方法很多初学者一开始都很迷惑这个方法有什么用，当你看了java的集合之后应该会找到答案。对hashcode在集合类里面是有作用的特别是底层数据结构是hash表的集合类如HashMap、HashSet等。 以HashMap为例，在往HashMap中存Element时，首先会先调用key的hashcode方法，并且进一步根据HashMap的hash方法进行再哈希，进而找到需要存放的地址。并且HashMap的元素是不重复的，如果重复插入相同的对象是value是会被覆盖的。HashMap的get方法也是一样先要通过hash方法找到Element在哈希表上位置。上面说到重写了equals方法必须重写hashcode方法是因为如果只重写equals方法会打破元素不重复的规则，重复插入相同的key并不会在哈希表上找到同一个位置，原因是hashcode不一致，最后将会导致相同的几个元素在哈希表上的多个位置上出现。如果你equals方法都不重写估计你put进HashMap的元素再get出来很可能返回NULL。有兴趣的同学可以自己去试验下。多说一句，有的人说为啥我如果key是String类型就没问题，那是因为String的equals方法和hashcode方法已经被重写过了。 hashcode方法重写的最佳实践 定义一个种子数。 用该种子数*31+你的字段的hashcode赋值例如:123456public int hashcode() &#123; int hash = 17; hash = hash*31+field1.hashcode(); hash = hash*31+filed2.hashcode(); ........&#125; 或者你也可以使用Objects.hashcode方法，把你要比较的fields当做参数传进去就可以了。]]></content>
      <tags>
        <tag>JAVA,equals,hashcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java基础之final关键字]]></title>
    <url>%2F2019%2F02%2F20%2Fjava%E5%9F%BA%E7%A1%80%E4%B9%8Bfinal%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[引言java关键字中final关键字绝对是我用的最勤最多的关键字之一。毕竟大量的常量定义总会带上final关键字，为什么常量定义会加上final关键字？final关键字如何用？为什么要用final关键字？接下来让我们聊聊final关键字。 用法 final关键字可以作用在类上，如果用来修饰类，则该类无法被继承。你如果使用final关键字修饰类，说明你已经很明确不希望该类被继承，不希望该类的方法被子类覆盖，换句大白话来说就是不想让别人改掉你的方法。jdk中String类就是使用final修饰的。 final关键字可以作用在方法上，如果用来修饰方法，则该方法无法被子类覆盖。 final关键字可以作用在变量上，final修饰过的变量不允许改变（如果是引用类型，不可变的是引用，引用类型的内容还是可以变的，如果作用在基本数据类型上，不可变的则是数据），也就是说只能赋值一次。 final关键字可以作用在参数上，同样final关键字作用在方法参数上保证该参数是不可变的。 在java中有以上几种方式来使用final关键字，虽然有这么多种方式，但是使用到final关键字通常都是想告诉人们被final关键字修饰的“都是无法改变的”。不想做改变的可能出于两种理由：设计或效率，且不可变的特性可以保证在多线程情况下变量的安全性。被final修饰的变量是不可变的，所以在多线程情况下，final域天然线程安全，并且不需要保证final线程安全而做其他额外操作。对于final域，编译器和处理器会遵从两点禁止指令重排序的情况：121. 在构造函数内对final域写入，与随后把这个构造的对象赋值给引用对象两个操作之间不允许重排序。2. 在首次读持有final域对象的引用和首次读该对象的final域字段之间不允许重排序。 第一点，翻译成中文就是在构造函数内写入final域值前是不允许把该对象赋值给其他对象，必须等final域写入后，换句话说就是final关键字保证了该变量的可见性。为了保证上述所述，编译器会自构造函数返回前插入StoreStore屏障，禁止final域重排序到构造函数之外。 第二点，同理也是为了保证final域的可见性，保证先读到持有final域对象的引用再读到final域字段，编译器通过在这两个操作之间插入LoadLoad屏障，保证永远读到final域字段的值都是正确的。 顺便说一嘴，在编译器层面也会对有final关键字修饰的方法进行优化，该优化叫方法内联。其实我们理解起来很简单，就是编译器会把多个final修饰的方法体内联到同一个方法体里面执行，这么做减少了方法调用的成本例如栈帧的创建等，也可以因为内联起来做更多的优化（比如公共子表达式消除等）。但并不是编译器有这些优化就所有的方法都final了，如果一个方法很大，程序代码膨胀之后可能就看不到方法内联带来的任何性能提高了，因为所带来的性能提高会因为花费于方法内的时间量而被缩减，所以不要陷入对仓促优化的强烈渴望中，如果你的程序很慢，final关键字的优化的那丁点性能无论如何也不能有质的突破。使用final关键字还是要看你实际的用途，如果某些变量确实不怎么改变，如常量，或者确实你希望某个对象在赋值之后不希望被后面的逻辑改变该对象的引用，那就大方的使用final关键字吧。 参考：深入理解 Java 内存模型（六）——final]]></content>
      <tags>
        <tag>final</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[thread interrupt机制]]></title>
    <url>%2F2018%2F11%2F20%2Fthread%20interrupt%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[最近在工作中碰到同事使用interrupt，刚好本人并没怎么用过这个interrupt机制，只知道这个方法是用来中断线程的，对于阻塞的线程，我们可以调用interrupt方法中断线程，并且还听说这个方法并不靠谱，今天对interrupt机制做个总结。 对于java语言来说，不会用一个api，最简单粗暴的方式就是去看看JDK源码，看看道格李大神的解释。在interrupt方法中第一句注释就是 Interrupts this thread. 根据这个解释似乎这个interrupt就是给开发人员用来中断线程的。但是本人做了个小测试。测试代码如下 123456789101112131415161718192021222324252627282930313233343536package rest;public class TestThread implements Runnable &#123; private int count; public TestThread(int count) &#123; this.count=count; &#125; public void run() &#123; for (int i=0;i&lt;count;i++)&#123; System.out.println(&quot;current count is: &quot;+i); &#125; System.out.println(&quot;the thread: &quot;+Thread.currentThread().getName()+&quot; is end&quot;); &#125;&#125;package rest;public class TestInterrupt &#123; public static void main(String[] args)throws Exception&#123; TestThread testThread = new TestThread(10000); Thread thread = new Thread(testThread); thread.start(); Thread.sleep(10); thread.interrupt(); System.out.println(&quot;1:::::&quot;+thread.isInterrupted()); &#125;&#125; 这段代码很简单，就是创建个线程进行counter，启动线程之后让主线程sleep 10毫秒，再调用interrupt方法企图停止线程。但是结果大概各位都猜到了，testThread仿佛啥都没有发生直接运行到结束，并没有按照我们的想法中断。到底是什么情况，无法中止线程为啥还要提供这个方法出来呢？让我们带着问题去看看JDK源码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Interrupts this thread. * * &lt;p&gt; Unless the current thread is interrupting itself, which is * always permitted, the &#123;@link #checkAccess() checkAccess&#125; method * of this thread is invoked, which may cause a &#123;@link * SecurityException&#125; to be thrown. * * &lt;p&gt; If this thread is blocked in an invocation of the &#123;@link * Object#wait() wait()&#125;, &#123;@link Object#wait(long) wait(long)&#125;, or &#123;@link * Object#wait(long, int) wait(long, int)&#125; methods of the &#123;@link Object&#125; * class, or of the &#123;@link #join()&#125;, &#123;@link #join(long)&#125;, &#123;@link * #join(long, int)&#125;, &#123;@link #sleep(long)&#125;, or &#123;@link #sleep(long, int)&#125;, * methods of this class, then its interrupt status will be cleared and it * will receive an &#123;@link InterruptedException&#125;. * * &lt;p&gt; If this thread is blocked in an I/O operation upon an &#123;@link * java.nio.channels.InterruptibleChannel InterruptibleChannel&#125; * then the channel will be closed, the thread&apos;s interrupt * status will be set, and the thread will receive a &#123;@link * java.nio.channels.ClosedByInterruptException&#125;. * * &lt;p&gt; If this thread is blocked in a &#123;@link java.nio.channels.Selector&#125; * then the thread&apos;s interrupt status will be set and it will return * immediately from the selection operation, possibly with a non-zero * value, just as if the selector&apos;s &#123;@link * java.nio.channels.Selector#wakeup wakeup&#125; method were invoked. * * &lt;p&gt; If none of the previous conditions hold then this thread&apos;s interrupt * status will be set. &lt;/p&gt; * * &lt;p&gt; Interrupting a thread that is not alive need not have any effect. * * @throws SecurityException * if the current thread cannot modify this thread * * @revised 6.0 * @spec JSR-51 */ public void interrupt() &#123; if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) &#123; Interruptible b = blocker; if (b != null) &#123; interrupt0(); // Just to set the interrupt flag b.interrupt(this); return; &#125; &#125; interrupt0(); &#125; 这个interrupt方法很简单，就只有十几行代码，初看这个代码还是有几点不明白的，第一：Interruptible是什么鬼，有什么作用？第二：interrupt0()方法又是什么作用？第二点很好回答，因为代码后面注释就说了 Just to set the interrupt flag interrupt0方法就是设置中断标志位。再看看interrupt()上面的注释后我们应该可以解答。注释大概意思是如果当前线程调用了sleep()/wait()/join()方法，中断状态标志会被清除，并且线程会接收一个中断异常。翻译成中文就是说当前线程阻塞了，如果你调用了interrupt方法，这个线程就会被中断，并且抛出中断异常。结合Interruptible的注释 The object in which this thread is blocked in an interruptible I/O operation, if any. The blocker’s interrupt method should be invoked after setting this thread’s interrupt status. 意思是说在可中断的I/O操作（如果有的话）中阻止该线程的对象。在设置线程中断状态后，应调用拦截器的中断方法。这么来看sleep()/wait()/join()就是所说的可中断的操作，所以调用了sleep()/wait()/join()方法后Interruptible会被赋值，Interruptible b = blocker中的b是不为空的，并且会先行设置当前线程的中断标志位，所以会执行if语句中的代码调用interrupt0方法来清除中断状态标志位然后调用Interruptible的interrupt方法真正的中断当前线程。也就是说非注释上说的这些阻塞方法调用或者可中断I/O调用，你使用thread对象的interrupt()方法是不能中断线程的，interrupt0()这个方法只是设置中断标志而已，并没有什么*用。那么有人要问了，那正常运行的线程我想中断停止它怎么办？很正常的需求啊，很多业务都很可能要这个需求，比如我用多个线程去抢一张火车票，有一个线程抢到了我就可以直接终止其他线程。我会建议你使用自定义的一个标志位，这个标志位用volatile修饰让标志具有可见性。简单的例子如下： 123456789101112131415161718192021222324252627282930313233343536373839404142public class TestThread implements Runnable &#123; private int count; private volatile boolean stop=false; public TestThread(int count) &#123; this.count=count; &#125; public void shutdownNow()&#123; this.stop=true; &#125; public void run() &#123; for (int i=0;i&lt;count;i++)&#123; System.out.println(&quot;current count is: &quot;+i); if(stop) &#123; System.out.println(&quot;aaaa i&apos;m be stoped!!!&quot;); return; &#125; &#125; System.out.println(&quot;the thread: &quot;+Thread.currentThread().getName()+&quot; is end&quot;); &#125;&#125;public class TestInterrupt &#123; public static void main(String[] args)throws Exception&#123; TestThread testThread = new TestThread(10000); Thread thread = new Thread(testThread); thread.start(); Thread.sleep(10); testThread.shutdownNow(); &#125;&#125;]]></content>
      <tags>
        <tag>thread,interrupt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java HTTP多线程断点续传下载]]></title>
    <url>%2F2018%2F07%2F21%2Fjava%20HTTP%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%96%AD%E7%82%B9%E7%BB%AD%E4%BC%A0%E4%B8%8B%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[HTTP协议可以说是当前最最重要的通信协议之一，HTTP协议作为应用层协议作用在TCP协议之上，是现在最广泛、最通用的通信协议。正因为如此，今天来说一说HTTP的断点续传功能。 断点续传：顾名思义就是说在数据传输时因网络原因出现下载中断，在这个时候可以在中断的地方继续下载而不需要重新下载。HTTP的断点续传原理比较简单，在HTTP1.1(RFC2616)中定义了断点续传相关的HTTP头Range和Content-Range字段。在请求某资源时，HTTP头加上Range头，如果服务器支持断点续传功能，那么你可以获取一个带有Content-Range的响应头的响应。 断点续传：顾名思义就是说在数据传输时因网络原因出现下载中断，在这个时候可以在中断的地方继续下载而不需要重新下载。HTTP的断点续传原理比较简单，在HTTP1.1(RFC2616)中定义了断点续传相关的HTTP头Range和Content-Range字段。在请求某资源时，HTTP头加上Range头，如果服务器支持断点续传功能，那么你可以获取一个带有Content-Range的响应头的响应。 一个HTTP断点续传基本步骤如下： 客户端请求某资源，HTTP头加上Range头，如： Range:bytes=1024-2048； 请求成功，服务器返回带COntent-Range响应头的响应，如：Content-Range:bytes 1024-2048/512000； 此时网络中断，客户端已经记录了当前下载的进度。 客户端继续请求资源，此时Range头将从2048开始。 资源下载成功。接下来看代码： public class MultiDownloadProcessor { private String url; private String targetPath; private int threadCount; private long contentLength; private static final String FILE_WRITE_READ = &quot;rw&quot;; private static final String FILE_WRITE_READ_MODIFY = &quot;rwd&quot;; private static final String SUFFIX_TEMP = &quot;.tmp&quot;; private static final String RANGE_HEAD = &quot;Range&quot;; private static final int SNIFF_BYTES = 1024; private static final int BUFFER = 1024 * 1024; private static final String CONTENT_RANGE = &quot;Content-Range&quot;; private static final String CONTENT_RANGE_DASH = &quot;/&quot;; private static final int TEMP_FILE_SKIP = 8; public MultiDownloadProcessor(String url, String targetPath, int threadCount) { this.url = url; this.targetPath = targetPath; this.threadCount = threadCount; } public void download() throws Exception { long startTime = System.currentTimeMillis(); boolean isRange = sniffDownload(); System.out.println(&quot;contentLength:&quot; + this.contentLength); File file = new File(targetPath, getFileName(url)); //提前初始化好要下载文件 initFile(file); if (isRange) { //分片下载 partialDownload(file); System.out.println(&quot;down!!!!!!,use time：&quot; + (System.currentTimeMillis() - startTime)); }else { //......简单单线程下载 } } private void partialDownload(File file) throws Exception { File tempFile = new File(targetPath, fetchFileName(url) + SUFFIX_TEMP); List&lt;FutureTask&lt;Boolean&gt;&gt; list = new ArrayList&lt;&gt;(); if(contentLength&lt;=0) { throw new Exception(&quot;contentLength is illegal&quot;); } //分块下载，建议设一个阈值，大于这个值才多线程下载 long blockSize = contentLength / threadCount; for (int threadId = 0; threadId &lt; threadCount; threadId++) { long startIndex = threadId * blockSize; long endIndex = (threadId + 1) * blockSize; if (threadId == (threadCount - 1)) { endIndex = contentLength - 1; } DownloadHandler downloadHandler = new DownloadHandler(threadId, startIndex, endIndex, file); FutureTask&lt;Boolean&gt; result = new FutureTask&lt;&gt;(downloadHandler); Thread thread = new Thread(result); thread.start(); list.add(result); } for (FutureTask&lt;Boolean&gt; futureTask : list) { futureTask.get(); } cleanTemp(tempFile); } private void initFile(File file) throws Exception { //做得更好可以进来就创建一个下载系统自己的下载文件名，当下载完成就把名字改为目标名，chrome就是这么做的 RandomAccessFile randomAccessFile = null; if (!file.exists()) { randomAccessFile = new RandomAccessFile(file, FILE_WRITE_READ_MODIFY); randomAccessFile.setLength(contentLength); randomAccessFile.close(); } } //嗅探下载，判断是否可分片下载 private boolean sniffDownload() throws Exception { Set&lt;Header&gt; set = new HashSet&lt;&gt;(); Header header = new BasicHeader(RANGE_HEAD, &quot;bytes=&quot; + 0 + &quot;-&quot; + SNIFF_BYTES); set.add(header); CloseableHttpResponse response = HttpUtils.doHttpGetResponse(url, set); int code = response.getStatusLine().getStatusCode(); long currentLength = response.getEntity().getContentLength(); response.close(); if (code == HttpStatus.SC_PARTIAL_CONTENT) { String contentRange = getContentRange(response.getAllHeaders()); if (!StringUtils.isEmpty(contentRange)) { this.contentLength = Long.valueOf(contentRange); return true; } return false; } else if (code &gt;= HttpStatus.SC_BAD_REQUEST) { throw new Exception(&quot;request download url failed,statusCode: &quot; + code); } else { this.contentLength = currentLength; return false; } } private String getContentRange(Header[] headers) { if (headers != null &amp;&amp; headers.length &gt; 0) { for (Header header : headers) { if (CONTENT_RANGE.equals(header.getName())) { String value = header.getValue(); return value.substring(value.lastIndexOf(CONTENT_RANGE_DASH) + 1); } } } return null; } private String getFileName(String url) { if (!url.contains(&quot;.&quot;)) { return null; } if (url.contains(&quot;?&quot;)) { return url.substring(url.lastIndexOf(&quot;/&quot;) + 1, url.lastIndexOf(&quot;?&quot;)); } return url.substring(url.lastIndexOf(&quot;/&quot;) + 1); } private String fetchFileName(String url) { return url.substring(url.lastIndexOf(&quot;/&quot;), url.lastIndexOf(&quot;.&quot;)); } private class DownloadHandler implements Callable&lt;Boolean&gt; { private int threadId; private long startIndex; private long endIndex; private File file; public DownloadHandler(int threadId, long startIndex, long endIndex, File file) { this.threadId = threadId; this.startIndex = startIndex; this.endIndex = endIndex; this.file = file; } private void readTemp(File tempFile, int threadId) throws Exception { if (tempFile.exists()) { RandomAccessFile randomAccessFile = new RandomAccessFile(tempFile, &quot;r&quot;); long skip = threadId &lt;&lt; TEMP_FILE_SKIP; randomAccessFile.seek(skip); if (randomAccessFile.length() &lt; skip) return; long l = randomAccessFile.readLong(); this.startIndex = l; randomAccessFile.close(); } } private void writeTemp(File tempFile,int threadId,int downloadTotal) throws Exception { RandomAccessFile temp = new RandomAccessFile(tempFile, FILE_WRITE_READ_MODIFY); temp.seek(threadId &lt;&lt; TEMP_FILE_SKIP); temp.writeLong(this.startIndex + downloadTotal); temp.close(); } private CloseableHttpResponse partialHttpRequest(String url, long startIndex, long endIndex) throws Exception { Set&lt;Header&gt; set = new HashSet&lt;&gt;(); Header header = new BasicHeader(RANGE_HEAD, &quot;bytes=&quot; + startIndex + &quot;-&quot; + endIndex); set.add(header); CloseableHttpResponse response = HttpUtils.doHttpGetResponse(url, set); return response; } //使用callable而不是runnable方便捕获异常 @Override public Boolean call() throws Exception { System.out.println(&quot;threadId:&quot; + threadId + &quot;start download&quot; + System.currentTimeMillis()); CloseableHttpResponse response = null; RandomAccessFile targetFile = null; InputStream content = null; try { File tempFile = new File(targetPath, fetchFileName(url) + SUFFIX_TEMP); readTemp(tempFile, threadId); System.out.println(&quot;threadId:&quot; + threadId + &quot; startIndex:&quot; + startIndex + &quot; endIndex:&quot; + endIndex); response = partialHttpRequest(url, startIndex, endIndex); content = response.getEntity().getContent(); targetFile = new RandomAccessFile(file, FILE_WRITE_READ_MODIFY); targetFile.seek(startIndex); byte[] buffer = new byte[BUFFER]; int len = 0; int total = 0;//记录本次文件下载大小 while ((len = content.read(buffer)) &gt; 0) { total += len; targetFile.write(buffer, 0, len); //记录当前线程下载进度 writeTemp(tempFile,threadId,total); } System.out.println(System.currentTimeMillis() + &quot;threadId:&quot; + threadId + &quot;download finished! this time get total :&quot; + total + &quot; byte data&quot;); } finally { if (content != null) content.close(); if (response != null) response.close(); if (targetFile != null) targetFile.close(); } return true; } } //删除线程产生的临时文件 private synchronized void cleanTemp(File file) { if (file.exists()) { file.delete(); } } }]]></content>
      <tags>
        <tag>多线程,断点续传</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次内存泄漏排查]]></title>
    <url>%2F2018%2F04%2F29%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[引言最近公司一项目写完在进行压测，在压测过程中偶然top了几次，发现项目运行的进程占用的资源RES一直在缓慢增长。于是怀疑是存在内存泄漏。 用通俗的话来讲内存泄漏是由于开发人员没有注意到内存管理，没有有效的进行内存回收导致的一部分内存无法被回收，同时在系统运行过程中会不断有新的相关内存占用，最终导致Out of Memory。这种情况在C++ programmer中是非常头疼的一件事，因为C++把内存管理的权限交给了开发人员，但是对于Java开发人员来说会轻松很多，因为JVM自带GC收集器垃圾内存回收一般不需要开发人员关心。那么有人会问了，既然如此Java程序有可能会出现内存泄漏情况吗？答案是肯定的。那么为什么在有GC收集器的情况下还会有内存泄露呢？这还需要搞清楚JVM的垃圾回收的原理–什么样的对象会被认为是垃圾 垃圾回收算法Java的JVM种类繁多，以Hotspot JVM为例，Hotspot使用的是根搜索算法，根搜索算法基本原理是定义好一个或多个GC Root对象，从这些GC Root对象开始向下遍历该对象的引用对象，遍历走过的路径叫引用链，如果一个对象没有一条引用链可达，那么这个对象和其引用链都会被标记为垃圾，会被GC收集器回收掉。在JAVA语言中，可以作为GC Root的对象有如下几种： 虚拟机栈（栈帧中d额本地变量表）中引用的对象 方法区中静态属性引用的对象 方法区中常量引用的对象 本地方法栈JNI（native方法）的引用对象了解了垃圾回收算法，我们就有理由相信JAVA程序也可能出现内存泄漏的，如果我们开发人员不注意写了一些对象被GC Root对象引用了，并且没有做内存释放操作，比如说一些集合的操作，尤其是类全局变量的集合，一有操作不慎就会造成内存泄漏。 排查过程说了这么多，现在来看看本人经历的一次内存泄露排查过程。背景上面已经介绍了，项目就是一个简单的netty程序。当发现可能有内存泄漏后，做的第一件事就是排查代码，毕竟是自己写的代码，自己最熟悉，在一通排查后并没有发现有明显集合数据添加了没有remove的操作，当时是懵逼的，因为有add就有正常remove，没办法只能祭出杀手锏使用jmap、jstat和三方内存泄漏分析工具–memory analyzer。 首先使用jstat -gcutil pid 6000 命令每6秒查看一次gc情况，观察一段时间后发现，项目运行一天后疯狂进行Full GC，这下可以断定绝对有内存泄露。然后使用jmap -histo:live pid | head -10 命令查看系统运行进程存活对象数量和占用内存前五的对象，如下图： num #instances #bytes class name ---------------------------------------------- 1: 278 16903672 [B 2: 8766 819424 [C 3: 3454 385560 java.lang.Class 4: 2777 305984 [Ljava.lang.Object; 5: 6858 219456 java.util.concurrent.ConcurrentHashMap$Node 6: 8716 209184 java.lang.String 7: 6438 103008 java.lang.Object 发现排名第一多对象数量和占用内存最多的竟然是一个Long对象，这绝对有问题，一般没有内存泄漏的系统jmap出来的前五一般都是byte、char、string这些对象，知道这个Long有问题，本人又去代码中瞧了一眼，用了Long的地方都是正常的，有remove释放操作，为了进一步弄清到底是哪个地方出问题，我祭出了终极大法–Memory Analyzer。使用jmap -dump:format=b,file=文件名 [pid] 命令dump出来内存映像文件，然后扔进Memory Analyzer，进入histoGram，选择Long这个对象，右键选择with income object。可以找到引用链，最终发现是一个别的同事写的私用协议有个全局字段add到队列中但是没有remove，所以导致内存泄漏。 对了，最后说一嘴之前我不是使用top看内存涨了么，其实使用top看是看不出什么的，因为就算没有内存泄漏，特么RES也是会涨的，因为JVM向操作系统要内存了之后，如果当前内存够，JVM是不会立马释放内存的，JVM还会占用这块内存当做缓存，防止数据高峰时又需要向操作系统要内存（因为系统调用是要时间和性能做代价的）。]]></content>
      <tags>
        <tag>JAVA,内存泄漏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java基础之synchronized关键字]]></title>
    <url>%2F2018%2F04%2F29%2Fjava%E5%9F%BA%E7%A1%80%E4%B9%8Bsynchronized%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[引言在java中有两种加锁方式，一种使用同步关键字synchronized，另一种使用concurrent包下的Lock（比如我们所熟知的ReentrantLock）在我刚刚工作的时候很多前辈或者文章都说慎用同步关键字，太重了，很耗性能，与ReentrantLock相比性能没它好。但是好像是在jdk1.6之后（未验证过）特定对同步关键字的实现进行过优化，这两种锁性能已经不相上下了，甚至在某些情况下同步关键字反而更胜一筹。今天我们就窥探下同步关键字的原理。（提示：看这篇文章前需要对JVM有一定理解，需要了解栈帧、CAS等概念，且本文是针对hotSpot虚拟机的） 用法synchronized的关键字可以作用在方法上也可以作用在部分代码上组成同步代码块。如果同步关键字作用在方法上则获取的对象锁为当前类对象，如果是同步代码块，则获取的锁对象为同步代码块括号中的对象。建议优先使用同步代码块，只有线程运行到同步代码块后线程才会阻塞，除非你确定整个方法都需要同步，否则应该尽量减小同步的粒度。伪代码如下：12345678910public synchronized void test()&#123; &#125;public void test ()&#123; synchronized (object) &#123; &#125;&#125; 基本原理synchronized经过编译后在关键字前后会多出monitorenter和monitorexit字节码指令，所以也有人说同步关键字在jvm层面叫做监视器锁。当一个线程获取锁执行时，jvm为当前线程维护一个计数器，线程进入就加1，退出执行monitorexit时就减1，所以当一个线程获取了锁要执行多个同步方法是可以的，这叫可重入性。当该计数器为零时就说明线程执行代码完成锁被释放，其他阻塞的线程被唤醒。当然，jdk1.6之前同步关键字未被优化前是这么干的，在后面的版本中jdk团队进行了一系列化的优化，提出了偏向锁、轻量级锁、自旋锁、和重量级锁。 Java对象头锁信息存在java的对象头中，如果java对象是非数组则大小为2个字宽，在32位虚拟机中一个字宽=4bytes，如果是数组则为3个字宽。以32bit虚拟机为例： 长度 内容 说明 32bit Mark Word 存储对象的hashcode或者锁信息 32bit Class Metadata Address 存储到对象类型数据的指针 32bit 数组长度 如果对象为数组的话为数组长度，若不是则不存在这一列 锁信息是存放在对象头里的Mark Word中的，Mark Word结构如下： 锁状态 25bit 4bit 1bit 2bit 23bit 2bit 是否允许偏向锁 锁标志位 轻量级锁 指向栈中锁记录的指针 00 重量级锁 指向互斥量的指针 10 GC标记 空 11 偏向锁 线程ID Epoch 对象分代年龄 1 01 偏向锁在乐观情况下，锁不仅不会竞争而且经常是同一个线程多次获得锁，所以hotSpot虚拟机开发人员为这种情况进行优化，提出了偏向锁的概念，当在没有竞争的情况下，线程申请获取锁只需要通过CAS将线程ID设置进锁对象中，以后该线程申请获取锁只需要对比一下锁对象中的线程ID是否一致并且epoch和锁记录中的Klass的mark_prototype中的epoch是否一致。如果都一致就直接获取锁。也就是说偏向锁的开销只有一次CAS操作。 当线程申请获取锁时，当前线程会查询锁对象的锁标志位，看当前是偏向锁还是轻量级锁还是其他。如果判断是标志位为01，则当前处于偏向锁状态，然后接着会判断是否允许偏向锁也就是判断上图的的是否允许偏向锁状态位，JDK1.6以后默认是允许偏向锁的。 偏向锁存在以下三种状态： 匿名偏向（Anonymously biased）在此状态下是偏向锁最初始的情况，此时线程ID还是null，还没有偏向任何线程。只要有线程申请锁理论上是可以申请成功的。 可重偏向（Rebiasable）可重偏向状态是在偏向锁撤销时发生，锁撤销下面会详细讲。如果偏向锁处于可重偏向状态则说明之前偏向的线程获取的锁已经失效，锁记录中的Epoch字段与锁对象的klass的mark_prototype的epoch字段不一致。以后其他线程想获取锁，通过CAS操作替换线程ID成功就行。 已偏向（Biased）在这种情况下，锁对象存在线程ID（thread_ptr字段不为空），并且epoch值是有效的，总之就说明锁已经偏向锁对象中的线程ID的线程。 锁撤销必须拿出来讲一讲，锁撤销存在两种情况，一种是当前锁处于已偏向状态，并且偏向的线程正在执行同步方法，此时其他线程也申请锁，换句话说就是存在竞争了，此时会触发锁撤销，锁撤销完成后如果当前偏向线程还没退出同步代码块，那么就升级成轻量级锁。而另一种是其他线程申请锁，也就是通过CAS操作尝试把自己的线程ID设置到锁对象中，如果成功（要成功只能是原偏向的线程没有进入同步代码块）那么锁就重新偏向新的线程。如果CAS操作失败则启动偏向锁撤销操作，原持有偏向锁的线程到达全局安全点后JVM会检查当前线程状态，如果当前偏向线程已退出同步代码块，那么偏向锁撤销成功。如果撤销总数超过一个阈值（对应 Java 虚拟机参数 -XX:BiasedLockingBulkRevokeThreshold，默认值为 40）该参数超过阈值JVM会认为该线程不适合偏向，不适合偏向JVM会将锁升级成轻量级锁。 如上所述并不是所有场景都适合偏向锁，比如基于生产者消费者模型的场景等竞争激烈的情况下，最好将偏向锁禁掉，JVM默认是启用的，通过使用以下命令禁止：1-XX:-UseBiasedLocking=false 轻量级锁当真正出现竞争时，偏向锁会升级成轻量级锁。当线程申请轻量级锁时当前线程在自身栈帧中创建一片用于存放锁记录的空间，然后把锁对象头中的Mark Word内容复制到锁记录中（Displace Mark Word），同时通过CAS操作把锁对象头的Mark Word内容修改为指向当前线程栈帧的指针。如果修改成功那么当前线程获取到锁并开始执行同步代码块。如果获取锁失败那么当前线程先自旋一定次数，自旋的想法是JVM开发团队认为一有竞争就上mutex还是太浪费了，让这些获取锁失败的线程先等一段时间吧，而不是立马阻塞，毕竟开销太大，线程切换都是小的，还有用户态和内核态切换+系统调用这个大头呢。说不定当前运行的同步代码块粒度很小，锁立马释放了。这里自旋的次数只有初次自旋是用默认的自旋参数，之后将会通过自适应的方式来调整自旋次数，比如当前线程自旋时成功拿到了锁，下次自旋可能会多自旋几次。 轻量级锁通过自旋的方式尽可能避开使用重量级锁，但是这样也因为多个线程空转浪费了cpu资源，如果当前场景是计算密集型的任务，cpu就没有很好的利用好。 重量级锁如果轻量级锁被其他线程拿到了，当前线程又自旋了规定次数，锁还没有被释放，此时就锁将膨胀成重量级锁，重量级锁是我们的老朋友了，在同步关键字没有优化前一直就是这个家伙。当锁膨胀成重量级锁，未获取锁的（那些自旋的线程）线程被挂起，直到当前线程释放锁。]]></content>
      <tags>
        <tag>JAVA,锁,多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解dubbo之服务引用源码分析]]></title>
    <url>%2F2018%2F01%2F14%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3dubbo%E4%B9%8B%E6%9C%8D%E5%8A%A1%E5%BC%95%E7%94%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[在之前说了一下dubbo的服务发布过程，其实严格意义上只说了一半吧，只把dubbo如何经过ProxyFactory的代理成一个Invoker，等待客户端调用的过程讲了一遍，而重要的Protocol.export方法略过去了，今天我将连带dubbo的comsumer客户端服务引用和Protocol机制来讲一讲。 dubbo服务引用和上一篇文章一样，先来个demo 123456789101112131415&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;dubbo:application name=&quot;ifenqu-web&quot; /&gt; &lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;$&#123;dubbo.address&#125;&quot; /&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;$&#123;dubbo.port&#125;&quot;/&gt; &lt;dubbo:consumer timeout=&quot;60000&quot; check=&quot;false&quot;/&gt; &lt;dubbo:service interface=&quot;com.xxx.xxx.xxxService&quot; ref=&quot;xxxService&quot; timeout=&quot;5000&quot;/&gt;&lt;/beans&gt; 在上篇文章我们已经说了，对于service暴露方也就是provider方有对应的ServiceConfig，相应的Reference引用方也就是Consumer有对应的ReferenceConfig。ReferenceConfig中定义了每一个接口参数定义，这只是部分，还有一大堆参数在父类里就不列出来了。 123456789101112131415161718// 接口类型private String interfaceName;private Class&lt;?&gt; interfaceClass;// 客户端类型private String client;// 点对点直连服务提供地址private String url;// 方法配置private List&lt;MethodConfig&gt; methods;//接口所有的方法配置// 缺省配置private ConsumerConfig consumer;//该参数对应的就是&lt;dubbo:consumer timeout=&quot;60000&quot; check=&quot;false&quot;/&gt;private String protocol;//如果为空默认dubbo 参数设值分两步，第一步是对象创建的时候，第二步是调用了get方法后执行init()方法。这个get方法就是服务引用的入口： 12345678910public synchronized T get() &#123; if (destroyed)&#123; throw new IllegalStateException(&quot;Already destroyed!&quot;); &#125; //服务实例已经存在就直接返回，没有就进行初始化 if (ref == null) &#123; init(); &#125; return ref; &#125; init()方法主要分为两个步骤，第一步：收集上下文，第二步：根据上下文创建服务实例 ref = createProxy(map);进入createProxy方法中去看看 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879private T createProxy(Map&lt;String, String&gt; map) &#123; URL tmpUrl = new URL(&quot;temp&quot;, &quot;localhost&quot;, 0, map); final boolean isJvmRefer; if (isInjvm() == null) &#123; if (url != null &amp;&amp; url.length() &gt; 0) &#123; //指定URL的情况下，不做本地引用 isJvmRefer = false; &#125; else if (InjvmProtocol.getInjvmProtocol().isInjvmRefer(tmpUrl)) &#123; //默认情况下如果本地有服务暴露，则引用本地服务. isJvmRefer = true; &#125; else &#123; isJvmRefer = false; &#125; &#125; else &#123; isJvmRefer = isInjvm().booleanValue(); &#125; if (isJvmRefer) &#123; URL url = new URL(Constants.LOCAL_PROTOCOL, NetUtils.LOCALHOST, 0, interfaceClass.getName()).addParameters(map); invoker = refprotocol.refer(interfaceClass, url); if (logger.isInfoEnabled()) &#123; logger.info(&quot;Using injvm service &quot; + interfaceClass.getName()); &#125; &#125; else &#123; if (url != null &amp;&amp; url.length() &gt; 0) &#123; // 用户指定URL，指定的URL可能是对点对直连地址，也可能是注册中心URL String[] us = Constants.SEMICOLON_SPLIT_PATTERN.split(url); if (us != null &amp;&amp; us.length &gt; 0) &#123; for (String u : us) &#123; URL url = URL.valueOf(u); if (url.getPath() == null || url.getPath().length() == 0) &#123; url = url.setPath(interfaceName); &#125; if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; urls.add(url.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map))); &#125; else &#123; urls.add(ClusterUtils.mergeUrl(url, map)); &#125; &#125; &#125; &#125; else &#123; // 通过注册中心配置拼装URL List&lt;URL&gt; us = loadRegistries(false); if (us != null &amp;&amp; us.size() &gt; 0) &#123; for (URL u : us) &#123; URL monitorUrl = loadMonitor(u); if (monitorUrl != null) &#123; map.put(Constants.MONITOR_KEY, URL.encode(monitorUrl.toFullString())); &#125; urls.add(u.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map))); &#125; &#125; if (urls == null || urls.size() == 0) &#123; throw new IllegalStateException(&quot;No such any registry to reference &quot; + interfaceName + &quot; on the consumer &quot; + NetUtils.getLocalHost() + &quot; use dubbo version &quot; + Version.getVersion() + &quot;, please config &lt;dubbo:registry address=\&quot;...\&quot; /&gt; to your spring config.&quot;); &#125; &#125; if (urls.size() == 1) &#123; invoker = refprotocol.refer(interfaceClass, urls.get(0)); &#125; else &#123; List&lt;Invoker&lt;?&gt;&gt; invokers = new ArrayList&lt;Invoker&lt;?&gt;&gt;(); URL registryURL = null; for (URL url : urls) &#123; invokers.add(refprotocol.refer(interfaceClass, url)); if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; registryURL = url; // 用了最后一个registry url &#125; &#125; if (registryURL != null) &#123; // 有 注册中心协议的URL // 对有注册中心的Cluster 只用 AvailableCluster URL u = registryURL.addParameter(Constants.CLUSTER_KEY, AvailableCluster.NAME); invoker = cluster.join(new StaticDirectory(u, invokers)); &#125; else &#123; // 不是 注册中心的URL invoker = cluster.join(new StaticDirectory(invokers)); &#125; &#125; &#125; //忽略非核心代码 // 创建服务代理 return (T) proxyFactory.getProxy(invoker); &#125; 该方法中主要逻辑就是先判断需要引用的类型，是本地服务暴露还是直连远程服务还是集群远程服务。如果暴露的服务本地就有直接url就是localhost，而对于集群还涉及到了loadbanlance。无论是什么类型的服务核心都是refprotocol.refer(interfaceClass, urls.get(0))，这个方法的返回值就是上篇说的Invoker对象，回忆一下，Invoker对象中封装了接口信息和invoke方法，只要客户端拿到了这个Invoker就可以执行invoke进而通过远程通信触发服务端的service返回执行结果。让我们的视线再回到refprotocol上： 123456789101112@SPI(&quot;dubbo&quot;)public interface Protocol &#123; int getDefaultPort(); @Adaptive &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; var1) throws RpcException; @Adaptive &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; var1, URL var2) throws RpcException; void destroy();&#125; 这个Protocol接口定义了三个方法，export、refer、destory。分别是服务暴露和服务引用和销毁方法。经过上一篇的讲述，我们已经知道了dubbo支持dubbo、http、thrift等多种协议。那么dubbo是如何做到多个版本协议可以切换自如呢？方法就在SPI上。 SPISPI（Service Provider Interface）本来是针对不同厂商或插件的一个规范，提供扩展的时候可以对同一个功能用不同的实现。Java SPI的基本思想可以用设计模式六大原则之开闭原则解释，也就是说要对接口开放，对修改关闭。基于这个原则我们就可以对不同的实现完成可拔插的效果。多种不用实现想用哪种用哪种，只要简单修改配置。 Java SPI的具体约定为:当服务的提供者，提供了服务接口的一种实现之后，在jar包的META-INF/services/目录里同时创建一个以服务接口命名的文件。该文件里就是实现该服务接口的具体实现类。而当外部程序装配这个模块的时候，就能通过该jar包META-INF/services/里的配置文件找到具体的实现类名，并装载实例化，完成模块的注入。 基于这样一个约定就能很好的找到服务接口的实现类，而不需要再代码里制定。jdk提供服务实现查找的一个工具类：java.util.ServiceLoader 知道了SPI的定义现在就更好了解Protocol的实现原理了，在ReferenceConfig中获取具体的Protocol是这一行代码private static final Protocol refprotocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();我们可以根据SPI的定义来看看它的实现过程。进入ExtensionLoader类，在这个类中我们可以看到以下几个熟悉的全局常量 1234private static final String SERVICES_DIRECTORY = &quot;META-INF/services/&quot;; private static final String DUBBO_DIRECTORY = &quot;META-INF/dubbo/&quot;; private static final String DUBBO_INTERNAL_DIRECTORY = &quot;META-INF/dubbo/internal/&quot;; private static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap(); debug断点跟进去就会看到这个EXTENSION_LOADERS里面已经装满了多个ExtensionLoaders，尽到dubbo的jar包的META-INF/dubbo/internal/路径时就全明白了，这里面就是这些ExtensionLoaders。就拿我们要说的Protocol来说，ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension()这行代码说的就是传入Protocol.class类型，就能在EXTENSION_LOADERS中找到com.alibaba.dubbo.rpc.Protocol这个类，也就是META-INF/dubbo/internal/路径下的定义的文件com.alibaba.dubbo.rpc.Protocol。进入这个文件我们能看到所有Protocol实现类定义: 1234567891011121314registry=com.alibaba.dubbo.registry.integration.RegistryProtocoldubbo=com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocolfilter=com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapperlistener=com.alibaba.dubbo.rpc.protocol.ProtocolListenerWrappermock=com.alibaba.dubbo.rpc.support.MockProtocolinjvm=com.alibaba.dubbo.rpc.protocol.injvm.InjvmProtocolrmi=com.alibaba.dubbo.rpc.protocol.rmi.RmiProtocolhessian=com.alibaba.dubbo.rpc.protocol.hessian.HessianProtocolcom.alibaba.dubbo.rpc.protocol.http.HttpProtocolcom.alibaba.dubbo.rpc.protocol.webservice.WebServiceProtocolthrift=com.alibaba.dubbo.rpc.protocol.thrift.ThriftProtocolmemcached=com.alibaba.dubbo.rpc.protocol.memcached.MemcachedProtocolredis=com.alibaba.dubbo.rpc.protocol.redis.RedisProtocol 如果你选择dubbo协议，Protocol的接口实现类就会使用com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol我这里使用的是系统默认的dubbo协议，所以我们上面ReferenceConfig方法里面调用的invoker = refprotocol.refer(interfaceClass, urls.get(0));就是DubboProtocol的Refer方法： 12345public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; serviceType, URL url) throws RpcException &#123; DubboInvoker&lt;T&gt; invoker = new DubboInvoker(serviceType, url, this.getClients(url), this.invokers); this.invokers.add(invoker); return invoker; &#125; 这个方法没什么好说的，就是Invoker的实例化而已，不过这个invoker已经有所有调用服务端的服务的必要参数。只需要通过invoker作为参数用ProxyFactory进行动态代理来拿到代理类就行了。 远程调用真正在方法调用时才会触发invoker的doInvoke方法，让我们看看这个doInvoke方法： 123456789101112131415161718192021222324252627282930313233343536protected Result doInvoke(Invocation invocation) throws Throwable &#123; RpcInvocation inv = (RpcInvocation)invocation; String methodName = RpcUtils.getMethodName(invocation); inv.setAttachment(&quot;path&quot;, this.getUrl().getPath()); inv.setAttachment(&quot;version&quot;, this.version); //通信客户端，可以与socket的客户端类比 ExchangeClient currentClient; if(this.clients.length == 1) &#123; currentClient = this.clients[0]; &#125; else &#123; currentClient = this.clients[this.index.getAndIncrement() % this.clients.length]; &#125; try &#123; boolean isAsync = RpcUtils.isAsync(this.getUrl(), invocation); boolean isOneway = RpcUtils.isOneway(this.getUrl(), invocation); int timeout = this.getUrl().getMethodParameter(methodName, &quot;timeout&quot;, 1000); if(isOneway) &#123; boolean isSent = this.getUrl().getMethodParameter(methodName, &quot;sent&quot;, false); currentClient.send(inv, isSent); RpcContext.getContext().setFuture((Future)null); return new RpcResult(); &#125; else if(isAsync) &#123; ResponseFuture future = currentClient.request(inv, timeout); RpcContext.getContext().setFuture(new FutureAdapter(future)); return new RpcResult(); &#125; else &#123; RpcContext.getContext().setFuture((Future)null); return (Result)currentClient.request(inv, timeout).get(); &#125; &#125; catch (TimeoutException var9) &#123; throw new RpcException(2, &quot;Invoke remote method timeout. method: &quot; + invocation.getMethodName() + &quot;, provider: &quot; + this.getUrl() + &quot;, cause: &quot; + var9.getMessage(), var9); &#125; catch (RemotingException var10) &#123; throw new RpcException(1, &quot;Failed to invoke remote method: &quot; + invocation.getMethodName() + &quot;, provider: &quot; + this.getUrl() + &quot;, cause: &quot; + var10.getMessage(), var10); &#125; &#125; 这个方法也很简单，首先拿到远程调用的参数，比如方法名，调用路径，暴露服务的版本号（版本号不同无法调通），拿到了ExchangeClient后就开始了请求，这个请求分同步和异步，都是看你配置来的，如果是同步的就一直阻塞直到timeout或者结果返回，如果是异步那么直接返回一个ResponseFuture，等执行成功后提供回调。到这，从consumer的方法引用到方法执行都说完了。讲得比较精炼，把很多东西都给省略了，其实dubbo真的特别复杂，但是对于我个人来说只要了解原理就已经达到我的目的了，所以到这就可以了。其实还有一部分比较重要，那就是网络通信部分，dubbo用的是netty。等有空了可以去膜拜膜拜。]]></content>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解dubbo之服务发布源码分析]]></title>
    <url>%2F2018%2F01%2F14%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3dubbo%E4%B9%8B%E6%9C%8D%E5%8A%A1%E5%8F%91%E5%B8%83%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[dubbo 是阿里开源的一个分布式服务框架，它的最大特点是按照分层的方式来架构，使各层之间充分解耦，并且它是无侵入性的，dubbo可以无缝与spring整合，更重要的是dubbo还提供了强大的容错和监控功能。 对于业务方来说，dubbo使用上手足够简单，调用过程对业务方透明，对开发人员友好。 Demo在spring项目中添加如下pom包：123456789101112&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;/dependency&gt; 如果你的是springboot项目也可以用springboot的starter包12345&lt;dependency&gt; &lt;groupId&gt;io.dubbo.springboot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-dubbo&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; 添加配置文件:spring-dubbo.xml123456789101112131415&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;dubbo:application name=&quot;ifenqu-web&quot; /&gt; &lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;$&#123;dubbo.address&#125;&quot; /&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;$&#123;dubbo.port&#125;&quot;/&gt; &lt;dubbo:consumer timeout=&quot;60000&quot; check=&quot;false&quot;/&gt; &lt;dubbo:service interface=&quot;com.xxx.xxx.xxxService&quot; ref=&quot;xxxService&quot; timeout=&quot;5000&quot;/&gt;&lt;/beans&gt; 调用的时候也很简单 12 @Autowiredprivate xxxService xxxService; demo 接介绍到这，今天的重点不是讲如何使用dubbo，今天的重点是说一说dubbo的架构设计。 源码分析dubbo框架设计总共分了10层： 服务接口层（Service）：该层是与实际业务逻辑相关，就如上面demo配置的&lt;dubbo:service interface=&quot;com.xxx.xxx.xxxService&quot; ref=&quot;xxxService&quot; timeout=&quot;5000&quot;/&gt;,这个service就是业务方自己定义的接口与其实现。 配置层（Config）：该层是将业务方的service信息，配置文件的信息收集起来，主要是以ServiceConfig和ReferenceConfig为中心，ServiceConfig是服务提供方的配置，当Spring启动的时候会相应的启动provider服务发布和注册的过程，主要是加入一个ServiceBean继承ServiceConfig在Spring注册。同理ReferenceConfig是consumer方的配置，当消费方启动时，会启动consumer的发现服务订阅服务的过程，当然也是使用一个ReferenceBean继承ReferenceConfig注册在spring上。 服务代理层（Proxy）：对服务接口进行透明代理，生成服务的客户端和服务器端，使服务的远程调用就像在本地调用一样。默认使用JavassistProxyFactory，返回一个Invoker，Invoker则是个可执行核心实体，Invoker的invoke方法通过反射执行service方法。 服务注册层（Registry）：封装服务地址的注册和发现，以服务URL为中心，基于zk。 集群层（Cluster）:提供多个节点并桥接注册中心，主要负责loadBanlance、容错。 监控层（Monitor）：RPC调用次数和调用时间监控，以Statistics为中心，扩展接口为MonitorFactory、Monitor和MonitorService。 远程调用层（Protocol）：封装RPC调用，provider通过export方法进行暴露服务/consumer通过refer方法调用服务。而Protocol依赖的是Invoker。通过上面说的Proxy获得的Invoker，包装成Exporter。 信息交换层（Exchange）：该层封装了请求响应模型，将同步转为异步，信息交换层依赖Exporter，最终将通过网络传输层接收调用请求RequestFuture和ResponseFuture。 网络传输层（Transport）：抽象mina和netty为统一接口，以Message为中心，扩展接口为Channel、Transporter、Client、Server和Codec。 数据序列化层：该层无需多言，将数据序列化反序列化。服务发布过程通过上面的框架了解我们大致知道了dubbo是怎么工作的，接下来我们来通过代码来具体看看dubbo的服务发布过程，进一步理解dubbo的工作原理。先看到demo中的spring-dubbo配置文件。这些配置文件全都会被装配成RegistryConfig，其属性如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class RegistryConfig extends AbstractConfig &#123; private static final long serialVersionUID = 5508512956753757169L; public static final String NO_AVAILABLE = &quot;N/A&quot;; // 注册中心地址 private String address; // 注册中心登录用户名 private String username; // 注册中心登录密码 private String password; // 注册中心缺省端口 private Integer port; // 注册中心协议 private String protocol; // 客户端实现 private String transporter; private String server; private String client; private String cluster; private String group; private String version; // 注册中心请求超时时间(毫秒) private Integer timeout; // 注册中心会话超时时间(毫秒) private Integer session; // 动态注册中心列表存储文件 private String file; // 停止时等候完成通知时间 private Integer wait; // 启动时检查注册中心是否存在 private Boolean check; // 在该注册中心上注册是动态的还是静态的服务 private Boolean dynamic; // 在该注册中心上服务是否暴露 private Boolean register; // 在该注册中心上服务是否引用 private Boolean subscribe; // 自定义参数 private Map&lt;String, String&gt; parameters; // 是否为缺省 private Boolean isDefault; 这些配置文件根据注册中心的个数会被装配拼接成Dubbo的URL（该url是dubbo中自定义的），该URL长这个样子：registry://sit-zk.host:2181/com.alibaba.dubbo.registry.RegistryService?application=ifenqu-web&amp;dubbo=2.5.3&amp;pid=13168&amp;registry=zookeeper&amp;timestamp=1510828420296看完配置信息，接下来让我们看下Service发布的核心方法：ServiceConfig类中的doExportUrls12345678private void doExportUrls() &#123; //该方法根据配置文件装配成一个URL的list List&lt;URL&gt; registryURLs = loadRegistries(true); //根据每一个协议配置来分别暴露服务 for (ProtocolConfig protocolConfig : protocols) &#123; doExportUrlsFor1Protocol(protocolConfig, registryURLs); &#125; &#125; 这个protocols长这个样子&lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20888&quot; id=&quot;dubbo&quot; /&gt; protocols也是根据配置装配出来的。接下来让我们进入doExportUrlsFor1Protocol方法看看dubbo具体是怎么样将服务暴露出去的。这个方法特别大，有将近300多行代码，但是其中大部分都是获取类似protocols的name、port、host和一些必要的上下文，代码太长就不全都贴出来了，只贴关键部分。1234567891011121314private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL&gt; registryURLs) &#123; //........省略获取上下文代码//通过interfaceClass获取要暴露服务的所有要暴露的方法String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames();//.......省略非核心代码//根据上下文创建URL对象 URL url = new URL(name, host, port, (contextPath == null || contextPath.length() == 0 ? &quot;&quot; : contextPath + &quot;/&quot;) + path, map);//通过proxyFactory来获取Invoker对象 Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString()));//将invoker对象在protocol中封装成Exporter方便提供给信息交换层进行网络传输 Exporter&lt;?&gt; exporter = protocol.export(invoker); //将exporter添加到list中 exporters.add(exporter); 看到这里就比较明白dubbo的工作原理了doExportUrlsFor1Protocol方法，先创建URL，URL创建出来长这样dubbo://192.168.xx.63:20888/com.xxx.xxx.VehicleInfoService?anyhost=true&amp;application=test-web&amp;default.retries=0&amp;dubbo=2.5.3&amp;interface=com.xxx.xxx.VehicleInfoService&amp;methods=get,save,update,del,list&amp;pid=13168&amp;revision=1.2.38&amp;side=provider&amp;timeout=5000&amp;timestamp=1510829644847，是不是觉得这个URL很眼熟，没错在注册中心看到的services的providers信息就是这个，再传入url通过proxyFactory获取Invoker，再将Invoker封装成Exporter的数组，只需要将这个list提供给网络传输层组件，然后consumer执行Invoker的invoke方法就行了。让我们再看看这个proxyFactory的getInvoker方法。proxyFactory下有JDKProxyFactory和JavassistProxyFactory。官方推荐也是默认使用的是JavassistProxyFactory。因为javassist动态代理性能比JDK的高。123456789101112131415161718192021public class JavassistProxyFactory extends AbstractProxyFactory &#123; @SuppressWarnings(&quot;unchecked&quot;) public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] interfaces) &#123; return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker)); &#125; public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; // TODO Wrapper类不能正确处理带$的类名 final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf(&apos;$&apos;) &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;; &#125;&#125; 可以看到使用了动态代理的方式调用了要暴露的service的方法。并且返回了Invoker对象。在dubbo的服务发布中我们可以看到，这个Invoker贯穿始终，都可以看成是一个context的作用了，让我们进Invoker里面去看看这个Invoker到底是何方神圣。1234567891011121314151617public interface Invoker&lt;T&gt; extends Node &#123; /** * get service interface. * * @return service interface. */ Class&lt;T&gt; getInterface(); /** * invoke. * * @param invocation * @return result * @throws RpcException */ Result invoke(Invocation invocation) throws RpcException; 这个Invoker就两个方法，一个getInterface，也就是要暴露的服务接口，一个就是invoke方法，这个invoke方法在AbstractProxyInvoker中是这样的：12345678910public Result invoke(Invocation invocation) throws RpcException &#123; try &#123; //调用doInvoke方法，返回一个Result return new RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments())); &#125; catch (InvocationTargetException e) &#123; return new RpcResult(e.getTargetException()); &#125; catch (Throwable e) &#123; throw new RpcException(&quot;Failed to invoke remote proxy method &quot; + invocation.getMethodName() + &quot; to &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); &#125;&#125; 其实看到JavassistProxyFactory大家就应该大概明白了这个Invoker的作用，同时这个类的名字就叫Invoker也可以猜个大概，Invoker就是调用service的方法的实体类。其中doInvoke方法已经在JavassistProxyFactory中定义了，通过反射调用要暴露的service的方法。 服务发布总结看完源码，我们已经知道了dubbo的主要发布过程，现在我们回过头来结合dubbo的总体架构和源码的分析，总结一下dubbo服务发布。服务发布过程总共五个步骤： 业务方将服务接口和实现编写定义好，添加dubbo相关配置文件。 Config层加载配置文件形成上下文，Config层包括：ServiceConfig、ProviderConfig、RegistryConfig等。 ServiceConfig根据Protocol类型，根据ProtocolConfig、ProviderConfig加载registry，根据加载的registry创建dubbo的URL。 准备工作做完后ProxyFactory上场，dubbo中有两种代理方式，JDK代理和Javassist代理，默认使用Javassist代理，Proxy代理类根据dubbo配置信息获取到接口信息、通过动态代理方式将接口的所有方法交给Proxy代理类进行代理，并封装进Invoker里面。 将所有需要暴露的service封装的Invoker组成一个list传给信息交换层提供给消费方进行调用。]]></content>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch5.3.0 索引创建及查询]]></title>
    <url>%2F2018%2F01%2F14%2Felasticsearch5-3-0-%E7%B4%A2%E5%BC%95%E5%88%9B%E5%BB%BA%E5%8F%8A%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[引言上篇文章介绍了elasticsearch5.3.0服务器搭建，接下来说说elasticsearch的java客户端对数据的索引创建和对数据的查询。虽说现在es的api使用文档不少，但是5.3.0版本的太新了，许多都不兼容老版本，所以有了这篇博文。elasticsearch允许HTTP Restful的方式进行数据访问和操作，也同样允许通过JAVA API来访问服务器，HTTP Restful方式官方网站有很详细的说明在这就不罗嗦了，先看如何使用JAVA API来访问服务器。 准备本人使用springboot建的项目，本文重点是如何使用es的java api，其他有的没的就先略去。首先引入elasticsearch客户端maven包,因为是5.3.0的版本，所以客户端包也保持一致。12345678910&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;transport&lt;/artifactId&gt; &lt;version&gt;5.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;5.3.0&lt;/version&gt; &lt;/dependency&gt; 索引创建及查询Client1234567891011@Beanpublic Client esClient()throws UnknownHostException &#123; Settings settings=Settings.builder() .put(&quot;cluster.name&quot;,clusterName)//集群名称 .put(&quot;client.transport.sniff&quot;,true)//是否开启嗅探功能 .build(); InetAddress inetAddress=InetAddress.getByName(ip); TransportAddress transportAddress =new InetSocketTransportAddress(inetAddress,port); return new PreBuiltTransportClient(settings) .addTransportAddress(transportAddress);&#125; 创建索引对于es的文档而言，一个文档会包括一个或者多个字段，任何字段都要有自己的数据类型，比如string、date等。es中是通过映射来进行字段和数据类型对应的，在默认的情况下es会自动识别字段的数据类型，但是最好还是提供一个mappings参数类显式的进行映射。 接下来我们先给要索引的数据创建一个mapping 1234567891011121314151617181920212223242526272829303132public boolean getMapping(String index, String type) &#123; try &#123; CreateIndexRequest createIndexRequest = new CreateIndexRequest(index); CreateIndexResponse createIndexResponse = esClient.admin().indices().create(createIndexRequest).get(); logger.info(&quot;Index:&#123;&#125; created,response:&#123;&#125;&quot;, index, JSON.toJSON(createIndexResponse)); XContentBuilder builder = XContentFactory.jsonBuilder(); builder.startObject() .startObject(type) .startObject(&quot;properties&quot;) .startObject(&quot;firstName&quot;).field(&quot;type&quot;, &quot;string&quot;) .endObject() .startObject(&quot;lastName&quot;).field(&quot;type&quot;, &quot;string&quot;) .endObject() .startObject(&quot;about&quot;).field(&quot;type&quot;, &quot;string&quot;) .endObject() .startObject(&quot;interests&quot;).field(&quot;type&quot;, &quot;string&quot;) .endObject() .endObject() .endObject(); PutMappingRequest putMappingRequest = new PutMappingRequest(index); putMappingRequest.type(type); putMappingRequest.source(builder); PutMappingResponse putMappingResponse = esClient.admin().indices().putMapping(putMappingRequest).get(); logger.info(&quot;Mapping for `&#123;&#125;.&#123;&#125;` putted, response:&#123;&#125;&quot;, index, type, JSON.toJSON(putMappingResponse)); return true; &#125; catch (Exception e) &#123; logger.error(&quot;doCreateIndex&quot;, e); return false; &#125;&#125; 测试数据是官网上的一个例子，就是一个公司部门中员工的信息，而mapping的作用就是在es中被索引的数据规定每一个field数据类型。 接下来添加索引数据：12345678910111213141516public boolean createIndex(String json) &#123; try &#123; if(!esIndexTypes.get(index)) &#123; if(getMapping(index, indexType)) esIndexTypes.put(index,true); &#125; IndexRequestBuilder requestBuilder = esClient.prepareIndex(index, indexType); IndexResponse indexResponse = requestBuilder.setSource(json).execute().actionGet(); logger.info(&quot;Index:&#123;&#125; created,response:&#123;&#125;&quot;, index, JSON.toJSON(indexResponse)); return true; &#125; catch (Exception e) &#123; logger.error(&quot;createIndex failed,exception:&#123;&#125;&quot;, e.getMessage()); return false; &#125;&#125; 组合查询并高亮显示123456789101112131415161718192021222324252627282930313233343536373839public List&lt;String&gt; search(String... queryStr) &#123; BoolQueryBuilder queryBuilder = QueryBuilders.boolQuery(); for (String s : queryStr) &#123;//使用queryStringQuery无法使用高亮 queryBuilder.should(QueryBuilders.matchQuery(&quot;about&quot;, s)); &#125; HighlightBuilder highlightBuilder = new HighlightBuilder(); highlightBuilder.preTags(&quot;&lt;span style=\&quot;color:red\&quot;&gt;&quot;); highlightBuilder.postTags(&quot;&lt;/span&gt;&quot;); highlightBuilder.field(&quot;about&quot;).field(&quot;interests&quot;).forceSource(true); SearchResponse searchResponse = esClient.prepareSearch(index) .setTypes(indexType) .setQuery(queryBuilder) .highlighter(highlightBuilder) .execute() .actionGet(); SearchHits hits = searchResponse.getHits(); List&lt;String&gt; list = new ArrayList&lt;String&gt;(); if (hits != null &amp;&amp; hits.getHits().length &gt; 0) &#123; for (SearchHit hit : hits) &#123; JSONObject data = new JSONObject(); for(Map.Entry&lt;String, Object&gt; entry : hit.getSource().entrySet()) &#123; data.put(entry.getKey(), entry.getValue()); &#125; hit.getHighlightFields().forEach((title, frag) -&gt; &#123; String str = &quot;&quot;; for (Text text : frag.getFragments()) &#123; str = str + text.string(); &#125; data.put(title, str); &#125;); list.add(JSON.toJSONString(data)); &#125; &#125; return list; &#125; 测试1234567@org.junit.Test public void testquery()&#123; List&lt;String&gt; haha = esProxy.search(&quot;认真&quot;,&quot;眼泪&quot;,&quot;杀猪&quot;); System.out.println(haha.toString()); &#125; //结果 [&#123;&quot;firstName&quot;:&quot;王麻子&quot;,&quot;lastName&quot;:&quot;君君&quot;,&quot;about&quot;:&quot;爱的那么&lt;span style=\&quot;color:red\&quot;&gt;认&lt;/span&gt;&lt;span style=\&quot;color:red\&quot;&gt;真&lt;/span&gt;，不让我的&lt;span style=\&quot;color:red\&quot;&gt;眼&lt;/span&gt;&lt;span style=\&quot;color:red\&quot;&gt;泪&lt;/span&gt;陪我过夜&quot;,&quot;interests&quot;:[&quot;怼人，我是在等待发呆，笨小孩&quot;,&quot;杀猪&quot;,&quot;打豆豆&quot;],&quot;age&quot;:18&#125;, &#123;&quot;firstName&quot;:&quot;王把&quot;,&quot;lastName&quot;:&quot;君君&quot;,&quot;about&quot;:&quot;中华人民共和国体育总局，不让我的&lt;span style=\&quot;color:red\&quot;&gt;眼&lt;/span&gt;&lt;span style=\&quot;color:red\&quot;&gt;泪&lt;/span&gt;陪我过夜&quot;,&quot;interests&quot;:[&quot;怼人，我是在等待发呆，笨小孩&quot;,&quot;杀猪&quot;,&quot;打豆豆&quot;],&quot;age&quot;:18&#125;]]]></content>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch实现中文分词和拼音分词混合查询+CompletionSuggestion]]></title>
    <url>%2F2018%2F01%2F14%2Felasticsearch%E5%AE%9E%E7%8E%B0%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%92%8C%E6%8B%BC%E9%9F%B3%E5%88%86%E8%AF%8D%E6%B7%B7%E5%90%88%E6%9F%A5%E8%AF%A2-CompletionSuggestion%2F</url>
    <content type="text"><![CDATA[引言之前已经介绍了如何搭建elasticsearch服务端和简单的索引创建，和中文分词的支持。今天我们来说一说如何实现elasticsearch同时实现中文分词和pinyin分词。并且实现类似百度搜索栏的搜索建议的功能。 混合查询实现混合查询有很多方式，这里介绍我认为是一个偷懒的方法，就是为你要拼音搜索的字段提供两个额外的字段，一个是全拼字段，一个是首字母缩写字段。我这里用的是官网的Employee的例子：1234567891011public class Employee implements Serializable &#123; private String firstName; private String lastName; private String pinyin;//firstName全拼 private String header;//firstName首字母缩写 private int age; private String about; private List&lt;String&gt; interests; ....省略getter setter 接下来为index添加setting和mapping123456789101112131415161718192021222324252627282930313233343536373839404142434445XContentBuilder settings = XContentFactory.jsonBuilder(); settings.startObject() .startObject(&quot;analysis&quot;) .startObject(&quot;analyzer&quot;) .startObject(&quot;ik_analyzer&quot;).field(&quot;tokenizer&quot;,&quot;ik_smart&quot;) .endObject() .endObject() .endObject().endObject(); CreateIndexRequest createIndexRequest = new CreateIndexRequest(index).settings(settings); CreateIndexResponse createIndexResponse = esClient.admin().indices().create(createIndexRequest).get(); logger.info(&quot;Index:&#123;&#125; created,response:&#123;&#125;&quot;, index, JSON.toJSON(createIndexResponse)); XContentBuilder builder = XContentFactory.jsonBuilder(); builder.startObject() .startObject(type) .startObject(&quot;properties&quot;) .startObject(&quot;firstName&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) /* .field(&quot;search_analyzer&quot;,&quot;ik_smart&quot;).field(&quot;preserve_separators&quot;,false) .field(&quot;preserve_position_increments&quot;,false)*/ .endObject() .startObject(&quot;lastName&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) .endObject() .startObject(&quot;pinyin&quot;).field(&quot;type&quot;,&quot;string&quot;).field(&quot;analyzer&quot;,&quot;pinyin&quot;) .startObject() .startObject(&quot;header&quot;).field(&quot;type&quot;,&quot;string&quot;).field(&quot;analyzer&quot;,&quot;pinyin&quot;) .startObject(&quot;about&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) .endObject() .startObject(&quot;interests&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) .endObject() .endObject() .endObject() .endObject(); PutMappingRequest putMappingRequest = new PutMappingRequest(index); putMappingRequest.type(type); putMappingRequest.source(builder); PutMappingResponse putMappingResponse = esClient.admin().indices().putMapping(putMappingRequest).get(); logger.info(&quot;Mapping for `&#123;&#125;.&#123;&#125;` putted, response:&#123;&#125;&quot;, index, type, JSON.toJSON(putMappingResponse)); return true; &#125; catch (Exception e) &#123; logger.error(&quot;doCreateIndex&quot;, e); return false; &#125; 添加几个测试用例，我这里直接用了批量插入索引的方法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public Boolean bulkIndex(List&lt;String&gt; jsonList)&#123; if(esIndexTypes.get(index)==null) &#123; if(getMapping(index, indexType)) esIndexTypes.put(index,true); &#125; BulkRequestBuilder bulkBuilder= esClient.prepareBulk(); for (String s : jsonList) &#123; IndexRequestBuilder requestBuilder = esClient.prepareIndex(index, indexType) .setSource(s); bulkBuilder.add(requestBuilder); &#125; BulkResponse bulkResponse = bulkBuilder.execute().actionGet(); logger.info(&quot;index:&#123;&#125; bulk request,:response:&#123;&#125;&quot;,index,JSON.toJSON(bulkResponse)); return true;&#125;@org.junit.Testpublic void test()&#123; List&lt;String&gt; list1 = new ArrayList&lt;&gt;(10000); for (int i=0;i&lt;10000;i++) &#123; Employee employee = new Employee(); employee.setFirstName(&quot;告白气球&quot;+i); employee.setPinyin(&quot;gaobaiqiqiu&quot;+i); employee.setHeader(&quot;gbqq&quot;); employee.setLastName(&quot;周杰伦,日记&quot;); employee.setAbout(&quot;呜啦啦啦火车笛\n&quot; + &quot;\n&quot; + &quot;随着奔腾的马蹄\n&quot; + &quot;\n&quot; + &quot;小妹妹吹着口琴\n&quot; + &quot;\n&quot; + &quot;夕阳下美了剪影\n&quot; + &quot;\n&quot; + &quot;我用子弹写日记,我泡妞看电影&quot;); employee.setAge(18); List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;喜欢打篮球&quot;); list.add(&quot;在大晴天晒太阳&quot;); list.add(&quot;泡妞看电影&quot;); employee.setInterests(list); list1.add(JSON.toJSONString(employee)); &#125; boolean index = esProxy.bulkIndex(list1);&#125; 最后直接搜gaobaiqiqiu或gbqq搜出来的数据像这样：1[&#123;&quot;firstName&quot;:&quot;告白气球&quot;,&quot;lastName&quot;:&quot;周杰伦,日记&quot;,&quot;pinyin&quot;:&quot;gaobaiqiqiu&quot;,&quot;about&quot;:&quot;呜啦啦啦火车笛\n\n随着奔腾的马蹄\n\n小妹妹吹着口琴\n\n夕阳下美了剪影\n\n我用子弹写日记,我泡妞看电影&quot;,&quot;header&quot;:&quot;gbqq&quot;,&quot;interests&quot;:[&quot;喜欢打篮球&quot;,&quot;在大晴天晒太阳&quot;,&quot;泡妞看电影&quot;],&quot;age&quot;:18&#125;] 如果直接搜告白搜出来的数据像这样:1[&#123;&quot;firstName&quot;:&quot;&lt;span style=\&quot;color:red\&quot;&gt;告白&lt;/span&gt;气球&quot;,&quot;lastName&quot;:&quot;周杰伦,日记&quot;,&quot;pinyin&quot;:&quot;gaobaiqiqiu&quot;,&quot;about&quot;:&quot;呜啦啦啦火车笛\n\n随着奔腾的马蹄\n\n小妹妹吹着口琴\n\n夕阳下美了剪影\n\n我用子弹写日记,我泡妞看电影&quot;,&quot;header&quot;:&quot;gbqq&quot;,&quot;interests&quot;:[&quot;喜欢打篮球&quot;,&quot;在大晴天晒太阳&quot;,&quot;泡妞看电影&quot;],&quot;age&quot;:18&#125;] CompletionSuggestion查询建议使用CompletionSuggestion时mapping需要改一下，实时推荐的字段type需要使用completion。1234567891011121314151617181920XContentBuilder builder = XContentFactory.jsonBuilder(); builder.startObject() .startObject(type) .startObject(&quot;properties&quot;) .startObject(&quot;firstName&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) .field(&quot;search_analyzer&quot;,&quot;ik_smart&quot;).field(&quot;preserve_separators&quot;,false) .field(&quot;preserve_position_increments&quot;,false) .endObject() .startObject(&quot;lastName&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) .endObject() .startObject(&quot;pinyin&quot;).field(&quot;type&quot;,&quot;string&quot;).field(&quot;analyzer&quot;,&quot;pinyin&quot;) .startObject() .startObject(&quot;header&quot;).field(&quot;type&quot;,&quot;string&quot;).field(&quot;analyzer&quot;,&quot;pinyin&quot;) .startObject(&quot;about&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) .endObject() .startObject(&quot;interests&quot;).field(&quot;type&quot;, &quot;string&quot;).field(&quot;analyzer&quot;,&quot;ik_smart&quot;) .endObject() .endObject() .endObject() .endObject(); 查询的时候需要使用CompletionSuggestionBuilder.123456789101112131415161718192021public void searchSuggest(String str)&#123; CompletionSuggestionBuilder suggestionBuilder = new CompletionSuggestionBuilder(&quot;firstName&quot;); suggestionBuilder.analyzer(&quot;ik_smart&quot;); suggestionBuilder.text(str); SearchResponse response = esClient.prepareSearch(index).setTypes(indexType).setQuery(QueryBuilders.matchAllQuery()) .suggest(new SuggestBuilder().addSuggestion(&quot;my-suggest-1&quot;,suggestionBuilder)).get(); Suggest suggest= response.getSuggest(); CompletionSuggestion suggestion = suggest.getSuggestion(&quot;my-suggest-1&quot;); List&lt;CompletionSuggestion.Entry&gt; list = suggestion.getEntries(); for (int i = 0; i &lt; list.size(); i++) &#123; List&lt;CompletionSuggestion.Entry.Option&gt; options = list.get(i).getOptions(); for (int j = 0; j &lt; options.size(); j++) &#123; if (options.get(j) instanceof CompletionSuggestion.Entry.Option) &#123; CompletionSuggestion.Entry.Option op = options.get(j); System.out.println(op.getScore()+&quot;--&quot;+op.getText()); &#125; &#125; &#125; &#125; 你也可以使用restAPI：http://192.168.10.xxx:9200/megacorp/_search?pretty这里megacorp是indexName,12345678910&#123; &quot;size&quot;: 0, &quot;suggest&quot;: &#123; &quot;my-suggest-1&quot;: &#123; &quot;prefix&quot;: &quot;someone li&quot;, &quot;completion&quot;: &#123; &quot;field&quot;: &quot;firstName&quot; &#125; &#125; &#125;&#125; 查询出来的结果:12345678910111213141516171819202122232425262728293031323334353637383940414243&#123; &quot;took&quot;: 12, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 0, &quot;max_score&quot;: 0, &quot;hits&quot;: [] &#125;, &quot;suggest&quot;: &#123; &quot;blog-suggest&quot;: [ &#123; &quot;text&quot;: &quot;someone li&quot;, &quot;offset&quot;: 0, &quot;length&quot;: 10, &quot;options&quot;: [ &#123; &quot;text&quot;: &quot;someone like you&quot;, &quot;_index&quot;: &quot;megacorp&quot;, &quot;_type&quot;: &quot;employee&quot;, &quot;_id&quot;: &quot;AV_doqcXKY206Vs3lcCO&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;about&quot;: &quot;呜啦啦啦火车笛\n\n随着奔腾的马蹄\n\n小妹妹吹着口琴\n\n夕阳下美了剪影\n\n我用子弹写日记,我泡妞看电影&quot;, &quot;age&quot;: 18, &quot;firstName&quot;: &quot;someone like you&quot;, &quot;interests&quot;: [ &quot;喜欢打篮球&quot;, &quot;在大晴天晒太阳&quot;, &quot;泡妞看电影&quot; ], &quot;lastName&quot;: &quot;周杰伦,日记&quot; &#125; &#125; ] &#125; ] &#125;&#125;]]></content>
      <tags>
        <tag>elasticsearch,CompletionSuggestion</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot启动流程]]></title>
    <url>%2F2017%2F09%2F21%2Fspring-boot%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[引言早在15年的时候就开始用spring boot进行开发了，然而一直就只是用用，并没有深入去了解spring boot是以什么原理怎样工作的，说来也惭愧。今天让我们从spring boot启动开始，深入了解一下spring boot的工作原理。 为什么用spring boot在使用一个东西或者一个工具之前，我们总是会问自己，我为什么要用？用他能给我带来什么好处？ 最大的好处就是spring boot遵从了java约定大于配置不用面对一大堆的配置文件，spring boot是根据你用的包来决定提供什么配置。 服务器以jar包的形式内嵌于项目中，对于微服务满天飞的情况，spring boot天生适合微服务架构，方便部署。 提供devtools从此改代码就需重启成为历史。 ​ 有优点就一定有缺点，缺点来源于优点优点来源于缺点（感觉在说哲学问题了哈哈哈） 正因为配置对开发者不透明，不看源码会不清楚spring boot如何进行诸如JDBC加载、事务管理等，出现错误也很难调错。 自动配置之后要自定义配置需编码javaConfig，需要了解这些配置类api。 版本迭代太快，新版本对老版本改动太多导致不兼容，比如1.3.5之前的springBootTest和1.4.0之后的springBootTest。 只有合适的架构才是最好的架构如果能接受spring boot这些缺点，spring boot确实是一个可以提高开发效率的不错的选择。 启动流程扯了这么多，该上正题了，让我们来看看spring boot是怎样启动和启动做了哪些事情。 以下代码是spring boot项目标准的启动方式，使用注解@SpringBootApplication并且在main方法中调用SpringApplication的run方法，就可以完成。我们就从这个run方法开始看看spring boot的启动过程。12345678@SpringBootApplicationpublic class Application &#123; public static void main(String[] args)&#123; SpringApplication.run(Application.class,args); &#125;&#125; 我们进入run方法，可以看到最终是调用了 new SpringApplication(sources).run(args);new SpringApplication(sources).run(args); 这个方法，可以看到，springBoot的启动可以分为两个部分，第一部分：SpringApplication的实例化；第二部分：调用该实例运行run方法。我们先来看看这个SpringApplication的实例化过程。1234567891011121314private void initialize(Object[] sources) &#123; if (sources != null &amp;&amp; sources.length &gt; 0) &#123; this.sources.addAll(Arrays.asList(sources)); &#125; //判定是否为webEnvironment this.webEnvironment = deduceWebEnvironment(); //实例化并加载所有可以加载的ApplicationContextInitializer setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); //实例化并加载所有可以加载的ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); &#125; 关键点在两个set方法上setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)) 和 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)) 这两个方法一毛一样，挑实例化ApplicationContextInitializer讲一讲。123456789101112131415private &lt;T&gt; Collection&lt;? extends T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; //拿到类加载器 ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); // Use names and ensure unique to protect against duplicates //使用loadFactoryNames方法载入所有的ApplicationContextInitializer的类全限定名 Set&lt;String&gt; names = new LinkedHashSet&lt;String&gt;( SpringFactoriesLoader.loadFactoryNames(type, classLoader)); //使用反射将所有的ApplicationContextInitializer实例化 List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); //排序 AnnotationAwareOrderComparator.sort(instances); return instances; &#125; 自动配置的关键就是这个 getSpringFactoriesInstances方法,确切的说是这个方法里的loadFactoryNames方法，浪我们看看这个loadFactoryNames方法干了啥，咋就能实现自动配置。12345678910111213141516171819public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, ClassLoader classLoader) &#123; String factoryClassName = factoryClass.getName(); try &#123; Enumeration&lt;URL&gt; urls = classLoader != null?classLoader.getResources(&quot;META-INF/spring.factories&quot;):ClassLoader.getSystemResources(&quot;META-INF/spring.factories&quot;); ArrayList result = new ArrayList(); while(urls.hasMoreElements()) &#123; URL url = (URL)urls.nextElement(); Properties properties = PropertiesLoaderUtils.loadProperties(new UrlResource(url)); String factoryClassNames = properties.getProperty(factoryClassName); result.addAll(Arrays.asList(StringUtils.commaDelimitedListToStringArray(factoryClassNames))); &#125; return result; &#125; catch (IOException var8) &#123; throw new IllegalArgumentException(&quot;Unable to load [&quot; + factoryClass.getName() + &quot;] factories from location [&quot; + &quot;META-INF/spring.factories&quot; + &quot;]&quot;, var8); &#125;&#125; 可以看到这个方法就做了一件事，就是从META-INF/spring.factories这个路径取出所有”url”来，我们可以去到这个路径下看看到底是些啥？1234567# Initializersorg.springframework.context.ApplicationContextInitializer=\org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer# Application Listenersorg.springframework.context.ApplicationListener=\org.springframework.boot.autoconfigure.BackgroundPreinitializer 这下大家都应该明白了，spring是通过将所有你加载的jar包中找到它需要的ApplicationContextInitializer来进行动态的配置的，只要你有用到特定的maven包，初始化的时候会找这个包下的META-INF/spring.factories的需要的类比如ApplicationContextInitializer进行实例化bean，你就可以用了，不需要任何配置。说到这已经将所有SpringApplication实例化说完了，只是在加载完ApplicationContextInitializer和ApplicationListener这之后还有一步，就是找到启动类所在的位置并且设入属性mainApplicationClass中。 接下来让我们回到new SpringApplication(sources).run(args)方法来看看run方法是怎么run的。1234567891011121314151617181920212223242526272829303132333435363738public ConfigurableApplicationContext run(String... args) &#123; //开启启动计时器，项目启动完会打印执行时间出来 StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); //获取SpringApplicationRunListener并启动监听器 SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); //环境变量的加载 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); //启动后console的打印出来的一堆配置信息 Banner printedBanner = printBanner(environment); //终极大boss-&gt;ApplicationContext实例化 context = createApplicationContext(); analyzers = new FailureAnalyzers(context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125; &#125; 从这个方法里面做的最关键的三件事情就是： 获取监听器并启动 加载环境变量，该环境变量包括system environment、classpath environment和用户自己加的application.properties 创建ApplicationContext 12345678910111213141516171819202122232425private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); postProcessApplicationContext(context); applyInitializers(context); listeners.contextPrepared(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // Add boot specific singleton beans context.getBeanFactory().registerSingleton(&quot;springApplicationArguments&quot;, applicationArguments); if (printedBanner != null) &#123; context.getBeanFactory().registerSingleton(&quot;springBootBanner&quot;, printedBanner); &#125; // Load the sources Set&lt;Object&gt; sources = getSources(); Assert.notEmpty(sources, &quot;Sources must not be empty&quot;); load(context, sources.toArray(new Object[sources.size()])); listeners.contextLoaded(context); &#125; 前两点没什么好说的，重点说说第三个，创建ApplicationContext。创建applicationContext又分为几部：实例化applicationContext、prepareContext、refreshContext。实例化applicationContext会根据在之前我们说的webEnvironment这个属性判断是使用webContext类AnnotationConfigEmbeddedWebApplicationContext还是普通context类AnnotationConfigApplicationContext（在这里我们使用的是webContext为例）然后通过反射进行实例化。applicationContext实例化完了会进入prepareContext流程，这个prepareContext方法会加载之前准备好的environment进入context中，然后如果有beanNameGenerator和resourceLoader那么提前创建bean加载进applicationContext，但是一般这两个都是空的，所以直接进入applyInitializers方法，将之前实例化的所有initializers进行初始化，所有的bean就是在这里进行bean的扫描和加载的因这次讲的是启动过程，所以不再细讲。最后把创建好的applicationContext设置进入listener，prepareContext过程就结束了。最后是refreshContext，这个就和spring的bean加载过程一致了，bean的注入、beanFactory、postProcessBeanFactory等等，详情可以去看看spring bean的生命周期。 总结spring boot 初始化内容还是很多的，但是总结起来就四点： 创建SpringApplication实例，判定环境，是web环境还是普通环境。加载所有需要用到的Initializers和Listeners，这里使用约定大于配置的理念揭开了自动配置的面纱。 加载环境变量，环境变量包括system environment、classpath environment、application environment（也就是我们自定义的application.properties配置文件） 创建SpringApplicationRunListeners 创建ApplicationContext，设置装配context，在这里将所有的bean进行扫描最后在refreshContext的时候进行加载、注入。最终将装配好的context作为属性设置进SpringApplicationRunListeners，这就完成了一个spring boot项目的启动。]]></content>
      <tags>
        <tag>spring boot,源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch5.x服务器搭建]]></title>
    <url>%2F2017%2F06%2F21%2Felasticsearch5-x%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[引言之前与搜索有关的需求都是使用solrCloud实现的，最近公司在做日志监控的时候使用并没有用solr而是使用了好评更甚的elasticsearch。之前本来就一直想了解es，现在刚好有机会学习，特此记录下学习的过程。 what is elasticsearchelasticsearch（以下使用缩写es代替）是一个基于lucene的分布式、近实时的全文搜索引擎。它还是一个分布式非关系型数据库，被es存储的json数据每个字段都会被索引且可被搜索，并且es可以轻松的存储和处理达pb级别的数据。 服务环境搭建首先准备好elasticsearch按照包我用的是当时最新版5.3.0。1elasticsearch-5.3.0.tar.gz 解压，因本人机器性能有限，并没有用上集群，使用默认设置直接启动。需要注意的是elasticsearch不允许root权限进行启动，所以需要创建一个单独用户来运行。123456adduser elastic -g elastic -p elasticgroupadd elastictar -zvxf elasticsearch-5.3.0.tar.gz chown -R elastic:elastic elasticsearch-5.3.0 使用默认配置启动elasticsearch 1./elasticsearch-5.3.0/bin/elasticsearch 当看到以下日志时就说明启动成功123456789101112131415161718[2017-06-21T04:42:29,857][INFO ][o.e.n.Node ] initialized[2017-06-21T04:42:29,857][INFO ][o.e.n.Node ] [vQCqom0] starting ...[2017-06-21T04:42:30,305][INFO ][o.e.t.TransportService ] [vQCqom0] publish_address &#123;192.168.10.133:9300&#125;, bound_addresses &#123;[::]:9300&#125;[2017-06-21T04:42:30,333][INFO ][o.e.b.BootstrapChecks ] [vQCqom0] bound or publishing to a non-loopback or non-link-local address, enforcing bootstrap checks[2017-06-21T04:42:33,430][INFO ][o.e.c.s.ClusterService ] [vQCqom0] new_master &#123;vQCqom0&#125;&#123;vQCqom0yQMypwf2VdeS4cw&#125;&#123;8_zAvAFORVK2GCS-3N0CNQ&#125;&#123;192.168.10.133&#125;&#123;192.168.10.133:9300&#125;, reason: zen-disco-elected-as-master ([0] nodes joined)[2017-06-21T04:42:33,508][INFO ][o.e.h.n.Netty4HttpServerTransport] [vQCqom0] publish_address &#123;192.168.10.133:9200&#125;, bound_addresses &#123;[::]:9200&#125;[2017-06-21T04:42:33,521][INFO ][o.e.n.Node ] [vQCqom0] started[2017-06-21T04:42:33,651][INFO ][o.w.a.d.Monitor ] try load config from /elastic/elasticsearch-5.3.0/config/analysis-ik/IKAnalyzer.cfg.xml[2017-06-21T04:42:33,653][INFO ][o.w.a.d.Monitor ] try load config from /elastic/elasticsearch-5.3.0/plugins/ik/config/IKAnalyzer.cfg.xml[2017-06-21T04:42:35,023][INFO ][o.e.m.j.JvmGcMonitorService] [vQCqom0] [gc][young][5][9] duration [985ms], collections [1]/[1.1s], total [985ms]/[4.2s], memory [76.5mb]-&gt;[65.7mb]/[1.9gb], all_pools &#123;[young] [49mb]-&gt;[221.7kb]/[66.5mb]&#125;&#123;[survivor] [8.3mb]-&gt;[8.3mb]/[8.3mb]&#125;&#123;[old] [19.1mb]-&gt;[57.4mb]/[1.9gb]&#125;[2017-06-21T04:42:35,023][WARN ][o.e.m.j.JvmGcMonitorService] [vQCqom0] [gc][5] overhead, spent [985ms] collecting in the last [1.1s][2017-06-21T04:42:35,209][INFO ][o.w.a.d.Monitor ] [Dict Loading] custom/mydict.dic[2017-06-21T04:42:35,236][INFO ][o.w.a.d.Monitor ] [Dict Loading] custom/single_word_low_freq.dic[2017-06-21T04:42:35,261][INFO ][o.w.a.d.Monitor ] [Dict Loading] custom/ext_stopword.dic[2017-06-21T04:42:35,538][INFO ][o.e.g.GatewayService ] [vQCqom0] recovered [2] indices into cluster_state[2017-06-21T04:42:36,324][INFO ][o.e.c.r.a.AllocationService] [vQCqom0] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[megacorp][2]] ...]).[2017-06-21T04:43:04,255][INFO ][o.e.m.j.JvmGcMonitorService] [vQCqom0] [gc][young][34][10] duration [728ms], collections [1]/[1.1s], total [728ms]/[4.9s], memory [131.6mb]-&gt;[90.2mb]/[1.9gb], all_pools &#123;[young] [65.9mb]-&gt;[145kb]/[66.5mb]&#125;&#123;[survivor] [8.3mb]-&gt;[8.3mb]/[8.3mb]&#125;&#123;[old] [57.4mb]-&gt;[81.8mb]/[1.9gb]&#125;[2017-06-21T04:43:04,255][WARN ][o.e.m.j.JvmGcMonitorService] [vQCqom0] [gc][34] overhead, spent [728ms] collecting in the last [1.1s] 错误集锦与处理ERROR: bootstrap checks failed 具体报错信息为：max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]max number of threads [1024] for user [lishang] likely too low, increase to at least [2048] 意思就是文件描述符至少需要65536个，线程数至少需要2048个。 解决方法：切换到root用户，进入到security目录下的limits.conf1vim /etc/security/limits.conf 文件末尾追加一下数据1234567* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096 重启生效 max number of threads [1024] for user [lish] likely too low, increase to at least [2048] 解决方法：切换到root用户，进入limits.d目录下修改配置文件。12345vim /etc/security/limits.d/90-nproc.conf将这一行* soft nproc 1024改为* soft nproc 2048 max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144] 解决方法：切换到root用户修改配置sysctl.conf1vim /etc/sysctl.conf 文件后面追加一下配置：1vm.max_map_count=655360 执行命令1sysctl -p]]></content>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中如何正确使用volatile]]></title>
    <url>%2F2017%2F04%2F16%2Fjava%E4%B8%AD%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E4%BD%BF%E7%94%A8volatile%2F</url>
    <content type="text"><![CDATA[引言对于java开发同学来说，说到多线程首先想到的就是队列、synchronized、lock等等，就这几个东西就够说好几个文章的篇幅了，今天我们主角并不是它们，而是并不太受欢迎的volatile。很多开发同学可能一碰到多线程变量共享问题直接上锁，当然这样做也是无可以厚非，毕竟木有用错，只能说这样编码不是那么的优雅，如果说能使用锁和volatile配合使用无论对性能也好还是对java语言的理解也都是很有帮助的。volatile关键字在java多线程中有着比较重要作用，volatile主要作用是可以保持变量在多线程中是实时可见的,是java中提供的最轻量的同步机制。 可见性在Java的内存模型中所有的的变量（这里的变量是类全局变量，并不是局部变量，局部变量在方法内并没有线程安全的问题，因为变量随方法调用完成而销毁）都是存放在主内存中的，而每个线程有自己的工作内存，每次线程执行时，会从主内存获取变量的拷贝，对变量的操作都在线程的工作内存中进行，不同线程之间也不能共享工作内存，只能从主内存读取变量的拷贝。具体可以通过下图来表示： 然而对于volatile（使用synchronized/final修饰都具有可见性）来说打破了上述的规则，即当线程修改了变量的值，其他线程可以立即知道该变量的改变。然而对于普通变量来说，当一个线程修改了变量，需要先将变量写回主内存，其他线程从主内存读取变量后才对该线程可见。似乎从以上的描述可以推导出只要使用volatile修饰的变量就可以保证该变量在多线程环境下操作是安全的，因为它对于所有线程的工作内存都是可见的也就是说一致的。这么理解确实没错，但是在java中很多运算都不是原子的，所以在java的一些运算中使用volatile并不能保证线程安全问题。让我们来看一个例子：12345678910111213141516171819202122232425public class test&#123;private static volatile t=0; private static int add()&#123; return t++; &#125; public static void testVolatile()&#123; for (int i=0;i&lt;20;i++)&#123; Thread thread=new Thread(()-&gt; &#123; for (int j=0;j&lt;1000;j++) &#123; add(); &#125; &#125;); thread.start(); &#125; while (Thread.activeCount()&gt;1)&#123; Thread.yield(); &#125; System.out.println(t); &#125; public static void main(String[] args)&#123; testVolatile(); &#125;&#125; 预期这个t值应该是20000，但是会出现t值小于20000的情况，原因大家应该猜到了，问题出在t++上，t++并不是一个原子操作，t++的操作在java中代表先获取t值，再加1，再赋值还t。在获取t值时因为是volatile修饰的，所以可以获取线程最新值，然而在加1的时候就不能保证了，有可能其他线程已经加1了。 使用场景那么什么场景使用volatile是最合适的呢？ 在变量运算不依赖当前值 变量不需要与其他状态变量共同参与不变约束翻译成中文就是对于那些在多线程中既有读又有写的变量，完全可以使用volatile修饰，这样就对于读操作就不要使用lock/synchronized比较重的操作了，直接读就是，因为变量是可见的。]]></content>
      <tags>
        <tag>volatile,多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring boot学习之调用dubbo]]></title>
    <url>%2F2016%2F12%2F07%2FSpring-boot%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B0%83%E7%94%A8dubbo%2F</url>
    <content type="text"><![CDATA[Spring boot好早之前就有在用，但是都是用Spring boot建简单的web站点，很多Spring boot其他特性的使用都处于未知状态，最近又开始使用Spring boot开发，特此记录。 使用@Import注解引入配置文件Spring boot最好用的一点就是自动配置，约定大于配置的特性让我们减少了很多配置工作，但是有很多情况下是不能自动配置的，比如dubbo就没有，所以dubbo的引入依旧需要配置文件，Spring boot要使配置文件生效需要引入配置文件，引入方式如下：12345678@SpringBootApplication@Import(&quot;classpath:*.xml&quot;)public class App&#123; public static void main(String[] args)&#123; SpringApplication.run(App.class,args); &#125;&#125; 使用CommandLineRunner接口在开发时经常会有在项目启动后就初始化模块、或者执行一次的需求，这时CommandLineRunner就是一个很好的选择，该接口有run()方法当实现了CommandLineRunner接口,项目启动之后会首先执行run方法。例如：123456789@Componentpublic class StartupRunner implements CommandLineRunner &#123; protected final Logger logger = LoggerFactory.getLogger(StartupRunner.class); @Override public void run(String... strings) throws Exception &#123; logger.info(&quot;you are invoke this method!&quot;); &#125;&#125;]]></content>
      <tags>
        <tag>Spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用spring方式引入外部文件]]></title>
    <url>%2F2016%2F11%2F18%2F%E4%BD%BF%E7%94%A8spring%E6%96%B9%E5%BC%8F%E5%BC%95%E5%A6%82%E5%A4%96%E9%83%A8%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[在很多业务场景下我们都需要引入外部文件，比如大量的静态json、业务模板、xml文件等，大量的外部文件引入如果方式不正确很有可能会导致系统性能问题，今天我们就说说如何使用优雅的方式引入外部文件。 传统引入方式一般我们引入外部文件都是通过IO流的方式引入，每次使用都要从硬盘读到内存中。代码如下：12345678910111213public String readFile()&#123; File file=new File(&quot;test.txt&quot;); BufferedReader reader=new BufferedReader(new InputStreamReader(new FileInputStream(file))); StringBuffer sb=new StringBuffer(); String temp=null; while((temp=reader.readLine())!=null)&#123; sb.append(temp); &#125; reader.close(); &#125; 该代码缺陷在于，每用一次就要从硬盘读取到内存，性能着急，这样的代码是不行的。 使用spring方式如果系统中使用来spring框架，那么你可以优雅的使用spring来引入外部文件，spring自带有resource解析器Resource可以在项目启动时加载静态资源。我们可以定义一个专门的BeanResourceResolver来加载外部文件，代码如下：123456789101112131415161718192021222324252627282930313233public class ResourceResolver &#123; private Resource resource; private String transforStr; @PostConstruct public void readFile()throws IOException&#123; File file=resource.getFile(); BufferedReader reader=new BufferedReader(new InputStreamReader(new FileInputStream(file))); StringBuffer sb=new StringBuffer(); String temp=null; while((temp=reader.readLine())!=null)&#123; sb.append(temp); &#125; reader.close(); this.transforStr=sb.toString(); &#125; public String getTransforStr() &#123; return transforStr; &#125; public void setTransforStr(String transforStr) &#123; this.transforStr = transforStr; &#125; public Resource getResource() &#123; return resource; &#125; public void setResource(Resource resource) &#123; this.resource = resource; &#125;&#125; 在spring配置文件中配置：123&lt;bean id=&quot;resourceResolver&quot; class=&quot;com.ifenqu.bean.ResourceResolver&quot;&gt; &lt;property name=&quot;resource&quot; value=&quot;classpath:test.txt&quot;&gt;&lt;/property&gt; &lt;/bean&gt; 相对于第一种实现方式，使用spring的方式只需要在项目加载的时候执行一次从磁盘加载到内存操作就行，该方式更佳优雅。]]></content>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC源码分析之Handler请求映射与调用]]></title>
    <url>%2F2016%2F10%2F30%2FpageSpringMVC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BHandler%E8%AF%B7%E6%B1%82%E6%98%A0%E5%B0%84%E4%B8%8E%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[在前两篇说了springMVC的初始化和HandlerMapping，接下来我们用最后一篇说说handler被映射和调用的过程。在说过初始化和HandlerMapping的注册过程后，springMVC的映射和调用就很简单了。 请求映射Handler当一个请求发出后，比如我们发出一个”http://localhost:8080/pay/payment&quot;的请求，springMVC会先将路径封装到HttpServletRequest中，而spring容器会通过getHandler方法来通过路径找到上一篇说的已经注册好的HandlerMapping。请看如下代码：123456789101112131415161718192021222324252627protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // 找到当前请求的handler. mappedHandler = getHandler(processedRequest); if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; //未找到handler抛出异常 noHandlerFound(processedRequest, response); return; &#125; // 找到handler之后，为该handler匹配正确的适配器 HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());................截取部分代码 通过request来匹配当前已经注册了的handlerMapping，再通过handlerMapping来获取handler。123456789101112protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; for (HandlerMapping hm : this.handlerMappings) &#123; if (logger.isTraceEnabled()) &#123; logger.trace( &quot;Testing handler map [&quot; + hm + &quot;] in DispatcherServlet with name &apos;&quot; + getServletName() + &quot;&apos;&quot;); &#125; HandlerExecutionChain handler = hm.getHandler(request); if (handler != null) &#123; return handler; &#125; &#125; return null; 从下面的代码来看，spring容器是通过request封装的请求路径lookupPath来找到handler的，并且也是通过lookupPath来找到handler的handlerMethod的，代码就不重复贴了。12345678910111213141516171819202122protected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception &#123; String lookupPath = getUrlPathHelper().getLookupPathForRequest(request); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Looking up handler method for path &quot; + lookupPath); &#125; this.mappingRegistry.acquireReadLock(); try &#123; HandlerMethod handlerMethod = lookupHandlerMethod(lookupPath, request); if (logger.isDebugEnabled()) &#123; if (handlerMethod != null) &#123; logger.debug(&quot;Returning handler method [&quot; + handlerMethod + &quot;]&quot;); &#125; else &#123; logger.debug(&quot;Did not find handler method for [&quot; + lookupPath + &quot;]&quot;); &#125; &#125; return (handlerMethod != null ? handlerMethod.createWithResolvedBean() : null); &#125; finally &#123; this.mappingRegistry.releaseReadLock(); &#125; &#125; 在找到handler之后返回的并不是仅仅是handler，而是HandlerExecutionChain，这一招应该是借鉴了struts的优良责任链模式，在handler的处理前后还有可能有多个处理逻辑，这其中包括各种拦截器或者其他的handler处理。 handler调用handler获取之后接下来就是获取对应的adapter，在这使用的是适配器模式，在springMVC中有各种类型的controller bean，你比如使用注解的不使用注解的。为了方便扩展，spring容器使用适配器模式来对应不同controller调用，也就是通过实现adapter接口同时组合该handler来实现不同handler使用统一的调用方式。获取adapter的方式和获取handler的方式差不多，这里就不展开讲。接下来也就是最后的一步–调用handler。调用handler主要三步，第一获取解析器，第二步获取具体方法，第三部反射调用方法并返回结果封装到ModelAndView中最终返回，详情看下面代码：123456789101112131415161718protected ModelAndView invokeHandlerMethod(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //获取方法解析器 ServletHandlerMethodResolver methodResolver = getMethodResolver(handler); //通过方法解析器通过request的url来调用具体方法 Method handlerMethod = methodResolver.resolveHandlerMethod(request); ServletHandlerMethodInvoker methodInvoker = new ServletHandlerMethodInvoker(methodResolver); ServletWebRequest webRequest = new ServletWebRequest(request, response); ExtendedModelMap implicitModel = new BindingAwareModelMap(); //调用具体方法返回结果 Object result = methodInvoker.invokeHandlerMethod(handlerMethod, handler, webRequest, implicitModel); //将结果封装到modelAndView中结果返回 ModelAndView mav = methodInvoker.getModelAndView(handlerMethod, handler.getClass(), result, implicitModel, webRequest); methodInvoker.updateModelAttributes(handler, (mav != null ? mav.getModel() : null), implicitModel, webRequest); return mav;&#125; 总的来说，springMVC方法调用还是比较简单的，通过请求的mapping路径匹配具体的handler，也就是我们说的controller，找到handler还要将找到对应的适配器，最后才是调用具体方法返回已经被封装成ModelAndView的结果。]]></content>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springMVC源码分析之HandlerMapping请求映射]]></title>
    <url>%2F2016%2F09%2F16%2FspringMVC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BHandlerMapping%E8%AF%B7%E6%B1%82%E6%98%A0%E5%B0%84%2F</url>
    <content type="text"><![CDATA[在上一篇我们说了springMVC的初始化，作为springMVC启动的第一步完成的任务是初始化spring的IoC容器、初始化DispatchServlet的IoC容器，同时将webApplicationContext进行初始化，接下来就是strategy的初始化。这一系列初始化后接下来就是要完成根据url来映射到对应的具体方法并调用到最后返回页面。在接下的的两篇博文中我会分两篇来说说springMVC具体的映射分析。 Handler注册在springMVC中最后一步是初始化strategy，就是初始化各个解析器如HandlerMapping和handlerAdapter。这是springMVC各配件初始化的入口。而initStrategies方法中initHandlerMapping是handlerMapping初始化的入口，该方法逻辑比较简单，首先从ApplicationContext中找到所有的HandlerMapping，如果没有则使用默认的HandlerMapping –DefaultAnnonationHandlerMapping、BeanNameUrlHandlerMapping。具体请看下面源码12345678910111213141516171819202122232425262728293031private void initHandlerMappings(ApplicationContext context) &#123; this.handlerMappings = null; if (this.detectAllHandlerMappings) &#123; //从ApplicationContext中获取所有HandlerMapping包括父Context Map&lt;String, HandlerMapping&gt; matchingBeans = BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerMapping.class, true, false); if (!matchingBeans.isEmpty()) &#123; this.handlerMappings = new ArrayList&lt;HandlerMapping&gt;(matchingBeans.values()); // We keep HandlerMappings in sorted order. AnnotationAwareOrderComparator.sort(this.handlerMappings); &#125; &#125; else &#123; try &#123; HandlerMapping hm = context.getBean(HANDLER_MAPPING_BEAN_NAME, HandlerMapping.class); this.handlerMappings = Collections.singletonList(hm); &#125; catch (NoSuchBeanDefinitionException ex) &#123; // Ignore, we&apos;ll add a default HandlerMapping later. &#125; &#125; //如果handlerMapping为空那么给其初始化默认的handlerMapping if (this.handlerMappings == null) &#123; this.handlerMappings = getDefaultStrategies(context, HandlerMapping.class); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;No HandlerMappings found in servlet &apos;&quot; + getServletName() + &quot;&apos;: using default&quot;); &#125; &#125; &#125; 在该方法中一般如果没有特别配置基本上ApplicationContext中handlerMapping是null，所以都需要调用getDefaultStrategies方法，该方法会将默认的handlerMapping实例化并注册进ApplicationContext中。具体请看以下代码：12345678910111213141516171819202122232425262728293031protected &lt;T&gt; List&lt;T&gt; getDefaultStrategies(ApplicationContext context, Class&lt;T&gt; strategyInterface) &#123; String key = strategyInterface.getName(); //defaultStrategies是一个map，获取的是DispatchServlet.properties的属性，在这里获取的是系统默认的String类型的handlerMapping String value = defaultStrategies.getProperty(key); if (value != null) &#123; String[] classNames = StringUtils.commaDelimitedListToStringArray(value); List&lt;T&gt; strategies = new ArrayList&lt;T&gt;(classNames.length); for (String className : classNames) &#123; try &#123; //通过反射实例化类 Class&lt;?&gt; clazz = ClassUtils.forName(className, DispatcherServlet.class.getClassLoader()); Object strategy = createDefaultStrategy(context, clazz); strategies.add((T) strategy); &#125; catch (ClassNotFoundException ex) &#123; throw new BeanInitializationException( &quot;Could not find DispatcherServlet&apos;s default strategy class [&quot; + className + &quot;] for interface [&quot; + key + &quot;]&quot;, ex); &#125; catch (LinkageError err) &#123; throw new BeanInitializationException( &quot;Error loading DispatcherServlet&apos;s default strategy class [&quot; + className + &quot;] for interface [&quot; + key + &quot;]: problem with class file or dependent class&quot;, err); &#125; &#125; return strategies; &#125; else &#123; return new LinkedList&lt;T&gt;(); &#125; &#125; 该方法就是通过反射将默认的handlerMapping进行实例化并且通过createDefaultStrategy将controller也就是这里handlerMapping中的handler注册到handlerMapping中。而handler的注册是在BeanUrlHandlerMapping的父类AbstractDetectingUrlHandlerMapping中detectHandler实现的，该方法主要逻辑是将所有spring IoC容器初始化的bean进行匹配，查找到该bean的urls不为空我们就认为他是一个handler并通过registerHandler方法进行注册。具体逻辑代码如下：1234567891011121314151617181920212223protected void detectHandlers() throws BeansException &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Looking for URL mappings in application context: &quot; + getApplicationContext()); &#125; String[] beanNames = (this.detectHandlersInAncestorContexts ? BeanFactoryUtils.beanNamesForTypeIncludingAncestors(getApplicationContext(), Object.class) : getApplicationContext().getBeanNamesForType(Object.class)); // Take any bean name that we can determine URLs for. for (String beanName : beanNames) &#123; //获取handler的所有url定义 String[] urls = determineUrlsForHandler(beanName); if (!ObjectUtils.isEmpty(urls)) &#123; // URL paths found: Let&apos;s consider it a handler. registerHandler(urls, beanName); &#125; else &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Rejected bean name &apos;&quot; + beanName + &quot;&apos;: no URL paths identified&quot;); &#125; &#125; &#125; &#125; 最终在registerHandler方法中将url注册进一个HandlerMapping的私有属性handlerMap中，该handlerMap是一个以url为key、handler为value的linkedHashMap。经过以上几个步骤handler注册已经完成了，其中handlerMap是这里面的核心，在handlerMap中配置好了url请求和对应的handler映射，这为springMVC响应http请求做好了基本映射数据的准备。]]></content>
      <tags>
        <tag>springMVC,HandlerMapping</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springMVC源码分析之初始化]]></title>
    <url>%2F2016%2F09%2F04%2FSpringMVC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[springMVC属于SpringFrameWork家族中的一员，目前已经是最流行的和效率最好的MVC框架了，特别是配合spring的bean管理容器使用能让你很优雅的开发WEB应用。从这篇开始本人会从springMVC的初始化、springMVC的Controller调用过程、springMVC的视图解析过程、springMVC拦截器原理来分析源码，而今天就让我们先来领教一下springMVC的初始化吧。 springMVC配置在开始源码分析前，我们先来看看springMVC的配置文件和web.xml的配置方便接下来de分析。首先是spring-servlet.xml（配置文件什么名字都可以）1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd&quot;&gt; &lt;context:annotation-config/&gt; &lt;context:component-scan base-package=&quot;com.ifenqu.controller&quot;/&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot; p:suffix=&quot;.jsp&quot;&gt; &lt;/bean&gt; &lt;/beans&gt; 以上是一个非常简单的demo配置，包括第一个&lt;context:annotation-config&gt;用来声明允许使用注解，第二个&lt;context:component-scan base-package=&quot;com.ifenqu.controller&quot;/&gt;来自动扫描需要注入的bean，第三个&lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot; p:suffix=&quot;.jsp&quot;&gt;&lt;/bean&gt;为返回的view自动加上后缀。接下来是web.xml文件 123456789101112131415161718192021222324&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd&quot; id=&quot;WebApp_ID&quot; version=&quot;3.0&quot;&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;servlet&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-*.xml&lt;/param-value&gt; &lt;/context-param&gt;&lt;/web-app&gt; web.xml没什么好说的，就是将springMVC在web.xml中注册加入各配置文件。接下来看看controller 1234567891011121314151617package com.ifenqu.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;/** * Created by LAIYAO on 2016/9/4. */@Controllerpublic class HelloController &#123; @ResponseBody @RequestMapping(value=&quot;/hello&quot;) public String hello()&#123; return &quot;hello&quot;; &#125;&#125; 初始化springMVC中最核心的就是DispatcherServlet这个类，该类充当前端控制器控制着request的Mapping、handle、viewResolver等。我们看看这个DispatcherServlet类继承体系。如图所示，DispatcherServlet继承于FrameworkServlet，而FrameworkServlet继承于HttpServletBean，最终继承于HttpServlet。 当系统启动时，在web.xml配置的各配置文件被读取最终组成RootWebApplicationContext并初始化IoC容器，紧接着会执行DispatcherServlet持有的IoC容器的初始化，DispatcherServlet初始化包括两个部分，第一，DispatcherServlet持有的子上下文初始化（该上下文对应的是Servlet的上下文，与Web应用的servletContext上下文呈父子关系）和DispatcherServlet其他部分如strategy初始化等，接下来我们看看springMVC的init方法，如下图所示：其中这个PropertyValues是DispatcherServlet的内部静态类,在这一步主要是用来读入从web.xml配置的文件如下图所示：接下来将DispatcherServlet封装了一层并且初始化好资源加载器resourceLoader，这个resourceLoader初始化之后主要是有类似于getResourceAsStream、getRealPath等资源加载的方法的一个Map和classLoader。 接下来就是初始化这个BeanWrapper，然后执行initServletBean方法，这个方法中主要是初始化webApplicationContext。webApplicationContext的初始化是要以RootWebApplicationContext作为参数，通过反射来创建webApplicationContext对象，实例化结束后需要给上下文设置一下基本配置如bean定义的配置文件位置等，双亲上下文（实例化后子上下文会被setAttribute到根上下文，当要获取bean时先进根上下文获取，再去子上下文找），最后通过调用DispatcherServlet的IoC容器的refresh方法完成strategy的初始化，也就是各种解析器、HandlerMapping、适配器等的初始化，为什么是strategy呢，因为在这里使用了策略模式，springMVC中有很多解析器、映射器和适配器以适应不同场合的调用，所以这里使用使用策略模式。如下图所示：我们挑这其中的initHandlerMappings和initHandlerAdapters方法来看看。首先initHandlerMappings，方法如下图所示：初始化HandlerMapping首先会从ApplicationContext中找到所有的HandlerMappings，为保证至少有一个HandlerMapping注册，如果在ApplicationContext中没有找到HandlerMapping，系统会提供默认的HandlerMapping，即BeanNameUrlHandlerMapping和DefaultAnnotionHandlerMapping而initHandlerAdapters方法和initHandlerMappings差不多，或者说是简直一模一样（moji笑哭脸），不过话说回来，HandlerMapping和HandlerAdapter本来就是相同的用途的类用在不同作用域上，HandlerMapping是找到需要请求的bean，而HandlerAdapter则是找到该bean的具体方法并调用，在最初的初始化时期当然是差不多的逻辑。在这一系列的各模块的初始化之后，WebApplicationContext算是初始化结束，同时FrameworkServlet初始化结束。 总结起来，springMVC的初始化过程就三步，第一步：加载配置文件读取配置文件属性，第二步：将配置文件属性和读取servletContext的组成自己的上下文，第三步，调用refresh方法初始化各strategy组件（各种解析器、适配器）,完成WebApplicationContext的初始化，最终完成DispacherServlet持有的IoC容器的初始化。]]></content>
      <tags>
        <tag>springMVC,源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于redis的发布订阅模式]]></title>
    <url>%2F2016%2F08%2F20%2F%E5%9F%BA%E4%BA%8Eredis%E7%9A%84%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[发布订阅模式pub/sub（publish/subscribe）发布订阅模式是基于事件中广泛使用的通信模型，其中subscriber将注册到自己所监听的事件中，只要publisher有消息或者消息改变，所有注册的subscriber就会接收到消息通知。 发布订阅模式应用广泛，各种消息中间件（如rabbitmq，activemq）都是基于该模式开发，同时在zookeeper中的文件配置集中管理功能中就是用了发布订阅模式，而即时聊天也可以使用这种模式。 redis作为高性能的内存数据库也支持pub/sub模式，今天就说说基于redis的发布订阅模式。 准备首先要安装redis，因本人使用win7开发，所以就直接下载了window版redis，地址 redis on windows ,直接解压运行redis.exe就按默认的配置启动。 编码本实例是基于spring的所以获取redis的bean实例都是由spring注入，首先需先配置spring配置文件spring-redis-config.xml12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;context:property-placeholder location=&quot;classpath:application.properties&quot;/&gt;&lt;bean id=&quot;jedisPoolConfig&quot; class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt; &lt;property name=&quot;maxTotal&quot;&gt; &lt;value&gt;$&#123;redis.pool.maxActive&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;maxIdle&quot;&gt; &lt;value&gt;$&#123;redis.pool.maxIdle&#125;&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;testOnReturn&quot; value=&quot;true&quot;/&gt;&lt;/bean&gt;&lt;bean id = &quot;jedisPool&quot; class=&quot;redis.clients.jedis.JedisPool&quot;&gt; &lt;constructor-arg index=&quot;0&quot; ref=&quot;jedisPoolConfig&quot;/&gt; &lt;constructor-arg index=&quot;1&quot; value=&quot;$&#123;redis.host&#125;&quot;/&gt; &lt;constructor-arg index=&quot;2&quot; value=&quot;$&#123;redis.port&#125;&quot; type=&quot;int&quot;/&gt; &lt;constructor-arg index=&quot;3&quot; value=&quot;$&#123;redis.timeout&#125;&quot; type=&quot;int&quot;/&gt; &lt;!-- &lt;constructor-arg index=&quot;4&quot; value=&quot;$&#123;redis.password&#125;&quot;/&gt;--&gt;&lt;/bean&gt;&lt;bean id=&quot;jedisConnectionFactory&quot; class=&quot;org.springframework.data.redis.connection.jedis.JedisConnectionFactory&quot; destroy-method=&quot;destroy&quot;&gt; &lt;property name=&quot;poolConfig&quot; ref=&quot;jedisPoolConfig&quot;&gt;&lt;/property&gt; &lt;property name=&quot;hostName&quot; value=&quot;$&#123;redis.host&#125;&quot;&gt;&lt;/property&gt; &lt;property name=&quot;port&quot; value=&quot;$&#123;redis.port&#125;&quot;&gt;&lt;/property&gt; &lt;!--&lt;property name=&quot;password&quot; value=&quot;$&#123;redis.password&#125;&quot;&gt;&lt;/property&gt;--&gt; &lt;property name=&quot;timeout&quot; value=&quot;$&#123;redis.timeout&#125;&quot;&gt;&lt;/property&gt; &lt;property name=&quot;usePool&quot; value=&quot;true&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;jedisTemplate&quot; class=&quot;org.springframework.data.redis.core.RedisTemplate&quot;&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;jedisConnectionFactory&quot;&gt;&lt;/property&gt; &lt;property name=&quot;keySerializer&quot;&gt; &lt;bean class=&quot;org.springframework.data.redis.serializer.StringRedisSerializer&quot; /&gt; &lt;/property&gt; &lt;property name=&quot;valueSerializer&quot;&gt; &lt;bean class=&quot;org.springframework.data.redis.serializer.StringRedisSerializer&quot; /&gt; &lt;/property&gt;&lt;/bean&gt; 接着封装publisher-MQPublisher主要封装的是该方法，其中我们可以制定自己的消息格式，方便业务操作，在这里本人封装了一个MQMessage的一个消息实体类。123456789101112131415161718public void pub(String channel,String message) &#123; Jedis jedis = null; try &#123; jedis = jedisPool.getResource(); MQMessage mqMessage = new MQMessage(); mqMessage.setChannelName(channel); mqMessage.setData(message); mqMessage.setMsgId(channel + UUID.randomUUID()); String mqMsg = JSON.toJSONString(mqMessage); jedis.publish(channel, mqMsg); &#125; catch (Exception e) &#123; log.error(&quot;got exception :&quot; + e); &#125; finally &#123; if(jedis!=null) &#123; jedis.close(); &#125; &#125; &#125; 要实现redis的pub/sub需要定义一个监听器，该监听器继承redis的JedisPubSub。并重写onMessage等方法来消费接收消息，因为只是个demo，所以直接用log输出表示。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class MQPubListener extends JedisPubSub&#123; private static Logger log= LoggerFactory.getLogger(MQPubListener.class); /** * 订阅消息后的处理 * @param channel * @param message */ @Override public void onMessage(String channel, String message) &#123; log.info(channel+&quot;......&quot;+message); &#125; /** * 取得按表达式获取的消息后的处理 * @param pattern * @param channel * @param message */ public void onPMessage(String pattern, String channel, String message) &#123; log.info(pattern+&quot;....&quot;+channel+&quot;....&quot;+message); &#125; /** * 初始化订阅时处理 * @param channel * @param subscribedChannels */ public void onSubscribe(String channel, int subscribedChannels) &#123; log.info(channel+&quot;......&quot;+&quot;subscirbed count:&quot;+subscribedChannels); &#125; /** * 取消订阅时处理 * @param channel * @param subscribedChannels */ public void onUnsubscribe(String channel, int subscribedChannels) &#123; log.info(channel+&quot;have unsubscribed&quot;+&quot;current subscirbed channel count is:&quot;+subscribedChannels); &#125; public void onPUnsubscribe(String pattern, int subscribedChannels) &#123; &#125; public void onPSubscribe(String pattern, int subscribedChannels) &#123; &#125;&#125; 接下来是定义subscribe方的消费者-MQComsumer由于redis的subscribe方法时阻塞的，并且消费者的注册需要在生产者的publish前进行，所以我们消费者利用多线程来实现。123456789101112131415161718192021222324252627282930public class MQComsumer &#123; private static Logger log= LoggerFactory.getLogger(MQComsumer.class); private JedisPubSub listener; private Jedis jedis; public MQComsumer(JedisPubSub listener,Jedis jedis)&#123; this.jedis=jedis; this.listener=listener; &#125; public SubTask subscribe(String channel)&#123; return new SubTask(channel); &#125; public void unSubscribe(String channel)&#123; jedis.del(channel); &#125; public class SubTask implements Runnable&#123; private String routeKey; public SubTask(String routeKey)&#123; this.routeKey=routeKey; &#125; public void run() &#123; log.info(&quot;sub starting ,the key is:&quot; +routeKey); jedis.subscribe(listener,routeKey); log.info(&quot;sub end&quot;); &#125; &#125;&#125; 最后使用MQEngine来触发启动comsumer线程123456789101112131415public class MQEngine &#123; private static Logger log= LoggerFactory.getLogger(MQEngine.class); private MQComsumer comsumer; private ExecutorService service; public MQEngine(MQComsumer comsumer)&#123; this.comsumer=comsumer; &#125; public void sub(String channel)&#123; log.info(&quot;subscribe channel:&quot;+channel); service= Executors.newFixedThreadPool(1); service.execute(comsumer.subscribe(channel)); &#125; 测试123456789101112131415161718@RunWith(SpringJUnit4ClassRunner.class)@WebAppConfiguration@ContextConfiguration(&#123;&quot;/spring-beans.xml&quot;,&quot;/spring-redis-config.xml&quot;&#125;)public class appTest &#123; @Autowired private JedisPool jedisPool; private static final String Channel=&quot;test&quot;; @Test public void test()&#123; MQPubListener listener=new MQPubListener(); MQComsumer comsumer=new MQComsumer(listener,jedisPool.getResource()); MQEngine engine=new MQEngine(comsumer); engine.sub(Channel); MQPublisher publisher=new MQPublisher(jedisPool); publisher.pub(Channel,&quot;hello message&quot;); &#125;&#125; 测试结果 test…….{“channelName”:”test”,”data”:”hello message”,”msgId”:”testbe6de83c-ffbf-4bbb-8553-381e41dc133f”}消费方成功获取消息]]></content>
      <tags>
        <tag>redis,sub/pub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用httpClient+PoolingHttpClientConnectionManager提交请求]]></title>
    <url>%2F2016%2F08%2F06%2F%E4%BD%BF%E7%94%A8httpClient%2BPoolingHttpClientConnectionManager%E6%8F%90%E4%BA%A4%E8%AF%B7%E6%B1%82%2F</url>
    <content type="text"><![CDATA[使用连接池的好处大家都知道http连接是基于tcp的，而tcp创建连接需要三次握手，断开连接四次挥手，如果我们不使用连接池，那么每发出一个请求，就需要三次握手和四次挥手，而三次握手和四次挥手都是耗资源的操作。试想如果频繁的发出请求，性能是不是会是个瓶颈。所以HttpClient在4之后就出现了连接池的概念，当请求结束并不是直接断开连接，而是返回给连接池方便下次调用。 连接池配置使用连接池主要是用到PoolingHttpClientConnectionManager这个类，基本上的配置像Cookie配置策略、连接数的控制都是在ConnectionManager中配置的,所以在调用httpClient时必须先初始化ConnectionManager。12345678910111213141516private static PoolingHttpClientConnectionManager clientConnectionManager=null; private static CloseableHttpClient httpClient=null; private static RequestConfig config = RequestConfig.custom().setCookieSpec(CookieSpecs.STANDARD_STRICT).build(); private final static Object syncLock = new Object(); @PostConstruct private void init()&#123; Registry&lt;ConnectionSocketFactory&gt; socketFactoryRegistry = RegistryBuilder.&lt;ConnectionSocketFactory&gt;create() .register(&quot;https&quot;, SSLConnectionSocketFactory.getSocketFactory()) .register(&quot;http&quot;, PlainConnectionSocketFactory.getSocketFactory()) .build(); clientConnectionManager =new PoolingHttpClientConnectionManager(socketFactoryRegistry); clientConnectionManager.setMaxTotal(50); clientConnectionManager.setDefaultMaxPerRoute(25); &#125; 创建httpClient实例一般在这个实例中我们将CookieStore传入并让其一直持有Cookie 12345678910111213141516public static CloseableHttpClient getHttpClient()&#123; if(httpClient == null)&#123; synchronized (syncLock)&#123; if(httpClient == null)&#123; CookieStore cookieStore = new BasicCookieStore(); BasicClientCookie cookie = new BasicClientCookie(&quot;sessionID&quot;, &quot;######&quot;); cookie.setDomain(&quot;#####&quot;); cookie.setPath(&quot;/&quot;); cookieStore.addCookie(cookie); httpClient =HttpClients.custom().setConnectionManager(clientConnectionManager).setDefaultCookieStore(cookieStore).setDefaultRequestConfig(config).build(); &#125; &#125; &#125; &#125; return httpClient; &#125; 创建POST/GET请求方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public static HttpEntity httpGet(String url, Map&lt;String,Object&gt; headers)&#123; CloseableHttpClient httpClient = getHttpClient(); HttpRequest httpGet = new HttpGet(url); if(headers!=null&amp;&amp;!headers.isEmpty())&#123; httpGet = setHeaders(headers, httpGet); &#125; CloseableHttpResponse response = null; try&#123; response =httpClient.execute((HttpGet)httpGet); HttpEntity entity = response.getEntity(); return entity; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; return null; &#125; /** * post请求,使用json格式传参 * @param url * @param headers * @param data * @return */ public static HttpEntity httpPost(String url,Map&lt;String,Object&gt; headers,String data)&#123; CloseableHttpClient httpClient = getHttpClient(); HttpRequest request = new HttpPost(url); if(headers!=null&amp;&amp;!headers.isEmpty())&#123; request = setHeaders(headers,request); &#125; CloseableHttpResponse response = null; try &#123; HttpPost httpPost = (HttpPost) request; httpPost.setEntity(new StringEntity(data, ContentType.create(&quot;application/json&quot;, &quot;UTF-8&quot;))); response=httpClient.execute(httpPost); HttpEntity entity = response.getEntity(); return entity; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; /** 使用表单键值对传参 */ public static HttpEntity PostForm(String url,Map&lt;String,Object&gt; headers,List&lt;NameValuePair&gt; data)&#123; CloseableHttpClient httpClient = getHttpClient(); HttpRequest request = new HttpPost(url); if(headers!=null&amp;&amp;!headers.isEmpty())&#123; request = setHeaders(headers,request); &#125; CloseableHttpResponse response = null; UrlEncodedFormEntity uefEntity; try &#123; HttpPost httpPost = (HttpPost) request; uefEntity = new UrlEncodedFormEntity(data,&quot;UTF-8&quot;); httpPost.setEntity(uefEntity); // httpPost.setEntity(new StringEntity(data, ContentType.create(&quot;application/json&quot;, &quot;UTF-8&quot;))); response=httpClient.execute(httpPost); HttpEntity entity = response.getEntity(); return entity; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; /** * 设置请求头信息 * @param headers * @param request * @return */ private static HttpRequest setHeaders(Map&lt;String,Object&gt; headers, HttpRequest request) &#123; for (Map.Entry entry : headers.entrySet()) &#123; if (!entry.getKey().equals(&quot;Cookie&quot;)) &#123; request.addHeader((String) entry.getKey(), (String) entry.getValue()); &#125; else &#123; Map&lt;String, Object&gt; Cookies = (Map&lt;String, Object&gt;) entry.getValue(); for (Map.Entry entry1 : Cookies.entrySet()) &#123; request.addHeader(new BasicHeader(&quot;Cookie&quot;, (String) entry1.getValue())); &#125; &#125; &#125; return request; &#125;]]></content>
      <tags>
        <tag>httpClient,连接池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos6.6搭建solrcloud5.3.1]]></title>
    <url>%2F2016%2F07%2F31%2Fcentos6-6%E6%90%AD%E5%BB%BAsolrcloud5-3-1%2F</url>
    <content type="text"><![CDATA[1.搭建前准备去官网分别下载以下压缩包：12345jdk-8u45-linux-x64.tar.gzzookeeper-3.4.6.tar.gzsolrcloud-5.3.1.tar.gz 1.1安装配置jdk1tar xvzf /home/workspaces/jdk-8u45-linux-x64.tar.gz 配置环境变量，进入profile文件1vim /etc/profile 追加以下内容12345JAVA_HOME=/usr/java/jdk1.8.45JRE_HOME=/usr/java/jdk1.8.45/jrePATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libexport JAVA_HOME JRE_HOME PATH CLASSPATH 2安装配置开启zookeeper集群1tar xf /home/workspace/soft/zookeeper-3.4.6.tar.gz 复制zookeeper默认配置文件12cd zookeeper-3.4.6/conf cp zoo_sample.cfg zoo.cfg 将需要搭建成集群的服务器添加进去12345678910vim zoo.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=/path/to/zookeeper/data clientPort=2181 server.1=192.168.156.121:2888:3888 server.2=192.168.156.122:2888:3888 server.3=192.168.156.123:2888:3888 将服务器编号写入每一台服务器12345678910# 注意每台机器上的不一样echo&quot;1&quot;&gt;myid#在solr1上echo&quot;2&quot;&gt;myid#在solr2上echo&quot;3&quot;&gt;myid#在solr3上 其中solr1、solr2、solr3分别是我三台不同服务器名在上面配置了三台服务器集群，要在三台服务器分别如上配置并且开启zookeeper服务器1zookeeper-3.4.6/bin ./zkServer.sh start 3.将solr安装为服务1tar xf /home/workspace/soft/solrcloud-5.3.1.tar.gz 创建两个文件夹solr、data1mkdir -p /solrcloud/&#123;data,solr&#125; 设置服务名称、端口等12cd solr-5.3.1/bin ./install_solr_service.sh /home/wokspace/soft/solr-5.3.1.tgz -d /solrcloud/data/ -i /solrcloud/solr/ -s solrcloud -u root -p 8080 这里面-d是放solr的data数据，-i是放solr文件，-s是服务名 -u是用户 -p是实用端口，默认是8983 修改solrcloud的data文件123456789cd /home/workspace/solrcloud/data ls data log4j.properties logs solr-8983.pid solr.in.sh vim solr.in.sh # Set the ZooKeeper connection string if using an external ZooKeeper ensemble # e.g. host1:2181,host2:2181/chroot # Leave empty if not using SolrCloud ZK_HOST=&quot;192.168.156.121:2181,192.168.156.122:2181,192.168.156.123:2181&quot; 启动solrcloud1service solrcloud restart 4.更新配置文件创建collection123456cd solr-5.3.1 ./server/scripts/cloud-scripts/zkcli.sh -zkhost localhost:2181 -cmd upconfig -confname demo-conf -confdir server/solr/configsets/basic_configs/conf/ ./server/scripts/cloud-scripts/zkcli.sh -zkhost localhost:2181 -cmd linkconfig -collection demo -confname demo-conf curl &apos;http://192.168.156.121:8080/solr/admin/collections?action=CREATE&amp;name=demo&amp;numShards=1&amp;replicationFactor=1&apos; 其中-upconfig 是更新配置文件，-linkconfig是创建链接最后curl 提交请求创建collection，collection名称为demo，一个collection创建一个shard，一个shard创建一个replica 5.添加文件数据索引123bin/post -c demo -p 8080 /home/workspace/solrcloud/example/exampledocs/books.json 以上 -c是指定要上传数据给哪个collection，-p是端口号 如果想自定义field字段，进入schema.xml添加或修改field，修改之后需要再次更新配置文件和第四步的更新配置文件一样 7.查询1curl &apos;http://192.168.219.128:8080/solr/demo/select?wt=json&amp;indent=true&amp;q=cat:book&amp;fl=name&apos; 响应12345678910111213141516171819&#123; &quot;responseHeader&quot;:&#123; &quot;status&quot;:0, &quot;QTime&quot;:6, &quot;params&quot;:&#123; &quot;q&quot;:&quot;cat:book&quot;, &quot;indent&quot;:&quot;true&quot;, &quot;fl&quot;:&quot;name&quot;, &quot;wt&quot;:&quot;json&quot;&#125;&#125;, &quot;response&quot;:&#123;&quot;numFound&quot;:4,&quot;start&quot;:0,&quot;docs&quot;:[ &#123; &quot;name&quot;:[&quot;The Lightning Thief&quot;]&#125;, &#123; &quot;name&quot;:[&quot;The Sea of Monsters&quot;]&#125;, &#123; &quot;name&quot;:[&quot;Sophie&apos;s World : The Greek Philosophers&quot;]&#125;, &#123; &quot;name&quot;:[&quot;Lucene in Action, Second Edition&quot;]&#125;] &#125;&#125;]]></content>
      <tags>
        <tag>centos,solrcloud</tag>
      </tags>
  </entry>
</search>
